ORIGINAL_INDEX,CONTENT,LABEL
1557,"Re: I want to develop transactions for Cassandra and I want your feedback That's what I'm saying, yes. ",not-ak
1558,"Re: I want to develop transactions for Cassandra and I want your feedback So basically, you are saying that even if I had developed something to provide serializable cross-partition transactions still nobody cares, nobody wants it because it would be too complex and for sure not performant enough? I just want to hear it crystal clear, so that I can talk to my supervisor and redirect my efforts to something more useful for you guys like this ramp for example.",not-ak
1559,"Re: I want to develop transactions for Cassandra and I want your feedback There is a lot of interest in ramp, but the dependency on requiring a unique timestamp id is a bitch. There is zero interest in committing and maintaining a more heavyweight framework to get all the way to serializable cross-partition transactions. ",not-ak
1560,"Re: I want to develop transactions for Cassandra and I want your feedback Hi Jonathan, I haven�t heard about it before, but now I�ve read it and it indeed offers something interesting. I�ve read blog post, paper and comments at Jira so I need to digest it a bit and let it sink in. Thanks for letting me know about it. Can you tell me something more about the status of that feature? Would you like to have it? From what I see, discussion stopped year ago and it has minor priority so it doesn�t seem like a hot subject that everyone awaits. Maybe I can incorporate that as a building block for something more functional. While reading I noticed that some concepts resemble what I�ve been thinking about, but here it is obviously much more detailed and specified. I need to digest it.",not-ak
1561,Re: I want to develop transactions for Cassandra and I want your feedback Have you seen RAMP transactions? I think that's a much better fit for C* than fully linearizable operations cross-partition. https://issues.apache.org/jira/browse/CASSANDRA-7056 ,executive
1562,"Re: I want to develop transactions for Cassandra and I want your feedback actually I have been also thinking about doing something like redundant execution of transaction. So you have this *single active thing* that executes transaction, but you can also have redundancy of form of other _followers_ that try to execute same transactions (like a dry-run) and upon detection of failure of *single active thing* one of them could pick transaction execution and finish it. Still it's a little bit vague and needs a lot more details, but now system could recover from failure of this _single active thing_. What do you think? 2015-08-07 14:48 GMT+02:00 Robert Stupp : -- Marek Lewandowski",existence
1563,Re: I want to develop transactions for Cassandra and I want your feedback That�s the point - a single thing. A single thing IS a single-point-of-failure. Sorry to reply that drastically: that�s an absolute no-go in C*. Every node must be equal - no special �this� or special �that�. � Robert Stupp @snazy,property
1564,"Re: I want to develop transactions for Cassandra and I want your feedback Hey Robert, thanks for reply. Yes, you understood correctly although I don't think it is quite necessary to provide full ACID support, concretely C could be eventual. D is supported by Cassandra as long as they are replicas (I think). I'd focus only on A and I for multiple statements, which still can be piece of work, but that should be more less possible. Although I haven't worked with such big clusters nor smaller ones I understand typical use of Cassandra in the wild and unreliability of network. I tried to incorporate that into my thinking process. I also believe that any solution that will be developed has to be like opt-in for end user. End user has to accept degraded performance doing transactions, retries of transactions at his side and so on. It won't work without some proper handling at client level and I mean at business logic level. So to answer your question what can be done when one transaction manager is no longer reachable => abort transaction and raise that issue up to client side. Let it crash. Let client handle it, but there can be some default handling supported at driver level to support common scenarios for clients, like retry again later after some timeout. Need to think about details, but point is to not hide everything from client. Client knows he does distributed transaction and should be aware of fallacies of that. That's my opinion for now. What do you think about it? About global lock / transaction manager. I agree. In both of my ideas there is some central piece. It doesn't have to be single point of failure thought, but once this single guy is elected for managing transaction (or however we call it) it will need to coordinate stuff with other nodes and I haven't found any other way around it. Anywho, my question is: Is there any one who would accompany me during journey of developing such solution and give feedback at what I do? If there is, that's awesome I will gladly present detailed solution up for discussion. If not I'll just try to do it on my own which in the end might turn into failure, but that's fine because it is an experiment. Marek 2015-08-07 10:31 GMT+02:00 Robert Stupp : -- Marek Lewandowski",existence
1565,"Re: I want to develop transactions for Cassandra and I want your feedback Hey Marek, you�ve put a lot of effort in your proposal and first of all: Thanks for that! If I understood you right, your proposal is about full ACID support ; able to handle multiple statements in a single transaction. Cassandra is a database used in distributed environments - a few servers sitting nearby to each other up to 1000+ servers on the other side of the globe connected via a more or probably less reliable network connection. Cassandra is also a database that can handle many millions of operations per second. Why do I say that? If you now imagine that _one_ transaction manager is no longer reachable by the client/coordinator or the involved replica nodes - what do you do? I mean, you might be able to implement the A and D - but what about I and C? IMO there is no way around a global lock/transaction manager for ACID. You could optimize some things and take some load of �the central� instance - but you end up coordinating stuff at that transaction manager. Implementing distributed locks is a nightmare - especially if the lock spans the whole world. Proposing transactions for C* (full ACID or not) would need a thorough concept covering all these �little nice� edge cases that can happen in a huge distributed system and also deals with the problems that arise with many 10k clients. Just think of: clients fail/stuck, nodes fail/stuck, network gets broken, partitioned, flappy etc etc. Robert � Robert Stupp @snazy",not-ak
1566,"I want to develop transactions for Cassandra and I want your feedback Hello everyone, *TL;DR;* I want to develop transactions (similar to those relational ones) for Cassandra, I have some ideas and I'd like to hear your feedback. *Long story short:* I want to develop prototype of solution that features transactions spanning multiple Cassandra partitions resembling those in relational databases. I understand that in Cassandra's world such transactions will be quite a bit different than in relational db world. That prototype or research if you will, is subject of my master's thesis. It's been some time since I've been dancing around that subject and postponing it, but what I understood in the process is that I cannot do anything useful being hidden from community's feedback. I want you to provide feedback on my ideas. You also have a power of changing it completely because first and foremost _I want to develop something actually useful, not only get my master's degree._ To not scare anyone with huge wall of text, for now I'll just post very brief description of my ideas and longer block of text describing how I can see committing and rolling back data. I have more detailed descriptions prepared already, but I don't want to share 4 pages of text in one go. Scope of the project (assuming I'll do it alone) is an experiment, not production ready solution. Such experiment can use any tools possible to actually perform it. Baseline for any idea is: - asynchronous execution - think Akka and actors with non blocking execution and message passing - doesn't have to be completely transparent for end user - solution may enforce certain workflow of interacting with it and/or introduce new concepts (like akka messages instead of CQL and binary protocol). So far after reading a lot and thinking even more I have two ideas that I'd like to share. ### Ideas are (with brief description, details will come later): ### #### Idea 1: Event streaming #### - Imagine that every modiifcation is represented by an _Event_. - Imagine you can group these events into _Event Groups_. - Imagine that such groups are time series data - Imagine you can read such groups as a stream of events (think reactive stream) Idea is that: you don't need to lock data when you are sure there is no one else to compete with. There is 1 guy called _Cursor_ that reads Event Stream and executes Event Groups one by one advacing its position on the stream when Event Group has been executed. Seems like a system where you have only 1 transaction at any given time, but there are many areas to optimize that and to allow more than that. However I'll stop here. #### Idea 2: Locking data #### - uses additional tables to acquire read/write locks - seperate tables to append modifications - as in ""Rollback: Appending to seperate table."" - supports different isolation levels. - more traditional approach, kind of translation of traditional locking to cassandra reality. ------------------------------------------------------------------------------------------- Common part of two is approach to doing commit and rollback. ### Doing Rollback and commit ### I have two ideas for rollback. I like 2nd one more, because it is simpler and potentially faster. #### Rollback: Query rewriting #### It modifies original data, but before that it copies original data so that state can be restored. Then when failure is detected, modification query can be rewritten so that original data can be restored. Query rewriting seems like a complex functionality. I tried few simple and a little bit more complex statements and in general for basic stuff algorithm is not that complicated, but to support everything CQL has to offer it might be hard. Still such transactional system might have some restrictions over CQL statements used, because first of all when someone wants to have these transactions they already want something non standard. I will skip details of that approach for now. #### Rollback: Appending to seperate table. #### Image we have table A that we want to have transactions on. This requires another table A_tx which has same schema as A, but has *1 more clustering column* and few new columns. A_tx will be additionally clustered by transaction id. New columns are: - is_committed boolean - is_rolledback boolean - is_applied boolean General idea is: 1. During transaction append changes to XXX_tx tables. 2. For rollback: nothing needs to be done (besides cleaning XXX_tx tables of useless data scheduled for rollback) 3. For commit: rows in each XXX_tx are marked as committed. This can be done using BATCH update so that all rows affected by transactions are committed. These changes will be eventually merged back into original row. Committed changes are visible during query, because query has to select from 2 tables. If you query for XXX table then you have to query that table, but also XXX_TX and get all committed data, merge result and return that to client. Here committed data eventually lands into proper row - during read as background process for example (this is this is_applied column) results are merged and inserted into original row, plus additionally modifications can be marked as _applied_. Uncommitted data can also be eventually cleaned up. *Important note:* since partitioning key stays the same for {{XXX}} table and {{XXX_TX}} table, data will reside on same nodes so that queries and application of data can be done locally. ### What happens next ### Assuming I get any feedback I'll post more detailed descriptions of two approaches. I would love to hear your feedback on whole subject. Just to begin discussion and pick your interest. What you think about having more heavy transactions? Does this experiment has sense at all? regards -- Marek Lewandowski",existence
976,"Re: [VOTE] Merging branch HDFS-7240 to trunk Hi Owen, Thanks for the proposal. I was hoping for same releases, but I am okay with different releases as well. @Konstantin, I am completely open to the name changes, let us discuss that in HDFS-10419 and we can make the corresponding change. --Anu On 3/19/18, 10:52 AM, ""Owen O'Malley"" wrote: Andrew and Daryn, Do you have any feedback on the proposal? Otherwise, we can start a vote for ""adoption of new codebase"" tomorrow. .. Owen ",not-ak
977,"Re: [VOTE] Merging branch HDFS-7240 to trunk Andrew and Daryn, Do you have any feedback on the proposal? Otherwise, we can start a vote for ""adoption of new codebase"" tomorrow. .. Owen ",not-ak
978,"Re: [VOTE] Merging branch HDFS-7240 to trunk The proposal to add it as a subproject of Hadoop makes sense to me. Thank you Owen. I am glad to have a path for scaling HDFS further, especially as it enters areas like IoT and self-driving cars, where storage requirements are huge. I am not very fond of the name HDSL, though. ""Storage Layer"" sounds too generic. May be something more descriptive, like HDDS / HDSS (Hadoop Dynamically Distributed/Scaling Storage). We can discuss this in the jira HDFS-10419. Thanks, --Konstantin ",not-ak
979,"Re: [VOTE] Merging branch HDFS-7240 to trunk Owen, Thanks for your proposal. While I would have prefered to have HDSL in HDFS and also to be part of Hadoop releases for the reasons stated earlier in this thread, I am willing to accept your proposal as a compromise to move this forward. Jitendra, Anu, Daryn, Andrew, Konstantine your thoughts? Thanks Sanjay On Mar 14, 2018, at 1:50 PM, Owen O'Malley > wrote: This discussion seems to have died down coming closer consensus without a resolution. I'd like to propose the following compromise: * HDSL become a subproject of Hadoop. * HDSL will release separately from Hadoop. Hadoop releases will not contain HDSL and vice versa. * HDSL will get its own jira instance so that the release tags stay separate. * On trunk (as opposed to release branches) HDSL will be a separate module in Hadoop's source tree. This will enable the HDSL to work on their trunk and the Hadoop trunk without making releases for every change. * Hadoop's trunk will only build HDSL if a non-default profile is enabled. * When Hadoop creates a release branch, the RM will delete the HDSL module from the branch. * HDSL will have their own Yetus checks and won't cause failures in the Hadoop patch check. I think this accomplishes most of the goals of encouraging HDSL development while minimizing the potential for disruption of HDFS development. Thoughts? Andrew, Jitendra, & Sanjay? Thanks, Owen",not-ak
980,Re: [VOTE] Merging branch HDFS-7240 to trunk Originally I would have prefered (a); but Owen made a strong case for (b) in my discussions with his last week. Overall we need a broader discussion around the next steps for NN evolution and how to chart the course; I am not locked into any particular path or how we would do it. Let me make a more detailed response in HDFS-10419. sanjay,not-ak
981,"Re: [VOTE] Merging branch HDFS-7240 to trunk This discussion seems to have died down coming closer consensus without a resolution. I'd like to propose the following compromise: * HDSL become a subproject of Hadoop. * HDSL will release separately from Hadoop. Hadoop releases will not contain HDSL and vice versa. * HDSL will get its own jira instance so that the release tags stay separate. * On trunk (as opposed to release branches) HDSL will be a separate module in Hadoop's source tree. This will enable the HDSL to work on their trunk and the Hadoop trunk without making releases for every change. * Hadoop's trunk will only build HDSL if a non-default profile is enabled. * When Hadoop creates a release branch, the RM will delete the HDSL module from the branch. * HDSL will have their own Yetus checks and won't cause failures in the Hadoop patch check. I think this accomplishes most of the goals of encouraging HDSL development while minimizing the potential for disruption of HDFS development. Thoughts? Andrew, Jitendra, & Sanjay? Thanks, Owen",not-ak
982,"Re: [VOTE] Merging branch HDFS-7240 to trunk Hi Joep, ",executive
983,"Re: [VOTE] Merging branch HDFS-7240 to trunk Joep, You raise a number of points: (1) Ozone vs and object stores. �Some users would choose Ozone as that layer, some might use S3, others GCS, or Azure, or something else�. (2) How HDSL/Ozone fits into Hadoop and whether it is necessary. (3) You raise the release issue which we will respond in a separate email. Let me respond to 1 & 2: ***Wrt to (1) Ozone vs other object stores*** Neither HDFS or Ozone has any real role in cloud except for temp data. The cost of local disk or EBS is so high that long term data storage on HDFS or even Ozone is prohibitive. So why the hell create the KV namespace? We need to stabilize the HDSL where data is stored. - We are targeting Hive and SPark apps to stabilize HDSL using real Hadoop apps over OzoneFS. But HDSL/Ozone is not feature compatible with HDFS so how will users even use it for real to stability. Users can run HDFS and Ozone side by side in same cluster and have two namespace (just like in Federation) and run apps on both: run some hive and spark apps on Ozone and others that need full HDFS feature (encryption) on HDFS. As it becomes stable they can start using HDSL/Ozone for production use for a portion of their data. ***Wrt to (2) HDSL/Ozone fitting into Hadoop and why the same repository*** Ozone KV is a temporary step. Real goal is to put NN on top of HDSL, We have shown how to do that in the roadmap that Konstantine and Chris D asked. Milestone 1 is feasible and doesn't require removal of FSN lock. We have also shown several cases of sharing other code in future (protocol engine). This co-development will be easier if in the same repo. Over time HDSL + ported NN will create a new HDFS and become feature compatible - some of the feature will come for free because they are in NN and will port over to the new NN, Some are in block layer (erasure code) and will have to be added to HDSL. --- You compare with Yarn, HDFS and Common. HDFS and Yarn are independent but both depend on Hadoop common (e.g. HBase runs on HDFS without Yarn). HDSL and Ozone will depend on Hadoop common, Indeed the new protocol engine of HDSL might move to Hadoop common or HDFS. We have made sure that there are no dependencies of HDFS on HDSL or currently. ***The Repo issue and conclusion*** HDFS community will need to work together as we evolve old HDFS to use HDSL, new protocol engine and Raft. and together evolve to a newer more powerful set of sub components. It is important that they are in same repo and that we can share code through both private interface. We are not trying to build a competing Object store but to improve HDFS and fixing scalability fundamentally is hard and we are asking for an environment for that to happen easily over the next year while heeding to the stability concerns of HDFS developers (eg we remove compile time dependency, maven profile). This work is not being done by members of foreign project trying to insert code in Hadoop, but by Hadoop/HDFS developers with given track record s and are active participation in Hadoop and HDFS. Our jobs depend on HDFS/Hadoop stability - destabilizing is the last thing we want to do; we have responded every constructive feedback sanjay --------------------------------------------------------------------- To unsubscribe, e-mail: mapreduce-dev-unsubscribe@hadoop.apache.org For additional commands, e-mail: mapreduce-dev-help@hadoop.apache.org",not-ak
984,"Re: [VOTE] Merging branch HDFS-7240 to trunk Sorry for jumping in late into the fray of this discussion. It seems Ozone is a large feature. I appreciate the development effort and the desire to get this into the hands of users. I understand the need to iterate quickly and to reduce overhead for development. I also agree that Hadoop can benefit from a quicker release cycle. For our part, this is a challenge as we have a large installation with multiple clusters and thousands of users. It is a constant balance between jumping to the newest release and the cost of this integration and test at our scale, especially when things aren't backwards compatible. We try to be good citizens and upstream our changes and contribute back. The point was made that splitting the projects such as common and Yarn didn't work and had to be reverted. That was painful and a lot of work for those involved for sure. This project may be slightly different in that hadoop-common, Yarn and HDFS made for one consistent whole. One couldn't run a project without the other. Having a separate block management layer with possibly multiple block implementation as pluggable under the covers would be a good future development for HDFS. Some users would choose Ozone as that layer, some might use S3, others GCS, or Azure, or something else. If the argument is made that nobody will be able to run Hadoop as a consistent stack without Ozone, then that would be a strong case to keep things in the same repo. Obviously when people do want to use Ozone, then having it in the same repo is easier. The flipside is that, separate top-level project in the same repo or not, it adds to the Hadoop releases. If there is a change in Ozone and a new release needed, it would have to wait for a Hadoop release. Ditto if there is a Hadoop release and there is an issue with Ozone. The case that one could turn off Ozone through a Maven profile works only to some extend. If we have done a 3.x release with Ozone in it, would it make sense to do a 3.y release with y>x without Ozone in it? That would be weird. This does sound like a Hadoop 4 feature. Compatibility with lots of new features in Hadoop 3 need to be worked out. We're still working on jumping to a Hadoop 2.9 release and then working on getting a step-store release to 3.0 to bridge compatibility issues. I'm afraid that adding a very large new feature into trunk now, essentially makes going to Hadoop 3 not viable for quite a while. That would be a bummer for all the feature work that has gone into Hadoop 3. Encryption and erasure encoding are very appealing features, especially in light of meeting GDPR requirements. I'd argue to pull out those pieces that make sense in Hadoop 3, merge those in and keep the rest in a separate project. Iterate quickly in that separate project, you can have a separate set of committers, you can do separate release cycle. If that develops Ozone into _the_ new block layer for all use cases (even when people want to give up on encryption, erasure encoding, or feature parity is reached) then we can jump of that bridge when we reach it. I think adding a very large chunk of code that relatively few people in the community are familiar with isn't necessarily going to help Hadoop at this time. Cheers, Joep ",executive
985,"Re: [VOTE] Merging branch HDFS-7240 to trunk Hi Andrew, � I think we can eliminate the maintenance costs even in the same repo. We can make following changes that incorporate suggestions from Daryn and Owen as well. 1. Hadoop-hdsl-project will be at the root of hadoop repo, in a separate directory. 2. There will be no dependencies from common, yarn and hdfs to hdsl/ozone. 3. Based on Daryn�s suggestion, the Hdsl can be optionally (via config) be loaded in DN as a pluggable module. If not loaded, there will be absolutely no code path through hdsl or ozone. 4. To further make it easier for folks building hadoop, we can support a maven profile for hdsl/ozone. If the profile is deactivated hdsl/ozone will not be built. For example, Cloudera can choose to skip even compiling/building hdsl/ozone and therefore no maintenance overhead whatsoever. HADOOP-14453 has a patch that shows how it can be done. Arguably, there are two kinds of maintenance costs. Costs for developers and the cost for users. - Developers: A maven profile as noted in point (3) and (4) above completely addresses the concern for developers as there are no compile time dependencies and further, they can choose not to build ozone/hdsl. - User: Cost to users will be completely alleviated if ozone/hdsl is not loaded as mentioned in point (3) above. jitendra ",not-ak
986,"Re: [VOTE] Merging branch HDFS-7240 to trunk Anu, Jing, Nicholas, Sanjay, Jitendra and many others, thank you for staying focused on this effort. It has been almost 3.5 years since HDFS-7240 was created and all of the work has happened over the years in the open in the feature branch. Storage layer improvements from HDFS-7240 is important not only for scalability but also enabling flexibility for new innovations. One of the challenges with HDFS is balancing the need for stability for the majority of the existing deployments with the need for newer features and enhancements. Both of these are current needs we see at Uber. A single storage layer with the right abstractions can enable new use cases beyond file system and avoid siloes of storages to simplify management. HDSL and storage container abstraction is the architectural foundation toward that future. My main concerns with the merge is the stability impact on existing HDFS users. It needs to be a priority for the project. The modular approach taken to ensure the clean separation of code and dependencies addresses that concern. I am +1 (binding) on merging HDFS-7240 to HDFS repository. ",property
987,"Re: [VOTE] Merging branch HDFS-7240 to trunk Hi Sanjay, thanks for the response, replying inline: - NN on top HDSL where the NN uses the new block layer (Both Daryn and Owen HDFS? separately from HDSL. I'd be interested to learn more about the performance and other improvements from this new engine. Why isn't this possible with two processes? SCR for instance securely passes file descriptors between the DN and client over a unix domain socket. I'm sure we can construct a protocol that securely and efficiently creates hardlinks. It also sounds like this shallow copy won't work with features like HDFS encryption or erasure coding, which diminishes its utility. We also don't even have HDFS-to-HDFS shallow copy yet, so HDFS-to-Ozone shallow copy is even further out. Best, Andrew",not-ak
988,"Re: [VOTE] Merging branch HDFS-7240 to trunk Hi Owen, Wangda, Thanks for clearly laying out the subproject options, that helps the discussion. I'm all onboard with the idea of regular releases, and it's something I tried to do with the 3.0 alphas and betas. The problem though isn't a lack of commitment from feature developers like Sanjay or Jitendra; far from it! I think every feature developer makes a reasonable effort to test their code before it's merged. Yet, my experience as an RM is that more code comes with more risk. I don't believe that Ozone is special or different in this regard. It comes with a maintenance cost, not a maintenance benefit. I'm advocating for #3: separate source, separate release. Since HDSL stability and FSN/BM refactoring are still a ways out, I don't want to incur a maintenance cost now. I sympathize with the sentiment that working cross-repo is harder than within same repo, but the right tooling can make this a lot easier (e.g. git submodule, Google's repo tool). We have experience doing this internally here at Cloudera, and I'm happy to share knowledge and possibly code. Best, Andrew ",executive
989,"Re: [VOTE] Merging branch HDFS-7240 to trunk Andrew Thanks for your response. In this email let me focus on maintenance and unnecessary impact on HDFS. Daryn also touched on this topic and looked at the code base from the developer impact point of view. He appreciated that the code is separate and I agree with his suggestion to move it further up the src tree (e.g. Hadoop-hdsl-project or hadoop-hdfs-project/hadoop-hdsl). He also gave a good analogy to the store: do not break things as you change and evolve the store. Let�s look at the areas of future interaction as examples. - NN on top HDSL where the NN uses the new block layer (Both Daryn and Owen acknowledge the benefit of the new block layer). We have two choices here ** a) Evolve NN so that it can interact with both old and new block layer, ** b) Fork and create new NN that works only with new block layer, the old NN will continue to work with old block layer. There are trade-offs but clearly the 2nd option has least impact on the old HDFS code. - Share the HDSL�s netty protocol engine with HDFS block layer. After HDSL and Ozone has stabilized the engine, put the new netty engine in either HDFS or in Hadoop common - HDSL will use it from there. The HDFS community has been talking about moving to better thread model for HDFS DNs since release 0.16!! - Shallow copy. Here HDSL needs a way to get the actual linux file system links - HDFS block layer needs to provide a private secure API to get file names of blocks so that HDSL can do a hard link (hence shallow copy)o The first 2 examples are beneficial to existing HDFS and the maintenance burden can be minimized and worth the benefits (2x NN scalability!! And more efficient protocol engine). The 3rd is only beneficial to HDFS users who want the scalability of the new HDSL/Ozone code in a side-by-side system; here the cost is providing a private API to access the block file name. sanjay --------------------------------------------------------------------- To unsubscribe, e-mail: mapreduce-dev-unsubscribe@hadoop.apache.org For additional commands, e-mail: mapreduce-dev-help@hadoop.apache.org",not-ak
990,"Re: [VOTE] Merging branch HDFS-7240 to trunk Hi Owen, Thanks for the comments. I have merged trunk to HDFS-7240 branch. Hopefully, this makes it easy to look at the changes; I have committed the change required to fix the conflict as a separate commit to make it easy for you to see. Thanks Anu On 3/2/18, 4:42 PM, ""Wangda Tan"" wrote: I like the idea of same source / same release and put Ozone's source under a different directory. Like Owen mentioned, It gonna be important for all parties to keep a regular and shorter release cycle for Hadoop, e.g. 3-4 months between minor releases. Users can try features and give feedbacks to stabilize feature earlier; developers can be happier since efforts will be consumed by users soon after features get merged. In addition to this, if features merged to trunk after reasonable tests/review, Andrew's concern may not be a problem anymore: bq. Finally, I earnestly believe that Ozone/HDSL itself would benefit from being a separate project. Ozone could release faster and iterate more quickly if it wasn't hampered by Hadoop's release schedule and security and compatibility requirements. Thanks, Wangda ",not-ak
991,"Re: [VOTE] Merging branch HDFS-7240 to trunk I like the idea of same source / same release and put Ozone's source under a different directory. Like Owen mentioned, It gonna be important for all parties to keep a regular and shorter release cycle for Hadoop, e.g. 3-4 months between minor releases. Users can try features and give feedbacks to stabilize feature earlier; developers can be happier since efforts will be consumed by users soon after features get merged. In addition to this, if features merged to trunk after reasonable tests/review, Andrew's concern may not be a problem anymore: bq. Finally, I earnestly believe that Ozone/HDSL itself would benefit from being a separate project. Ozone could release faster and iterate more quickly if it wasn't hampered by Hadoop's release schedule and security and compatibility requirements. Thanks, Wangda ",executive
992,Re: [VOTE] Merging branch HDFS-7240 to trunk ,executive
993,"Re: [VOTE] Merging branch HDFS-7240 to trunk Hi Sanjay, I have different opinions about what's important and how to eventually integrate this code, and that's not because I'm ""conveniently ignoring"" your responses. I'm also not making some of the arguments you claim I am making. Attacking arguments I'm not making is not going to change my mind, so let's bring it back to the arguments I am making. Here's what it comes down to: HDFS-on-HDSL is not going to be ready in the near-term, and it comes with a maintenance cost. I did read the proposal on HDFS-10419 and I understood that HDFS-on-HDSL integration does not necessarily require a lock split. However, there still needs to be refactoring to clearly define the FSN and BM interfaces and make the BM pluggable so HDSL can be swapped in. This is a major undertaking and risky. We did a similar refactoring in 2.x which made backports hard and introduced bugs. I don't think we should have done this in a minor release. Furthermore, I don't know what your expectation is on how long it will take to stabilize HDSL, but this horizon for other storage systems is typically measured in years rather than months. Both of these feel like Hadoop 4 items: a ways out yet. Moving on, there is a non-trivial maintenance cost to having this new code in the code base. Ozone bugs become our bugs. Ozone dependencies become our dependencies. Ozone's security flaws are our security flaws. All of this negatively affects our already lumbering release schedule, and thus our ability to deliver and iterate on the features we're already trying to ship. Even if Ozone is separate and off by default, this is still a large amount of code that comes with a large maintenance cost. I don't want to incur this cost when the benefit is still a ways out. We disagree on the necessity of sharing a repo and sharing operational behaviors. Libraries exist as a method for sharing code. HDFS also hardly has a monopoly on intermediating storage today. Disks are shared with MR shuffle, Spark/Impala spill, log output, Kudu, Kafka, etc. Operationally we've made this work. Having Ozone/HDSL in a separate process can even be seen as an operational advantage since it's isolated. I firmly believe that we can solve any implementation issues even with separate processes. This is why I asked about making this a separate project. Given that these two efforts (HDSL stabilization and NN refactoring) are a ways out, the best way to get Ozone/HDSL in the hands of users today is to release it as its own project. Owen mentioned making a Hadoop subproject; we'd have to hash out what exactly this means (I assume a separate repo still managed by the Hadoop project), but I think we could make this work if it's more attractive than incubation or a new TLP. I'm excited about the possibilities of both HDSL and the NN refactoring in ensuring a future for HDFS for years to come. A pluggable block manager would also let us experiment with things like HDFS-on-S3, increasingly important in a cloud-centric world. CBlock would bring HDFS to new usecases around generic container workloads. However, given the timeline for completing these efforts, now is not the time to merge. Best, Andrew ",executive
994,"Re: [VOTE] Merging branch HDFS-7240 to trunk I�m generally neutral and looked foremost at developer impact. Ie. Will it be so intertwined with hdfs that each project risks destabilizing the other? Will developers with no expertise in ozone will be impeded? I think the answer is currently no. These are the intersections and some concerns based on the assumption ozone is accepted into the project: Common Appear to be a number of superfluous changes. The conf servlet must not be polluted with specific references and logic for ozone. We don�t create dependencies from common to hdfs, mapred, yarn, hive, etc. Common must be �ozone free�. Datanode I expected ozone changes to be intricately linked with the existing blocks map, dataset, volume, etc. Thankfully it�s not. As an independent service, the DN should not be polluted with specific references to ozone. If ozone is in the project, the DN should have a generic plugin interface conceptually similar to the NM aux services. Namenode No impact, currently, but certainly will be� Code Location I don�t feel hadoop-hdfs-project/hadoop-hdfs is an acceptable location. I�d rather see hadoop-hdfs-project/hadoop-hdsl, or even better hadoop-hdsl-project. This clean separation will make it easier to later spin off or pull in depending on which way we vote. Dependencies Owen hit upon his before I could send. Hadoop is already bursting with dependencies, I hope this doesn�t pull in a lot more. �� Do I think ozone be should be a separate project? If we view it only as a competing filesystem, then clearly yes. If it�s a low risk evolutionary step with near-term benefits, no, we want to keep it close and help it evolve. I think ozone/hdsl/whatever has been poorly marketed and an umbrella term for too many technologies that should perhaps be split. I'm interested in the container block management. I have little interest at this time in the key store. The usability of ozone, specifically container management, is unclear to me. It lacks basic features like changing replication factors, append, a migration path, security, etc - I know there are good plans for all of it - yet another goal is splicing into the NN. That�s a lot of high priority items to tackle that need to be carefully orchestrated before contemplating BM replacement. Each of those is a non-starter for (my) production environment. We need to make sure we can reach a consensus on the block level functionality before rushing it into the NN. That�s independent of whether allowing it into the project. The BM/SCM changes to the NN are realistically going to be contentious & destabilizing. If done correctly, the BM separation will be a big win for the NN. If ozone is out, by necessity interfaces will need to be stable and well-defined but we won�t get that right for a long time. Interface and logic changes that break the other will be difficult to coordinate and we�ll likely veto changes that impact the other. If ozone is in, we can hopefully synchronize the changes with less friction, but it greatly increases the chances of developers riddling the NN with hacks and/or ozone specific logic that makes it even more brittle. I will note we need to be vigilant against pervasive conditionals (ie. EC, snapshots). In either case, I think ozone must agree to not impede current hdfs work. I�ll compare to hdfs is a store owner that plans to maybe retire in 5 years. A potential new owner (ozone) is lined up and hdfs graciously gives them no-rent space (the DN). Precondition is help improve the store. Don�t make a mess and expect hdfs to clean it up. Don�t make renovations that complicate hdfs but ignore it due to anticipation of its departure/demise. I�m not implying that�s currently happening, it�s just what I don�t want to see. We as a community and our customers need an evolution, not a revolution, and definitively not a civil war. Hdfs has too much legacy code rot that is hard to change. Too many poorly implemented features. Perhaps I�m overly optimistic that freshly redesigned code can counterbalance performance degradations in the NN. I�m also reluctant, but realize it is being driven by some hdfs veterans that know/understand historical hdfs design strengths and flaws. If the initially cited issues are addressed, I�m +0.5 for the concept of bringing in ozone if it's not going to be a proverbial bull in the china shop. Daryn ",not-ak
995,"Re: [VOTE] Merging branch HDFS-7240 to trunk I think it would be good to get this in sooner rather than later, but I have some thoughts. 1. It is hard to tell what has changed. git rebase -i tells me the branch has 722 commits. The rebase failed with a conflict. It would really help if you rebased to current trunk. 2. I think Ozone would be a good Hadoop subproject, but it should be outside of HDFS. 3. CBlock, which is also coming in this merge, would benefit from more separation from HDFS. 4. What are the new transitive dependencies that Ozone, HDSL, and CBlock adding to the clients? The servers matter too, but the client dependencies have a huge impact on our users. 5. Have you checked the new dependencies for compatibility with ASL? ",not-ak
996,"Re: [VOTE] Merging branch HDFS-7240 to trunk Oops, retrying now subscribed to more than solely yarn-dev. -Clay On Wed, 28 Feb 2018, Clay B. wrote: --------------------------------------------------------------------- To unsubscribe, e-mail: mapreduce-dev-unsubscribe@hadoop.apache.org For additional commands, e-mail: mapreduce-dev-help@hadoop.apache.org",not-ak
997,"Re: [VOTE] Merging branch HDFS-7240 to trunk +1 (non-binding) I have walked through the code and find it very compelling as a user; I really look forward to seeing the Ozone code mature and it maturing HDFS features together. The points which excite me as an eight year HDFS user are: * Excitement for making the datanode a storage technology container - this patch clearly brings fresh thought to HDFS keeping it from growing stale * Ability to build upon a shared storage infrastructure for diverse loads: I do not want to have ""stranded"" storage capacity or have to manage competing storage systems on the same disks (and further I want the metrics datanodes can provide me today, so I do not have to instrument two systems or evolve their instrumentation separately). * Looking forward to supporting object-sized files! * Moves HDFS in the right direction to test out new block management techniques for scaling HDFS. I am really excited to see the raft integration; I hope it opens a new era in Hadoop matching modern systems design with new consistency and replication options in our ever distributed ecosystem. -Clay On Mon, 26 Feb 2018, Jitendra Pandey wrote: --------------------------------------------------------------------- To unsubscribe, e-mail: yarn-dev-unsubscribe@hadoop.apache.org For additional commands, e-mail: yarn-dev-help@hadoop.apache.org",not-ak
998,"Re: [VOTE] Merging branch HDFS-7240 to trunk Andrew, thanks for your response. 1) Wrt to NN on top of HDSL. You raised the issue of FSN lock separation . This was a key issue we discussed heavily in the past in the context of �Show the community a way to connect NN into the the new block layer�. We heard you clearly and thought deeply and showed how NN can be put on top of WITHOUT removing the FSN. We described this in detail in HDFS-10419 and also in the summary of the DISCUSSION thread: ---- Milestone 1 (no removal of FSN) gives almost 2x scalability and does not require separation of FSN lock and that milestone 2 which removes the FSN lock gives 2x scalability. You have conveniently ignored this. Let me reemphasize: Removing the FSN lock is not necessary for NN/HDFS to benefit from HDSL and you get almost the same scalability benefit. Hence the FSN local issue is moot. 2) You have also conveniently ignored our arguments that there is benefit in keeping HDSL and HDFS together that are in the vote and discussion thread summary: A) Side by side usage and resulting operational concerns B) Sharing code 3) You argue for separate project from 2 conflicting arguments: (1) Separate then merge later, what�s the hurry. (2) keep seperate and focus on non-HDFS storage use cases. The HDFS community members built HDSL to address HDFS scalability; they were not trying go after object store users or market (ceph etc). As explained multiple times OzoneFS is an intermediate step to stabilize HDSL but of immediate value for apps such as Hive and Spark. So even if there might be value in being separate (your motivation 2) and go after a new storage use cases, the HDFS community members that built HDSL want to focus on improving HDFS; you may not agree with that but the engineers that are writing the code should be able to drive the direction. Further look at the Security design we posted - shows a Hadoop/HDFS focus not a focus for some other object store market: it fits into the Hadoop security model, especially supporting the use case of Jobs and the resulting need to support delegation tokens. 4) You argue that the HDSL and OzoneFS modules are separate and therefore one should go as a separate project. * Looks like one can�t win here. Damned if you do and Damned if you don�t. In the discussion with the Cloudera team one of the issues raised was that there a lot of new code and it will destabilized HDFS. We explained that we have kept the code in separate modules so that it will not impact current HDFS stability, and that features like HDSL�s new protocol engine will be plugged into the old HDFS block layer only after stabilization. You argue for stability and hence separate modules and then use it against to push it out as a separate project. sanjay --------------------------------------------------------------------- To unsubscribe, e-mail: mapreduce-dev-unsubscribe@hadoop.apache.org For additional commands, e-mail: mapreduce-dev-help@hadoop.apache.org",existence
999,"Re: [VOTE] Merging branch HDFS-7240 to trunk Resending since the formatting was messed up, let's try plain text this time: Hi Jitendra and all, Thanks for putting this together. I caught up on the discussion on JIRA and document at HDFS-10419, and still have the same concerns raised earlier about merging the Ozone branch to trunk. To recap these questions/concerns at a very high level: * Wouldn't Ozone benefit from being a separate project? * Why should it be merged now? I still believe that both Ozone and Hadoop would benefit from Ozone being a separate project, and that there is no pressing reason to merge Ozone/HDSL now. The primary reason I've heard for merging is that the Ozone is that it's at a stage where it's ready for user feedback. Second, that it needs to be merged to start on the NN refactoring for HDFS-on-HDSL. First, without HDFS-on-HDSL support, users are testing against the Ozone object storage interface. Ozone and HDSL themselves are implemented as separate masters and new functionality bolted onto the datanode. It also doesn't look like HDFS in terms of API or featureset; yes, it speaks FileSystem, but so do many out-of-tree storage systems like S3, Ceph, Swift, ADLS etc. Ozone/HDSL does not support popular HDFS features like erasure coding, encryption, high-availability, snapshots, hflush/hsync (and thus HBase), or APIs like WebHDFS or NFS. This means that Ozone feels like a new, different system that could reasonably be deployed and tested separately from HDFS. It's unlikely to replace many of today's HDFS deployments, and from what I understand, Ozone was not designed to do this. Second, the NameNode refactoring for HDFS-on-HDSL by itself is a major undertaking. The discussion on HDFS-10419 is still ongoing so it�s not clear what the ultimate refactoring will be, but I do know that the earlier FSN/BM refactoring during 2.x was very painful (introducing new bugs and making backports difficult) and probably should have been deferred to a new major release instead. I think this refactoring is important for the long-term maintainability of the NN and worth pursuing, but as a Hadoop 4.0 item. Merging HDSL is also not a prerequisite for starting this refactoring. Really, I see the refactoring as the prerequisite for HDFS-on-HDSL to be possible. Finally, I earnestly believe that Ozone/HDSL itself would benefit from being a separate project. Ozone could release faster and iterate more quickly if it wasn't hampered by Hadoop's release schedule and security and compatibility requirements. There are also publicity and community benefits; it's an opportunity to build a community focused on the novel capabilities and architectural choices of Ozone/HDSL. There are examples of other projects that were ""incubated"" on a branch in the Hadoop repo before being spun off to great success. In conclusion, I'd like to see Ozone succeeding and thriving as a separate project. Meanwhile, we can work on the HDFS refactoring required to separate the FSN and BM and make it pluggable. At that point (likely in the Hadoop 4 timeframe), we'll be ready to pursue HDFS-on-HDSL integration. Best, Andrew ",existence
1000,"Re: [VOTE] Merging branch HDFS-7240 to trunk *Hi Jitendra and all,Thanks for putting this together. I caught up on the discussion on JIRA and document at HDFS-10419, and still have the same concerns raised earlier about merging the Ozone branch to trunk.To recap these questions/concerns at a very high level:* Wouldn't Ozone benefit from being a separate project?* Why should it be merged now?I still believe that both Ozone and Hadoop would benefit from Ozone being a separate project, and that there is no pressing reason to merge Ozone/HDSL now.The primary reason I've heard for merging is that the Ozone is that it's at a stage where it's ready for user feedback. Second, that it needs to be merged to start on the NN refactoring for HDFS-on-HDSL.First, without HDFS-on-HDSL support, users are testing against the Ozone object storage interface. Ozone and HDSL themselves are implemented as separate masters and new functionality bolted onto the datanode. It also doesn't look like HDFS in terms of API or featureset; yes, it speaks FileSystem, but so do many out-of-tree storage systems like S3, Ceph, Swift, ADLS etc. Ozone/HDSL does not support popular HDFS features like erasure coding, encryption, high-availability, snapshots, hflush/hsync (and thus HBase), or APIs like WebHDFS or NFS. This means that Ozone feels like a new, different system that could reasonably be deployed and tested separately from HDFS. It's unlikely to replace many of today's HDFS deployments, and from what I understand, Ozone was not designed to do this.Second, the NameNode refactoring for HDFS-on-HDSL by itself is a major undertaking. The discussion on HDFS-10419 is still ongoing so it�s not clear what the ultimate refactoring will be, but I do know that the earlier FSN/BM refactoring during 2.x was very painful (introducing new bugs and making backports difficult) and probably should have been deferred to a new major release instead. I think this refactoring is important for the long-term maintainability of the NN and worth pursuing, but as a Hadoop 4.0 item. Merging HDSL is also not a prerequisite for starting this refactoring. Really, I see the refactoring as the prerequisite for HDFS-on-HDSL to be possible.Finally, I earnestly believe that Ozone/HDSL itself would benefit from being a separate project. Ozone could release faster and iterate more quickly if it wasn't hampered by Hadoop's release schedule and security and compatibility requirements. There are also publicity and community benefits; it's an opportunity to build a community focused on the novel capabilities and architectural choices of Ozone/HDSL. There are examples of other projects that were ""incubated"" on a branch in the Hadoop repo before being spun off to great success.In conclusion, I'd like to see Ozone succeeding and thriving as a separate project. Meanwhile, we can work on the HDFS refactoring required to separate the FSN and BM and make it pluggable. At that point (likely in the Hadoop 4 timeframe), we'll be ready to pursue HDFS-on-HDSL integration.* Best, Andrew ",not-ak
1001,"[VOTE] Merging branch HDFS-7240 to trunk Dear folks, We would like to start a vote to merge HDFS-7240 branch into trunk. The context can be reviewed in the DISCUSSION thread, and in the jiras (See references below). HDFS-7240 introduces Hadoop Distributed Storage Layer (HDSL), which is a distributed, replicated block layer. The old HDFS namespace and NN can be connected to this new block layer as we have described in HDFS-10419. We also introduce a key-value namespace called Ozone built on HDSL. The code is in a separate module and is turned off by default. In a secure setup, HDSL and Ozone daemons cannot be started. The detailed documentation is available at https://cwiki.apache.org/confluence/display/HADOOP/Hadoop+Distributed+Storage+Layer+and+Applications I will start with my vote. +1 (binding) Discussion Thread: https://s.apache.org/7240-merge https://s.apache.org/4sfU Jiras: https://issues.apache.org/jira/browse/HDFS-7240 https://issues.apache.org/jira/browse/HDFS-10419 https://issues.apache.org/jira/browse/HDFS-13074 https://issues.apache.org/jira/browse/HDFS-13180 Thanks jitendra DISCUSSION THREAD SUMMARY : On 2/13/18, 6:28 PM, ""sanjay Radia"" wrote: Sorry the formatting got messed by my email client. Here it is again Dear Hadoop Community Members, We had multiple community discussions, a few meetings in smaller groups and also jira discussions with respect to this thread. We express our gratitude for participation and valuable comments. The key questions raised were following 1) How the new block storage layer and OzoneFS benefit HDFS and we were asked to chalk out a roadmap towards the goal of a scalable namenode working with the new storage layer 2) We were asked to provide a security design 3)There were questions around stability given ozone brings in a large body of code. 4) Why can�t they be separate projects forever or merged in when production ready? We have responded to all the above questions with detailed explanations and answers on the jira as well as in the discussions. We believe that should sufficiently address community�s concerns. Please see the summary below: 1) The new code base benefits HDFS scaling and a roadmap has been provided. Summary: - New block storage layer addresses the scalability of the block layer. We have shown how existing NN can be connected to the new block layer and its benefits. We have shown 2 milestones, 1st milestone is much simpler than 2nd milestone while giving almost the same scaling benefits. Originally we had proposed simply milestone 2 and the community felt that removing the FSN/BM lock was was a fair amount of work and a simpler solution would be useful - We provide a new K-V namespace called Ozone FS with FileSystem/FileContext plugins to allow the users to use the new system. BTW Hive and Spark work very well on KV-namespaces on the cloud. This will facilitate stabilizing the new block layer. - The new block layer has a new netty based protocol engine in the Datanode which, when stabilized, can be used by the old hdfs block layer. See details below on sharing of code. 2) Stability impact on the existing HDFS code base and code separation. The new block layer and the OzoneFS are in modules that are separate from old HDFS code - currently there are no calls from HDFS into Ozone except for DN starting the new block layer module if configured to do so. It does not add instability (the instability argument has been raised many times). Over time as we share code, we will ensure that the old HDFS continues to remains stable. (for example we plan to stabilize the new netty based protocol engine in the new block layer before sharing it with HDFS�s old block layer) 3) In the short term and medium term, the new system and HDFS will be used side-by-side by users. Side by-side usage in the short term for testing and side-by-side in the medium term for actual production use till the new system has feature parity with old HDFS. During this time, sharing the DN daemon and admin functions between the two systems is operationally important: - Sharing DN daemon to avoid additional operational daemon lifecycle management - Common decommissioning of the daemon and DN: One place to decommission for a node and its storage. - Replacing failed disks and internal balancing capacity across disks - this needs to be done for both the current HDFS blocks and the new block-layer blocks. - Balancer: we would like use the same balancer and provide a common way to balance and common management of the bandwidth used for balancing - Security configuration setup - reuse existing set up for DNs rather then a new one for an independent cluster. 4) Need to easily share the block layer code between the two systems when used side-by-side. Areas where sharing code is desired over time: - Sharing new block layer�s new netty based protocol engine for old HDFS DNs (a long time sore issue for HDFS block layer). - Shallow data copy from old system to new system is practical only if within same project and daemon otherwise have to deal with security setting and coordinations across daemons. Shallow copy is useful as customer migrate from old to new. - Shared disk scheduling in the future and in the short term have a single round robin rather than independent round robins. While sharing code across projects is technically possible (anything is possible in software), it is significantly harder typically requiring cleaner public apis etc. Sharing within a project though internal APIs is often simpler (such as the protocol engine that we want to share). 5) Security design, including a threat model and and the solution has been posted. 6) Temporary Separation and merge later: Several of the comments in the jira have argued that we temporarily separate the two code bases for now and then later merge them when the new code is stable: - If there is agreement to merge later, why bother separating now - there needs to be to be good reasons to separate now. We have addressed the stability and separation of the new code from existing above. - Merge the new code back into HDFS later will be harder. **The code and goals will diverge further. ** We will be taking on extra work to split and then take extra work to merge. ** The issues raised today will be raised all the same then. --------------------------------------------------------------------- To unsubscribe, e-mail: hdfs-dev-unsubscribe@hadoop.apache.org For additional commands, e-mail: hdfs-dev-help@hadoop.apache.org --------------------------------------------------------------------- To unsubscribe, e-ma",property
1271,Re: Proposal - 3.5.1 ,not-ak
1272,Re: Proposal - 3.5.1 ,not-ak
1273,"Re: Proposal - 3.5.1 If you all have never seen the movie ""grandma's boy"" I suggest it. https://www.youtube.com/watch?v=uJLQ5DHmw-U There is one funny seen where the product/project person says something like, ""The game is ready. We have fixed ALL THE BUGS"". The people who made the movie probably think the coders doing dance dance revolution is funny. To me the funniest part of the movie is the summary statement that ""all the bugs are fixed"". I agree with Sylvain, that cutting branches really has nothing to do with ""quality"". Quality like ""production ready"" is hard to define. I am phrasing this next part as questions to encourage deep thought not to be a jerk. Someone jokingly said said 3.0 was the ""break everything"" release. What if 4.0 was the ""fix everything"" release? What would that mean? What would we need? No new features for 6 months? A vast network of amazon machines to test things? Jepsen ++? 24 hour integration tests that run CAS operations across a multi-node mixed version cluster while we chaos monkey nodes? Could we keep busy for 6 months just looking at the code and fix all the bugs for Mr. Cheezle? Could we fix ALL THE BUGS and then from that day it is just feature, feature, feature? We sit there and join and unjoin nodes for 2 days while running stress and at the end use the map reduce export and prove that not a single datum was lost? ",not-ak
1274,Re: Proposal - 3.5.1 ,not-ak
1275,"Re: Proposal - 3.5.1 Yep - the progress that's been made on trunk recently has been excellent and should continue. The spirit of tick tock - stable trunk - should not change, just that the release cycle did not support what humans are comfortable with maintaining or deploying. ",not-ak
1276,Re: Proposal - 3.5.1 ,not-ak
1277,"Re: Proposal - 3.5.1 �I'm not even sure it's reasonable to� expect from *any* software, and even less so for an open-source� project based on volunteering. Not saying it wouldn't be amazing, it� would, I just don't believe it's realistic. Postgres does a pretty good job of this. This sort of thinking is a self fulfilling prophecy imo. Clearly, we won�t get to this point right away, but it should definitely be a goal. On September 16, 2016 at 9:04:03 AM, Sylvain Lebresne (sylvain@datastax.com) wrote: ",not-ak
1278,"Re: Proposal - 3.5.1 What I was trying to suggest is that the *goal* of trunk should always be releasable, and the alpha releases would be the means of testing that. If the goal is to always be releasable, we move towards achieving that goal by improving modularity, test coverage and test granularity. Yes, it's very difficult to prove a piece of software is completely free of bugs and I wouldn't expect NASA to put Cassandra on the space shuttle. That said, by prioritizing stability in the software development process up front, the cost of maintaining older branches over time will decrease and the velocity of the project will increase - which was the original goal of Tick Tock. Jon ",not-ak
1279,Re: Proposal - 3.5.1 ,not-ak
1280,Re: Proposal - 3.5.1 ,not-ak
1281,"Re: Proposal - 3.5.1 ""The historical trend with the Cassandra codebase has been to test minimally, throw the code over the wall, and get feedback from people putting it in prod who run into issues."" At the summit Brandon and a couple others were making fun over range tombstones from thrift https://issues.apache.org/jira/browse/CASSANDRA-5435 I added the thrift support based on code already in trunk. But there was something ugly bit in there and far on down the line someone else stuck with an edge case and had to fix it. Now, I actually added a number of tests, unit test, and nosetests. I am sure the range tombstones also had their own set of tests at the storage level. So as Brandon was making fun of me, I was thinking to myself, ""Well I did not make the bug, I just made it possible for others to find it! So I am helping!"" The next time I submit a thrift patch I am going to write 5x the unit tests jk :) ",not-ak
1282,"Re: Proposal - 3.5.1 Sorry, in my TL;DR I forgot release frequent alphas (nightly / weekly / whatever schedule you want) ",not-ak
1283,"Re: Proposal - 3.5.1 I've worked on a few projects where we've had a branch that new stuff went in before merging to master / trunk. What you've described reminds me a lot of git-flow (http://nvie.com/posts/a-successful-git-branching-model/) although not quite the same. I'll be verbose in this email to minimize the reader's assumptions. The goals of the release cycle should be (in descending order of priority): 1. Minimize bugs introduced through change 2. Allow the codebase to iterate quickly 3. Not get caught up in a ton of back porting bug fixes There is significant benefit to having a releasable trunk. This is different from a trunk which is constantly released. A releasable trunk simply means all tests should *always* pass and PMC & committers should feel confident that they could actually put it in prod for a project that actually matters. Having it always be releasable (all tests pass, etc) means people can at least test the DB on sample data or evaluate it before the release happens, and get feedback to the team when there are bugs. This is a different mentality from having a ""features"" branch, where it's implied that at times it's acceptable that it not be stable. The historical trend with the Cassandra codebase has been to test minimally, throw the code over the wall, and get feedback from people putting it in prod who run into issues. In my experience I have found a general purpose ""features"" branch to result in poorly quality codebases. It's shares a lot of the same problems as the 1+ year release cycle did previously, with things getting merged in and then an attempt to stabilize later. Improving the state of testing in trunk will catch more bugs, satisfying #1, which naturally leads to #2, and by reducing bugs before they get released #3 will happen over time. My suggestion for a *supported* feature release every 3 months (could just as well be 4 or 6) mixed with Benedict's idea of frequent non-supported releases (tagged as alpha). Supported releases should get ~6 months worth of bug fixes, which if done right, will decrease over time due to a hopefully more stable codebase. I 100% agree with Mick that semver makes sense here, it's not just for frameworks. Major.Minor.Patch is well understood and is pretty standard throughout the world, I don't think we need to reinvent versioning. TL;DR: Release every 3 months Support for 6 Keep a stable trunk New features get merged into trunk but the standard for code quality and testing needs to be property defined as something closer to ""production ready"" rather than ""let the poor user figure it out"" Jon ",executive
1284,"Re: Proposal - 3.5.1 As probably pretty much everyone at this point, I agree the tick-tock experiment isn't working as well as it should and that it's probably worth course correcting. I happen to have been thinking about this quite a bit already as it turns out so I'm going to share my reasoning and suggestion below, even though it's going to be pretty long, in the hope it can be useful (and if it isn't, so be it). My current thinking is that a good cycle should accommodate 2 main constraints: 1) be useful for users 2) be realistic/limit friction on the development side and let me develop what I mean by both points slightly first. I think users mostly want 2 things out of the release schedule: they want a clearly labeled stable branch to know what they should run into production, and they want new features and improvements. Let me clarify that different users will want those 2 in different degrees and with variation over time, but I believe it's mainly some combination of those. On the development side, I don't think it's realistic to expect more than 2/3 branches/series to be supported at any one time (not going to argue that, let's call it a professional opinion). I also think accumulating new work for any meaningful length of time before releasing, as we used to do, is bad as it pushes devs to rush things to meet a given release deadline as they don't want to wait for the next one. This in turn impacts quality and creates unnecessary drama. It's also good imo to have a clear policy regarding where a given work can go (having to debate on each ticket on which branch it should go is a waste of dev time). With those ""goals"" in mind, I'll note that: - the fixed _and_ short cadence of tick-tock is imo very good, in particular in (but not limited to) avoiding the 'accumulate unreleased stuffs' problem. - we have ample evidence that stuffs don't get truly stable until they get only bug fixes for a few months. Which doesn't mean at all that we shouldn't continue to make progress on increasing the quality of new code btw. - Simple is also a great quality of a release cycle. I think we should try to define what's truly important to achieve (my opinion on that is above) and do the simplest thing that achieve that. This does imply the release cycle won't make the coffee, but that's alright, it probably shouldn't anyway. In light of all this, my suggesting for a release cycle woud be: - To have 3 branches: 'features', 'testing' and 'stable', with an X month rotation: 'features' becomes 'testing' after X months and then 'stable' after X more, before getting EOL X months later. - The feature branch gets everything. The testing branch only gets bug fixes. The stable branch only gets critical bug fixes. And imo, we should be very strict on this (I acknowledge that there is sometimes a bit of subjectivity on whether something is a bug or an improvement, and if it's critical or not, but I think it's not that hard to get consensus if we're all reasonable (though it might worth agreeing on some rough but written guideline upfront)). - We release on a short and fixed cadence of Y month(s) for both the feature and testing branch. For the stable branch, given that it already had X months of only bug fixes during the testing phase, one can hope critical fixes will be fairly rare, less than 1 per Y period on average). Further, it's supposed to be stable and fixes are supposed to be critical, so doing hot-fix releases probably makes the most sense (though it probably only work if we're indeed strict on what is considered critical). And that's about it. I think it would believably achieve stability (with a clear label on which releases are stable), but also provide new features and improvements quickly for those that wants that. The testing phase is imo a necessary intermediate step to get the stable one. On thing to define is X and Y. For Y (the cadence of feature/testing), I think 1 or 2 months are the only options that make sense (less than 1 month is too fast, and more than 2 months is imo starting to get too long). For X, that's more debatable but it's open-source and we should recognize volunteers generally don't want to maintain things for too long either. My 2 is that 6 or 8 months are probably the best options here. We'd also have to put some numbering scheme on top of that, but that's not really the important part (the meaning is in the branch labels, not the numbers). To give just one possible option (and assuming X=6, Y=1), in January 2017 we could cut 4.0 as the start of both 'feature' and 'testing'. We'd then have 4.1, 4.2, ... on the 'feature' branch, and 4.0.1, 4.0.2, ... on the testing branch for the next 6 months. In July, we'd switch from 4.5 to 5.0, with that becoming the new 'feature' and 'testing' base. At the same time, we'd cut 4.0.6 from 4.0.5 as the new 'stable' branch. Hot-fix on that stable branch would be versioned 4.0.6.1, 4.0.6.2 and so on. Of course, there can be variations on all this. We could have a different X and/or Y for the different branches to name just one. I'm just trying to abide by the ""simpler is better"" rule though. Lastly, I'll note that the versioning wouldn't use semver. I like semver alright but I think it's more suited to libraries than something like Cassandra. Amongst other things, it strongly rely on a fine grained notion of backward compatibility which I think is ill-defined for Cassandra in general. Sylvain ",executive
1285,"Re: Proposal - 3.5.1 Totally agree with all the frustrations felt by Jon here. TL;DR Here's a proposal for 4.0 and beyond: that is puts together the comments from Benedict, Jon, Tyler, Jeremy, and Ed; - keep bimonthly feature releases, - revert from tick-tock to SemVer numbering scheme, - during the release vote also vote on the quality label (feature branches start with a 'Alpha' and the first patch release as 'Beta'), - accept that every feature release isn't by default initially supported, and its branch might never be, - maintain 3 'GA' branches at any one time, - accept that it's not going to be the oldest GA branches that necessarily reach EOL first. Background and rationale� IMO the problem with Tick-Tock is that it introduces two separate concepts: - incremental development, and - limiting patch releases. The first concept: having bimonthly tocks; made C* development more incremental. A needed improvement. No coincidence, at the same time as tick-tock was introduced, there was also a lot of effort being put into testing and a QA framework. The second concept: having bimonthly ticks; limited C* to having only one patch release per tock release. The only real benefit to this was to reduce the effort involved in maintenance, required because of the more frequent tock releases. The consequence is instability has gone bananas, as Jon clearly demonstrates. Someone went and let the monkey out. A quick comparison of before to tick-tock: * Before tick-tock: against 6-12 months of development it took a time-frame of 3-6 months and 6+ patch releases to stabilise C*. * After tick-tock: against 2 months of development we could have expected the same time-frame of 3-6 months (because adoption is dictated by users, not developers) and *over* this period 1-2 patch releases to stabilise. It seemed to have been a fools errand to force this to 1 patch release after only one month. It seems that the notion of incremental development was applied for the developers where-as the waterfall model was applied to QA in production for the users. (note: all this is not taking into account advantages of incremental development, an improved QA framework, and a move towards a stable-master.) The question remains to how many of these releases can the community afford to support. And being realistic much of this effort relies upon the commercial entities around the community. For example having 1 year of support means having to support 6 feature releases, and there's probably not the people power to do that. It also means that in effect any release is actually only supported for 6-9 months, since it took 3-6 for it to get to production-ready. A typical Apache release process is that each new major release gets voted on as only 'Alpha' or 'Beta'. As patch releases are made it is ascertained whether enough people are using it (eg in production) and the quality label appropriately raised to either 'Beta' or 'GA'. The quality label can be proposed in the vote or left to be voted upon by everyone. The quality label is itself not part of the version number, so that the version number can follow strict SemVer. Then the community can say, for example, it supports 3 'GA' branches. This permits some major releases to never make it to GA, and others to hang over for a bit longer. It's something that the community gets a feel for by appreciating the users and actors around it. The number of branches supported depends on what the community can sustain (including the new non-GA branches). The community also becomes a bit more honest about the quality of x.y.0 releases. The proposal is an example that embraces incremental development and the release-often mentality, while keeping a realistic and flexible approach to how many branches can be supported. The cost of supporting branches is still very real, and pushing for a stable master means no feature branch is cut without passing everything in the QA framework and 100% belief that it can be put into a user's production. That is there's not a return to thinking about feature branches as a place for ongoing stabilisation efforts, just because they have a 'Alpha/Beta' label. The onus of work is put upon the developer having to maintain branches for features targeted for master, and not on the community having to stabilise and support feature branches. BTW has anyone figured out whether it's the tick or the tock that represents the feature release?? I probably got it wrong here :-) ~mck",executive
1286,"Re: Proposal - 3.5.1 It is funny you say this: ""tick-tock started based off of the 3.0 big bang �we broke everything� release"" *""Brain battles itself over short-term rewards, long-term goals""* https://www.princeton.edu/pr/news/04/q4/1014-brain.htm *Normalization of deviance in software: how broken practices become standard* https://news.ycombinator.com/item?id=10811822 I had something really long written. I summarized to this thought. Huge generalization coming: Group 1 ""I have 1GB of data on a 200GB disk, I am going to switch to level DB and see what happens. YOLO DB!"" v.s. Group 2 ""I have 60GB data on a 200GB disk, If i switch to level DB I have to do in a way that does not impact my current users, and a way that won't fill my disks, and doing this in a controlled way might take days"" Users gravitate toward Group 2 as they move they become more risk adverse. They are not going to want to upgrade more than twice a year. If they see risk they will not upgrade at all. If Group 2 is not upgrading all the ""testers"" become that of Group 1. I think a new metric systems would be fun. In the readme.txt TestAdded T DTestAdded D Feature F Fix B Ninja Fix N Refactor R Version 3.0 DDFFBBBBBBRRRRRTTTTDDDDDD Version 3.1 FBBBBBBBBBBRRRRTTDD Over time IF these did not gravitate toward FTD we know we are headed in the wrong direction. ",executive
1287,"Re: Proposal - 3.5.1 If the releases can be tagged as alpha / beta so that people don't accidentally put it in prod (or at least, will do so less), that would be totally reasonable. ",executive
1288,"Re: Proposal - 3.5.1 Yes, agreed. I'm advocating a different cadence, not a random cadence. On Thursday, 15 September 2016, Tyler Hobbs wrote:",not-ak
1289,"Re: Proposal - 3.5.1 On Thu, Sep 15, 2016 at 2:22 PM, Benedict Elliott Smith",executive
1290,"Re: Proposal - 3.5.1 Feature releases don't have to be on the same cadence as bug fixes. They're naturally different beasts. Why not stick with monthly feature releases, but mark every third (or sixth) as a supported release that gets quarterly updates for 2-3 quarters? On Thursday, 15 September 2016, Tyler Hobbs wrote:",not-ak
1291,"Re: Proposal - 3.5.1 I agree that regular (monthly) releases, and smaller, more frequent feature releases are the best part of tick/tock. The downside of tick/tock, as mentioned above, is that there isn't enough time for user feedback and testing to catch new bugs before the next feature release. I would personally like to see a hybrid. The proposal that Jon mentions of doing a new feature release every three months plus 6 months of bugfixes for any release seems like like a good balance to me. ",executive
1292,"Re: Proposal - 3.5.1 Right - I think like Jake and others have said, it seems appropriate to do something at this point. Would a clearer, more liberal backport policy to the odd versions be worthwhile until we find our footing? As Jeremiah said, it does seem like the big bang 3.0 release has caused much of the baggage that we�re facing. Combine with that the slow uptake on any specific version so far at least partly because of the newness of the release model. To me, the hard thing to me about 3 month releases is that then you get into the larger untested feature releases which is what it was originally supposed to get away from. So in essence, would we 1) do nothing and see it through 2) have a more liberal backport policy in the 3.x line and revisit once we get to 4 3) do a tick-tock(-tock-tock) sort of model 4) do some sort of LTS 5) go back to the drawing board 6) go back to the old model I think the earlier numbers imply some confidence in the thinking behind tick-tock. Would 2 be acceptable to see the 3.x line through with the current release model? Or do we need to do something more extensive at this stage?",not-ak
1293,"Re: Proposal - 3.5.1 I don't think it's binary - we don't have to do year long insanity or bleeding edge crazyness. How about a release every 3 months, with each release accepting 6 months of patches? (oldstable & newstable) Also provide nightly builds & stick to the idea of stable trunk. The issue is the number of bug fixes a given release gets. 1 bug fix release for a new feature is just terrible. The community as a whole despises this system and is lowering confidence in the project. Jon ",executive
1294,"Re: Proposal - 3.5.1 Because tick-tock started based off of the 3.0 big bang �we broke everything� release I don�t think we can judge wether or not it is working until we are another 6 months in. AKA when we would have been releasing the next big bang release. Right now a lot if not most of the bugs in a given tick tock release are bugs that were introduced in 3.0. Even the bug mentioned here, it is not a tick tock bug, it is a 3.0 bug.",not-ak
1295,"Re: Proposal - 3.5.1 I'm pretty sure everyone will agree Tick-Tock didn't go well and needs to change. The problem for me is going back to the old way doesn't sound great. There are parts of tick-tock I really like, for example, the cadence and limited scope per release. I know at the summit there were a lot of ideas thrown around I can regurgitate but perhaps people who have been thinking about this would like to chime in and present ideas? -Jake On Thu, Sep 15, 2016 at 2:28 PM, Benedict Elliott Smith <benedict@apache.org -- http://twitter.com/tjake",not-ak
1296,"Re: Proposal - 3.5.1 I agree tick-tock is a failure. But for two reasons IMO: 1) Ultimately, the users are the real testers and it takes a while for a release to percolate into the wild for feedback. The reality is that a release doesn't have its tires properly kicked for at least three months after it's cut. So if we are to have any tocks, they should be completely unwed from the ticks, and should probably happen on a ~3M cadence to keep the labour down but the utility up (and there should probably still be more than one tock per tick) 2) Those promised resources to improved process never happened. We haven't even reached parity with the 2.1 release until very recently, i.e. no failing u/dtests. On 15 September 2016 at 19:08, Jeff Jirsa wrote:",not-ak
1297,"Re: Proposal - 3.5.1 Just another user perspective from someone who manages many clusters: Tick-tock doesn't really make sense unless at some point you stop ticking. You can't expect to release features constantly and have a stable product every tock. Not unless you have really high development, code review, and testing standards. Even then you're probably dreaming, as it's impossible for any one person to have enough knowledge to account for every possible implication of a feature (or bug fix for that matter). It seriously doesn't work when people are only running tock releases because that's the obvious choice. In reality the majority of bug fixes in the latest tock release will not be bug fixes for the latest feature release. That is, 3.7 is likely to have more bug fixes from 3.4/5 features than 3.6, as hardly anyone would be running 3.6. And the 3.6 features may well have introduced bugs that don't get picked up until 3.7 is well used in production. I'll throw some ideas in that may warrant discussion so I'm not just some negative nancy: tick-tock-tock releases. How you version these would be questionable, I suppose to minimise confusion you could just jump even numbers for the second tock (e.g 3.4 -> 3.5 -> 3.7). It kind of keeps the same release cycle but at least users could be more confident in the latest tock release. However it still suffers from the flaw that 3.5 is unlikely to have bug fixes relevant to 3.4 features. Another alternative is to eventually stop ticking altogether, that is you may tick up until 3.6 but then only tock from then on, pushing all further features to the next major release. In this case after 6 months the features would stop and you'd have 6 months of only bugfixes. Users looking for stability can wait for 3.7 onwards, whilst risk takers and people in development phases can start on earlier releases. At most people would be waiting 7-8 months from the last version of the previous major before upgrading, with a year in total to get any new features (e.g 3.7 -> 4.7). As it stands at the moment I typically wouldn't recommend 3.x for critical production loads, and I've been telling people they're better off waiting for 3.9 or later assuming the number of new features introduced slows down. Also, in my opinion if you start going back to minor releases and backporting patches, you've defeated the purpose of tick-tock entirely and you may as well do away with it. I think you're better off marking those releases as unstable and pushing out a new ""stable"" release as fast as possible. This is obviously further complicated that the next logical release may be a tick, which has the risk of introducing new bugs, in which case I'd say if a critical fix is necessary you skip the tick. Just my 1c. On 15 September 2016 at 15:18, Edward Capriolo wrote: -- Kurt Greaves kurt@instaclustr.com www.instaclustr.com",executive
1298,"Re: Proposal - 3.5.1 It's worth noting more clearly that 3.5 is an arbitrary point in time. All 3.X releases < 3.6 are affected. If we backport to 3.5, it seems like 3.1 and 3.3 should get the same treatment. I do recall commitments to backport critical fixes, but exactly what the bar is was never well defined. I also cannot see how there would be any added confusion. On 15 September 2016 at 18:31, Dave Lester wrote:",not-ak
1299,"Re: Proposal - 3.5.1 How would cutting a 3.5.1 release possibly confuse users of the software? It would be easy to document the change and to send release notes. Given the bug�s critical nature and that it's a minor fix, I�m +1 (non-binding) to a new release. Dave",not-ak
1300,"Re: Proposal - 3.5.1 Where did we come from? We came from a place where we would say, ""You probably do not want to run 2.0.X until it reaches 2.0.6"" One thing about Cassandra is we get into a situation where we can only go forward. For example, when you update from version X to version Y, version Y might start writing a new versions of sstables. X - sstables-v1 Y - sstables-v2 This is very scary operations side because you can not bring the the system back to running version X as Y data is unreadable. Where are we at now? We now seem to be in a place where you say ""Problem in 3.5 (trunk at a given day)?, go to 3.9 (trunk at last tt- release) "" http://www.planetcassandra.org/blog/cassandra-2-2-3-0-and-beyond/ ""To get there, we are investing significant effort in making trunk �always releasable,� with the goal that each release, or at least each odd-numbered bugfix release, should be usable in production. "" I support releasable trunk, but the qualifying statement ""or at least each odd number release"" undoes the assertion of ""always releasable"". Not trying to nit pick here. I realize it may be hard to get to the desired state of releasable trunk in a short time. Anecdotally I notice a lot of ""movement"" in class names/names of functions. Generally, I can look at a stack trace of a piece of software and I can bring up the line number in github and it is dead on, or fairly close to the line of code. Recently I have tried this in versions fairly close together and seen some drastic changes. We know some things i personally do not like: 1) lack of stable-ish api's in the codebase 2) use of singletons rather than simple dependency injection (like even constructor based injection) IMHO these do not fit well with 'release often' and always produce 'high quality release'. I do not love the concept of 'bug fix release' I would not mind waiting longer for a feature as long as I could have a high trust factor in in working right the first time. Take a feature like trickle_fs, By the description it sounds like a clear optimization win. It is off by default. The description says ""turn on for ssd"" but elsewhere in the configuration # disk_optimization_strategy: ssd. Are we tuning for ssd by default or not? By being false, it is not tested in wild, how is it covered and trusted during tests, how many tests have it off vs on? I think the concept that trickle_fs can be added as a feature, set false and possibly gains real world coverage is not comforting to me. I do not want to turn it on and get some weird issue because no one else is running this. I would rather it be added on by default with extreme confidence or not added at all. ",property
1301,"Re: Proposal - 3.5.1 I�m with Jeff on this, 3.7 (bug fixes on 3.6) has already been released with the fix. Since the fix applies cleanly anyone is free to put it on top of 3.5 on their own if they like, but I see no reason to put out a 3.5.1 right now and confuse people further. -Jeremiah",not-ak
1302,"Re: Proposal - 3.5.1 As I follow up, I suppose I'm only advocating for a fix to the odd releases. Sadly, Tick Tock versioning is misleading. If tick tock were to continue (and I'm very much against how it currently works) the whole even-features odd-fixes thing needs to stop ASAP, all it does it confuse people. The follow up to 3.4 (3.5) should have been 3.4.1, following semver, so people know it's bug fixes only to 3.4. Jon ",executive
1303,"Re: Proposal - 3.5.1 In this particular case, I'd say adding a bug fix release for every version that's affected would be the right thing. The issue is so easily reproducible and will likely result in massive data loss for anyone on 3.X WHERE X < 6 and uses the ""date"" type. This is how easy it is to reproduce: 1. Start Cassandra 3.5 2. create KEYSPACE test WITH replication = {'class': 'SimpleStrategy', 'replication_factor': 1}; 3. use test; 4. create table fail (id int primary key, d date); 5. delete d from fail where id = 1; 6. Stop Cassandra 7. Start Cassandra You will get this, and startup will fail: ERROR 05:32:09 Exiting due to error while processing commit log during initialization. org.apache.cassandra.db.commitlog.CommitLogReplayer$CommitLogReplayException: Unexpected error deserializing mutation; saved to /var/folders/0l/g2p6cnyd5kx_1wkl83nd3y4r0000gn/T/mutation6313332720566971713dat. This may be caused by replaying a mutation against a table with the same name but incompatible schema. Exception follows: org.apache.cassandra.serializers.MarshalException: Expected 4 byte long for date (0) I mean.. come on. It's an easy fix. It cleanly merges against 3.5 (and probably the other releases) and requires very little investment from anyone. ",not-ak
1656,"Re: [DISCUSSION] Portable remote client APIs First of all, I am considering to support https scheme in REST api. However, implementing REST API task was pretty much bigger than expected, so I decided to separate these two HTTP and HTTPS scheme support. HTTPS support will be uploaded in near future, when TAJO-1338 task is finished. Later one looks like implementing authentication on REST API, doesn't it? I also considering about HTTP basic auth using HTTPS and token based authentication. I did not decide yet, and selecting authentication method would be affected by future implementation in security module. 2015-03-20 13:37 GMT+09:00 Dongjoon Hyun :",existence
1657,"Re: [DISCUSSION] Portable remote client APIs Great! I have two questions. (I'm sure you think about these already.) 1. What about supporting https together? 2. What about supporting optional password in Request Message for supporting future-proof? { ""userName"": ""tajo-user"", ""userPassword"": ""password"", ""databaseName"": ""default"" } Warmly, Dongjoon. ",existence
1658,"Re: [DISCUSSION] Portable remote client APIs Hello All, TAJO REST API design page was created in TAJO wiki page. Please feel free to give any comments on this design. You can find details in following link. https://cwiki.apache.org/confluence/display/TAJO/TAJO+REST+API 2015-03-17 15:13 GMT+09:00 Hyunsik Choi :",not-ak
1678,"Re: [DISCUSSION] Portable remote client APIs Hi CharSyam, Thank you for suggestion. Yes, the REST api will be updated. Please see the attach file at https://issues.apache.org/jira/browse/TAJO-1331. Jihun already wrote the first draft of REST API. Best regards, Hyunsik ",not-ak
1679,Re: [DISCUSSION] Portable remote client APIs Yes :) But I think we need good docs for REST api also for client developers. 2015-03-17 14:32 GMT+09:00 Hyunsik Choi :,executive
1680,"Re: [DISCUSSION] Portable remote client APIs According to the vote results, let's focus on REST for remote API. Best regards, Hyunsik ",existence
1687,"Re: [DISCUSSION] Portable remote client APIs This discussion started to avoid duplicated efforts. IMPOV, if we choice both of REST and Thrift, it may be complex to maintain Tajo codes. 2015-03-13 15:28 GMT+09:00 ???(JUNG YOUSUN) :",existence
1689,"Re: [DISCUSSION] Portable remote client APIs Hi Jerry, How much faster and lightweight than REST? Luckily, Thrift may be faster 1~2 msec than REST per call. But, note that Tajo is an analytical system. The target response times of Tajo are usually from few seconds to hours. So, the speed which come from wired protocol is much trivial to the purpose of our client APIs. The link you introduce is about Hbase. As you know, Hbase is OLTP-like system. It processes thousands of transactions per seconds. So, the speed and lightweight are important to them. But, Tajo is not. As I mentioned, REST API is very portable and has no dependencies in many languages. I think that these are the most important factors of our client APIs. Best regards, Hyunsik ",existence
1690,"Re: [DISCUSSION] Portable remote client APIs Sorry, it was my misunderstanding. We still have no plan to support Thrift interface. Sincerely, Jihoon ",existence
1691,"Re: [DISCUSSION] Portable remote client APIs I missed one thing. It is not true that we will not provide the Thrift interface. We will provide the Thrift interface using REST. Sincerely, Jihoon ",existence
1692,"Re: [DISCUSSION] Portable remote client APIs Jerryjung, thanks for your suggestion. As you said, Thrift will be faster and more lightweight than REST. However, most native protocols are faster than REST. So, this cannot be a reason for using Thrift. Alternatively, maintaining various types of protocols can be an option. However, this will cause much greater maintenance cost. Even though the link which you gave above is not for comparing the performance Thrift and REST protocols, there is a paragraph as follows. There are two main approaches for doing that: One is the Thrift interface As indicated here, REST can be a good candidate to support various languages and programs. In addition, I think that the performance of Client APIs does not matter because it's contribution to the entire query performance is very little. Welcome any arguments. Sincerely, Jihoon ",property
1696,"Re: [DISCUSSION] Portable remote client APIs I give +1 to REST API, too. Best regards, Dongjoon. ",not-ak
1697,"Re: [DISCUSSION] Portable remote client APIs We seem to get a consent to use REST API. I'll wait for one more day, and then we can decide this issue. Best regards, Hyunsik ",not-ak
1698,"Re: [DISCUSSION] Portable remote client APIs Hi all, I give +1 to REST API. I think REST is more common. Warm regards, Hyoungjun 2015. 3. 12. ?? 10:41? ""Jihun Kang"" ?? ??:",not-ak
1699,"Re: [DISCUSSION] Portable remote client APIs Hello All, I would give +1 to REST API Implementation. Even Protobuf and Thrift give flexibility and extensibility to programmers, but entry barriers for these frameworks are extremely high. Also, if we want to make another client implementation for other programming languages, we need to figure out that these framework have code generator feature for that programming language. 2015-03-12 20:18 GMT+09:00 Jaehwa Jung :",property
1700,Re: [DISCUSSION] Portable remote client APIs Hi guys +1 for Hyunsik's suggestion. REST API may be more efficient for code maintenance and various clients implementation. Cheers Jaehwa +1 RESTful API for code maintenance -Jinho Best regards 2015-03-12 17:56 GMT+09:00 CharSyam : after,existence
1701,Re: [DISCUSSION] Portable remote client APIs +1 RESTful API for code maintenance -Jinho Best regards 2015-03-12 17:56 GMT+09:00 CharSyam :,not-ak
1702,Re: [DISCUSSION] Portable remote client APIs +1 I also agree with hyunsik's suggesttion. I think it is better to make language binding to use Rest API. It will be more efficient and less effort :) 2015-03-12 17:38 GMT+09:00 Jihoon Son :,existence
1703,"Re: [DISCUSSION] Portable remote client APIs +1 for Hyunsik's suggestion. I totally agree with you. Warm regards, Jihoon 2015? 3? 12? (?) ?? 5:35, Hyunsik Choi ?? ??:",not-ak
1704,"Re: [DISCUSSION] Portable remote client APIs Here is my suggestion. I prefer REST API. I think that it would be better than other due to the following reasons: * No dependency - most of script languages do not need any dependency for this approach. Also, C and C++ just needs json library for this approach. Please look at JSON for Modern C++ (https://github.com/nlohmann/json). It just requires to include one header and one source file. As a result, there is no dependency problem. * Portability - most of script languages basically support REST and JSON. They don't need client implementation. They can just use REST and JSON features in order to access Tajo. If necessary, we can make easily some helper libraries for other languages. * Secure - It is easy to provide the secure channel and authentication method too. Basically, many HTTP API provides HTTP over SSL. Jihoon Kang already started REST API work. If others start to develop clients for other languages like C/C++ client over REST API after his work, it would be best for us. Best regards, Hyunsik ",existence
1705,"[DISCUSSION] Portable remote client APIs Hi folks, Recently, there are three trials to add new remote client APIs. * C/C++ Client over Thrift - https://issues.apache.org/jira/browse/TAJO-1264 * Add REST Client API - https://issues.apache.org/jira/browse/TAJO-1331 * Tajo Python Native Client - https://issues.apache.org/jira/browse/TAJO-1367 In some aspect, I'm very happy to discuss such an issue. I haven't expected that we are discuss and vote for duplicated efforts. BTW, it would be great if we do not spend our resource on duplicated works. In order to rearrange this duplicated works, we need some discussion about their pros and cons. I hope that we consent our direction after this discussion. Otherwise, we can call for a vote for the approach. Best regards, Hyunsik",existence
390,"Re: Enable running Cassandra 3.11 on Java 11 Java 11 support in Cassandra 3.11 would be fantastic. Is this something the Hi Thomas, backporting to 3.11 probably won't be a task taken up by the community, with all focus and effort currently on 4.0. That's not to say it can't happen after 4.0.0. Leaving Java 11 marked as ""experimental"" was discussed here: https://lists.apache.org/thread.html/r38f6beaa22e247cb38212f476f5f79efdc6587f83af0397406c06d7c%40%3Cdev.cassandra.apache.org%3E Java 11 is getting tested and equal treatment to Java 8, so this is more just about using all available resources to first get 4.0 GA out. I suspect it will move from experimental to supported in one of the early 4.0.x patch versions, once we get more feedback on its usage. Feedback from users will help. regards",not-ak
427,"Enable running Cassandra 3.11 on Java 11 Hi, As an experiment, I tried to backport part of CASSANDRA-9608 and CASSANDRA-14607 that are needed to run Cassandra 3.11 on Java 11. For the most part it was quite straightforward; the results are available at https://github.com/apache/cassandra/compare/cassandra-3.11...kornelpal:cassandra-3.11-java11 To minimize the scope and risk, I only backported code changes needed to run on Java 11, not changes needed to compile on Java 11. I also did not update library versions and did not backport the script and config changes. Those might be higher risk, and Cassandra administrators should be able to manually replace library binaries and apply config changes from 4.0 for Java 11 support. Both ""ant test"" and ""ant long-test"" had the same results with and without the changes on Java 8 that is very promising. AtomicBTreePartition was somewhat challenging; CASSANDRA-14607 replaced all the relevant changes made in CASSANDRA-9608 and CASSANDRA-15367 has a 4.0 specific version. I changed CommitLogReader - that is not present in 4.0 - to use FileUtils.createTempFile for consistency. I did not apply the UFSecurityTest changes as those were failing, probably because are dependent on a newer library version. I believe that these changes could enable Cassandra 3.11 to run on modern Java versions with reasonable effort and with no code changes, while also would bring the shared code base closer to 4.0 that would reduce the risk and complexity of future code changes on the 3.11 branch. Could you please comment on whether this or a similar change could be accepted to the mainline Cassandra 3.11 source code. Thank you, Kornel --------------------------------------------------------------------- To unsubscribe, e-mail: dev-unsubscribe@cassandra.apache.org For additional commands, e-mail: dev-help@cassandra.apache.org",property
1305,Re: CASSANDRA-10993 Approaches ,not-ak
1306,"Re: CASSANDRA-10993 Approaches the strategic option to integrate reactive streams [1] in the overall Cassandra architecture at some point in the future. Reactive streams would allow to design back pressure fundamentally different compared to what we do in the current work-queue based execution model. Think about the optimizations currently deployed to walk a thin line between throughput, latency and GC pressure. About the lack of coordination between individual processes such as compactions, streaming and client requests that will effect each other; where we can just hope that clients back off due to latency aware policies, streams that will eventually timeout, or compactions that hopefully get enough work done at some point. We even have to tell people to tune batch sizes to not overwhelm nodes in the cluster. Squeezing out n% during performance tests is nice, but IMO 10993 should also address how to get more control on using system resources and a reactive stream based approach could help with that. [1] https://github.com/ReactiveX/RxJava/wiki/Reactive-Streams ",executive
1307,"Re: CASSANDRA-10993 Approaches I think I outlined the tradeoffs I see between the roll our own vs use a reactive framework in https://issues.apache.org/jira/plugins/servlet/mobile#issue/CASSANDRA-10528 My view is we should try to utilize the existing before we start writing our own. And even if we do write our own keep it reactive since reactive APIs are going to be adopted in the Java 9 spec. There is an entire community out there thinking about asynchronous programming that we can tap into. I don't buy the argument (yet) that Rx or other libraries lack the control we need. In fact these APIs are quite extensible. On Aug 17, 2016 3:08 PM, ""Tyler Hobbs"" wrote:",property
1308,"CASSANDRA-10993 Approaches In the spirit of the recent thread about discussing large changes on the Dev ML, I'd like to talk about CASSANDRA-10993, the first step in the ""thread per core"" work. The goal of 10993 is to transform the read and write paths into an event-driven model powered by event loops. This means that each request can be handled on a single thread (although typically broken up into multiple steps, depending on I/O and locking) and the old mutation and read thread pools can be removed. So far, we've prototyped this with a couple of approaches: The first approach models each request as a state machine (or composition of state machines). For example, a single write request is encapsulated in a WriteTask object which moves through a series of states as portions of the write complete (allocating a commitlog segment, syncing the commitlog, receiving responses from remote replicas). These state transitions are triggered by Events that are emitted by, e.g., the CommitlogSegmentManager. The event loop that manages tasks, events, timeouts, and scheduling is custom and is (currently) closely tied to a Netty event loop. Here are a couple of example classes to take a look at: WriteTask: https://github.com/thobbs/cassandra/blob/CASSANDRA-10993-WIP/src/java/org/apache/cassandra/poc/WriteTask.java EventLoop: https://github.com/thobbs/cassandra/blob/CASSANDRA-10993-WIP/src/java/org/apache/cassandra/poc/EventLoop.java The second approach utilizes RxJava and the Observable pattern. Where we would wait for emitted events in the state machine approach, we instead depend on an Observable to ""push"" the data/result we're awaiting. Scheduling is handled by an Rx scheduler (which is customizable). The code changes required for this are, overall, less intrusive. Here's a quick example of what this looks like for high-level operations: https://github.com/thobbs/cassandra/blob/rxjava-rebase/src/java/org/apache/cassandra/service/StorageProxy.java#L1724-L1732 . So far we've benchmarked both approaches on in-memory reads to get an idea of the upper-bound performance of both approaches. Throughput appears to be very similar with both branches. There are a few considerations up for debate as to which approach we should go with that I would appreciate input on. First, performance. There are concerns that going with Rx (or something similar) may limit the peak performance we can eventually attain in a couple of ways. First, we don't have as much control over the event loop, scheduling, and chunking of tasks. With the state machine approach, we're writing all of this, so it's totally under our control. With Rx, a lot of things are customizable or already have decent tools, but this may come up short in critical ways. Second, the overhead of the Observable machinery may become significant as other bottlenecks are removed. Of course, WriteTask et al have their own overhead, but once again, we have more control there. The second consideration is code style and ease of understanding. I think both of these approaches have downsides in different areas. The state machines are very explicit (an upside), but also very verbose and somewhat disjointed. Most of the complex operations in Cassandra can't cleanly be represented as a single state machine, because they're logically multiple state machines operating in parallel (e.g. the local write path and the remote write path in WriteTask). After working on the prototypes, I've found the state machines to be harder to logically follow than I had hoped. Perhaps we could come up with better abstractions and patterns for this, but that's the current state of things. On the Rx side, the downside is that the behavior is much less explicit. Additionally, some find it more difficult to mentally follow the flow of execution. Based on my past work with a large Twisted Python codebase, I'll agree that it's tough to get used to, but not unmanageable with experience and good coding patterns. A third consideration is code reuse. A big advantage of Rx is that it comes with many tools for transforming Observables, handling multiple Observables, error handling, and tracing. With the state machine approach, we would need to write equivalents for these from scratch. This is a non-trivial amount of work that might make the project take significantly longer to complete. Combining this with fact that the Rx approach would be less invasive, it seems like we would have an easier time introducing incremental changes to the code base rather than having a big-bang commit. If I can boil these concerns down to one tradeoff, it's this: do we want to expend more effort and have more explicit code and complete control, or do we want to piggyback on the Rx work, give up some control, and (hopefully) get to the next, deeper optimizations sooner? Thanks for any input on this topic. -- Tyler Hobbs DataStax",executive
2400,"Re: Hadoop Distributed File System requirements on Wiki I have updated the DFS requirements wiki page to reflect the discussion that took place. http://wiki.apache.org/lucene-hadoop/DFS_requirements The changes are: - two new requirements on recovery and availability; - clarification for item #16; - and 3 additional tasks that need to be prioritized. What people think about priorities of these three and other tasks? Thanks, Konstantin Paul Sutter wrote:",not-ak
2401,"Re: Hadoop Distributed File System requirements on Wiki I think we need to have task(s) on the list detailing upgrades. Also process around releasing filesystem changes that change durable data. And testing... On Jul 7, 2006, at 12:32 PM, Konstantin Shvachko wrote:",not-ak
2402,"Re: Hadoop Distributed File System requirements on Wiki Paul Sutter wrote: I agree, simplicity is also very important. That's a good point. We should probably add a task to define/describe manual failover procedures and to evaluate the availability goal that we can reasonably guarantee. I guess if we want to separate the backup from the original storage on the hardware level we have two options a) mirror data to another dfs cluster (earlier version, opposite cost) b) copy critical data to a different (local) fs If only 5% of the whole data set is critical you might want to go with (b). This can be a separate (dfs based) application or an extension to dfs. If ~100% is critical then (a) is the only way. On a related issue, do we want to add the upgrade procedures task to the list? Thanks, Konstantin",not-ak
2403,"Re: Hadoop Distributed File System requirements on Wiki thanks! comments below... On 7/7/06, Konstantin Shvachko wrote: Great place to put it, very nice. Actually its OK for me if we lose even an hour of data on a namenode crash, since I can just resubmit the recent jobs. Less loss is better, but my suggestion would be to favor simplicity over absolute recovery if thats a tradeoff. Others might feel differently about acceptable levels of data loss. Its about features. Is namenode failover automatic or manual? If its manual, it takes time. And it should definitely be manual for now. Seamless namenode failover done right is a lot of work, and unnecessary. With manual failover, what is the downtime when a namenode fails? Well, I imagine that you'd want to take everything down, bring the filesystem up in safe mode (nice feature!) on the new namenode, and do some kind of fscheck. And then, when you're comfortable that everything is copacetic, all your files are present, and that the filesystem wont do a radical dereplication of every block when you make it writable, you make it writable. (In fact, the secondary namenode might always come up in safe mode until manually changed). How long does this take? Well, during this time the system is unavailable. And if it fails at 2AM, you're probably not back up before 10AM. But thats OK. Better to be down for a few hours (manual failover) than to have a complex system likely to break (seamless automatic failover). Increasing replication doesnt protect me against a filesystem bug. I'm a nervous nelly on this one: file system revisions do scare me, and I dont have a 10PB system. Lets say I have a 100TB system, and that to get back into production I need only restore 5TB worth of critical files. Then once I'm back in production I can gradually restore the next 25TB and regenerate the rest. Its feasible and probably prudent. Its not that Im expecting data loss bugs in new code. My concern is less about the likelihood of the problem, and more about the severity of the problem. To back up a 10PB system, you would want to back it up to a second 10PB system located on an opposite coast. In fact if this system is important to your business, you must do this. And then there is the question, do you stagger software updates on these two systems? Probably. You might want to find someone from EMC or Netapp, and get their feedback on how software changes, QA, and beta testing is handled (including timelines). Storage systems are really a risky type of code to modify, for lots of reasons more apparent to the downstream consumers than to developers. :)",not-ak
2404,"Re: Hadoop Distributed File System requirements on Wiki Hi Paul, Paul Sutter wrote: Being able to reconstruct the system even if the checkpoint is lost forever is a nice feature to have. The ""original file name"" can be placed into the crc file (#15) related to the given block. The offset or the block sequence number to be precise can be a part of the block id followed by a random number. Generation ## will be required as soon as we start implementing concurrent appends and truncates. They can be also encoded into the local file name representing the block. Say, . Yes, the intention was not to make the blocks literally of constants size, but to let datanodes deal with incomplete blocks while the namenode would treat them equally. I'll add this clarifying ideas to the document. Good thing with Wiki is it's editable :-) This is an interesting observation. Ideally, we would like to save and replicate fs image file as soon as the edits file reaches a specific size, and we would like to make edits file updates transactional, with the file system locked for updates during the transaction. This would be the zero recoverability goal in your terms. Are we willing to weaken this requirement in favor of the performance? If I understood you correctly, this goal is more related to a specific installation of the system rather than to the system itself as a software product. Or do you mean that the total time spent by the system on self-maintenance procedures like backups and checkpointing should not exceed 2 hours a day? In any case, I agree, high availability should be mentioned, probably in the ""Feature requirements"" section. Frankly speaking I've never thought about a backup of a 10 PB storage system. How much space will that require? Isn't it easier just to increase the replication factor? Just a thought... Very true. Many features and performance tasks can be considered reliability tasks from certain point of view. We've also seen uneven distribution of data, which led to task failures. But this is sort of a higher order balancing - between different subsystems competing for the storage resources on the same node.",not-ak
2405,"Re: Hadoop Distributed File System requirements on Wiki Eric, Thanks - response embedded below. One more suggestion: store a copy of the per-block metadata on the datanode. it doesnt have to have an updated copy of the filename, just the ""original file name"" and block offset would be fine. since you're adding truncation features, you'd want some kind of truncation generation number too. this would make possible a distributed namenode recovery, which is belt-and-suspenders valuable even after adding checkpointing features to the namenode. storing this metadata is more important than writing the recovery program, since the recovery program could be written after the disaster that makes it necessary. (just a suggestion). On 7/6/06, Eric Baldeschwieler wrote: Wow! Good idea, and now I see why you wanted to make the change in the first place. I agree, please go ahead and add. Incidently, its probably fine if - the API just skipped the ghost bytes, - programs using such files should only ever seek to locations that had been returned by getPos(), and - getPos() should return the byte offset of the next block as soon as a ghost byte is reached. I think existing programs will work fine within these restrictions. The last one is intended for code like SequenceFile that checks current position against file length when reading data. (SequenceFiles' syncing code might have to get reconsidered, but would be easier since you'd just advance to the next block on a checksum failure). This is a fantastic idea. But as for covering my fears, I'll feel safer with key data backed up in a filesystem that is not DFS, as pedestrian as that sounds. :) We'll take a look at it.",not-ak
2406,"Re: Hadoop Distributed File System requirements on Wiki On Jul 6, 2006, at 12:02 PM, Paul Sutter wrote: ... ... I think we can achieve our goal without compromising yours. Each block can be of any size up to the files fixed block size. The system can be aware of that and provide an API to report gaps and/or an API option to skip them or see them as NULLs. This reporting can be done at the datanode level allowing us to remove all the size data & logic at the namenode level. ** If you agree, why don't we just add the above annotation to konstantine's doc? ... ** I agree, this needs to be on the list. I'm imagining a command that hardlinks every datanode's (and namenode's if needed) files into a snapshot directory. And another command that moves all current state into a snapshot directory and hardlinks a snapshot's state back into the working directory. This would be very fast and not cost much space in the short term. Thoughts? (yes, hardlinks are a pain on the PC, we can discuss design later) ** Good point. Any interest in helping us with this one?",not-ak
2407,"Re: Hadoop Distributed File System requirements on Wiki Konstantin, I've reviewed the list of proposed changes and they look excellent. A few suggestions: *Constant size file blocks (#16), -1* I vote to keep variable size blocks, especially because you are adding atomic append capabilities (#25). Variable length blocks creates the possibility for blocks that contain only whole records. This: - improves recoverability for large important files with one or more irrevocably lost blocks, and - makes it very clean for mappers to process local data blocks *Recoverability and Availability Goals* You might want to consider adding recoverability and availability goals. Recoverability goals might include data lost in case of a namenode failure (today its about a year, but it could be day-hour-minute-second-zero at varying costs). If we have a statistically inclined person on the project, we could estimate the acceptable block loss probabilities at scale. Availability goals are probably less stringent than for most storage systems (dare I say that a few hours downtime is probably OK) Adding these goals to the document could be valuable for consensus and prioritization. ** *Backup Scheme* ** We might want to start discussion of a backup scheme for HDFS, especially given all the courageous rewriting and feature-addition likely to occur. We've looked carefully at this, and we think that we can get back into production by restoring only a subset of the data into our system, but we're likely to need an effective backup tool to do this. *Rebalancing (#22,#21)* I would suggest that keeping disk usage balanced is more than a performance feature, its important for the success of running jobs with large map outputs or large sorts. Our most common reducer failure is running out of disk space during sort, and this is caused by imbalanced block allocation. Thanks! Paul On 6/30/06, Konstantin Shvachko wrote:",property
2408,"Re: Hadoop Distributed File System requirements on Wiki This page is fantastic. On 6/30/06, Konstantin Shvachko wrote:",not-ak
2409,Hadoop Distributed File System requirements on Wiki I've created a Wiki page that summarizes DFS requirements and proposed changes. This is a summary of discussions held in this mailing list and additional internal discussions. The page is here: http://wiki.apache.org/lucene-hadoop/DFS_requirements I see there is an ongoing related discussion in HADOOP-337. We prioritized our goals as (1) Reliability (which includes Recoverability and Availability) (2) Scalability (3) Functionality (4) Performance (5) other But then gave higher priority to some features like the append functionality. Happy holidays to everybody. --Konstantin Shvachko,property
2084,"Re: RFC: Cassandra Virtual Nodes There is now a parent ticket for this issue in JIRA: https://issues.apache.org/jira/browse/CASSANDRA-4119 Comments and contributions are still welcome! Cheers, Sam On 16 March 2012 23:38, Sam Overton wrote: -- Sam Overton Acunu |�http://www.acunu.com�| @acunu",not-ak
2088,"Re: RFC: Cassandra Virtual Nodes A friend pointed out to me privately that I came across pretty harsh in this thread. While I stand by my technical concerns, I do want to acknowledge that Sam's proposal here indicates a strong grasp of the principles involved, and a deeper level of thought into the issues than I think anyone else has brought to date. Thanks for putting that energy into it, Sam, and I look forward to seeing how you approach the implementation. ",not-ak
2089,"Re: RFC: Cassandra Virtual Nodes I would add (d) limiting the distribution factor to decrease the probability of data loss/multiple failures within a replica set. Agreed (but I think (d) relates). (or any other arbitrary change, yes) Yes. Cassandra would have a minimum of two topologies; the ""current"" and the ""next"" topology. Each would imply a mapping of partition -> replica set, and that mapping will potentially be different between the two. Reads would always be served form the ""current"" topology. Writes would go to the union of the current and the next topology, taking care to ""tie"" replicas together correctly for consistency level purposes (this is what CASSANDRA-3901 and CASSANDRA-3833 are talking about). Any topology change is treated the same from the read/write path perspective, regardless of whether you're adding a node, removing a node, adding an entire rack, or even an entire data center. No added complexity is introduced beyond the ""base case"". One of the benefits of pre-partitioning to a fixed set of partitions is that we can pre-calculate the mapping. This removes the CPU efficiency trade-off of the straw bucket, and the straw bucket would be a good choice. Consistent hashing: It's totally doable to use consistent hashing at each node in the topology. It is not without its own trade-offs though, because the granularity of weighting you want to support, and the accurace of it, relates directly to the number of vnodes per child you need to keep in your consistent hashing ring. Taking granularity, accuracy target and number of children into account can easily lead to very large amounts of vnodes. (At least experimentally from when I've implemented and played with the simple form of consistent hashing in the past. I don't currently have good mathematical evidence.) This is my understanding of what you meant by consistent hashing, and what I refer to above. I will have to re-read your orignal post. I seem to have missed something :) Yes, agreed. Also, the distribution factor limiting is also compatible with non-crush by hash chaining from the primary replica instead of the row key. I'm not sure I see why my suggestion is dynamo like. In what way? It is essentially random in the sense of converging toward uniformity, but with the difference that the mapping is produced deterministically (and in a stable fashion). In my scheme the limit would be implicit in the number of partitions (combined with cluster size). And yes, this is a very good property IMO. Relatedly, as mentioned, is that you can make sure to structure the data in terms of these partitions. In terms of current Cassandra, this means that ""cleanup"" is an instantaneous operation instead of an expensive operation that has to truck through a lot of data (less so with leveled compaction). This is common argument against limiting RDF, but I am *strongly* skeptical of this in real-life scenarios. This is one of those cases where I think one needs to look beyond the pure math. For one thing, a huge concern for me is that I don't want active re-balancing to have such an extreme availability requirement that a downtime on actively doing that implies a significantly increased risk of data loss. I don't want a system to be constantly teetering on the edge of data loss, and it not even being safe to *shut it down* because your lack of data loss is dependent on the system as a whole being fully available, working and actively moving data around. It also hinges on reality matching theory perfectly well in terms of ""independent"" failures truly being independent. I would feel much more comfortable with a system that did not rely on super-fast re-replication to ensure data safety. But like I said, a lot of people make this argument - I just remain unconvinced thus far. Further, even looking at just the math, the claim cannot possibly hold as N grows sufficiently large. At some point you will bottleneck on the network and no longer benefit form a higher RDF, but the probability of data loss doesn't drop off until you reach DF=number of partitions (because at that point an increased cluster size doesn't increase the number of nodes with data sharing with another node). -- / Peter Schuller (@scode, http://worldmodscode.wordpress.com)",existence
2090,"Re: RFC: Cassandra Virtual Nodes I think if we could go back and rebuild Cassandra from scratch, vnodes would likely be implemented from the beginning. However, I'm concerned that implementing them now could be a big distraction from more productive uses of all of our time and introduce major potential stability issues into what is becoming a business critical piece of infrastructure for many people. However, instead of just complaining and pedantry, I'd like to offer a feasible alternative: Has there been consideration given to the idea of a supporting a single token range for a node? While not theoretically as capable as vnodes, it seems to me to be more practical as it would have a significantly lower impact on the codebase and provides a much clearer migration path. It also seems to solve a majority of complaints regarding operational issues with Cassandra clusters. Each node would have a lower and an upper token, which would form a range that would be actively distributed via gossip. Read and replication requests would only be routed to a replica when the key of these operations matched the replica's token range in the gossip tables. Each node would locally store it's own current active token range as well as a target token range it's ""moving"" towards. As a new node undergoes bootstrap, the bounds would be gradually expanded to allow it to handle requests for a wider range of the keyspace as it moves towards it's target token range. This idea boils down to a move from hard cutovers to smoother operations by gradually adjusting active token ranges over a period of time. It would apply to token change operations (nodetool 'move' and 'removetoken') as well. Failure during streaming could be recovered at the bounds instead of restarting the whole process as the active bounds would effectively track the progress for bootstrap & target token changes. Implicitly these operations would be throttled to some degree. Node repair (AES) could also be modified using the same overall ideas provide a more gradual impact on the cluster overall similar as the ideas given in CASSANDRA-3721. While this doesn't spread the load over the cluster for these operations evenly like vnodes does, this is likely an issue that could be worked around by performing concurrent (throttled) bootstrap & node repair (AES) operations. It does allow some kind of ""active"" load balancing, but clearly this is not as flexible or as useful as vnodes, but you should be using RandomPartitioner or sort-of-randomized keys with OPP right? ;) As a side note: vnodes fail to provide solutions to node-based limitations that seem to me to cause a substantial portion of operational issues such as impact of node restarts / upgrades, GC and compaction induced latency. I think some progress could be made here by allowing a ""pack"" of independent Cassandra nodes to be ran on a single host; somewhat (but nowhere near entirely) similar to a pre-fork model used by some UNIX-based servers. Input? -- Rick Branson DataStax",executive
2091,"Re: RFC: Cassandra Virtual Nodes Hi Peter, It's great to hear that others have come to some of the same conclusions! I think a CRUSH-like strategy for topologically aware replication/routing/locality is a great idea. I think I can see three mostly orthogonal sets of functionality that we're concerned with: a) a virtual node partitioning scheme (to support heterogeneity and management simplicity) b) topology aware replication c) topology aware routing First of all, I think that while (c) depends on (b) it does not affect partitioning or replication directly, so I'm going to set that aside for the moment and talk just about the former two. I'll summarise your design here, mainly to make sure that I understand it, but also to refer back to it: 1. The hash-space is partitioned into a fixed number of partitions 2. The CRUSH algorithm is run - select(1, disk) - over the topology using each partition as a key, to get an assignment of partition -> physical host (primary) 2a. adding or removing a node requires re-running CRUSH to recalculate the partition assignment (and move data) 3. The CRUSH algorithm is run - select(RF-1, disk) - over the topology using each primary host id, to get an assignment of primary host -> RF-1 replicas 3a. adding or removing a node requires re-running CRUSH to recalculate replica assignment (which might be a different set of hosts to before?) Here are some thoughts: (clarification: when I'm talking about buckets, I'm referring to the same concept as in the CRUSH paper!) One of my concerns about using CRUSH exactly as described in the paper is that it seems to be sub-optimal in the amount of data that it moves after modifying the topology. The authors of the paper introduce several ""bucket types"" (uniform, list, tree, straw) which appear to be various sub-optimal alternatives to consistent hashing, with various trade-offs. Why not use consistent hashing? Given (2a) and (3a) I think we might end up moving way too much data when the set of replicas changes completely for a given host. Let's suppose we introduce our own bucket type called a ""ring bucket"". Each item in a ring bucket is assigned an equal, non-contiguous portion of the key hash-space, which determines which keys are assigned to it. When an item is added to the ring bucket, it takes an equal portion of the hash-space from every other item already in the bucket. And vice-versa for removals. It's easy to see that this ring bucket implements consistent hashing with some unspecified virtual node scheme. Additions and removals would be optimal (only \deltaw/W keys require moving when the topology changes). Using this ring bucket in the CRUSH topology, (with the hash function being the identity function) would give the exact same distribution properties as the virtual node strategy that I suggested previously, but of course with much better topology awareness. This makes it evident that the partitioning scheme, and a CRUSH-like replication scheme are orthogonal concerns. In the same way as NTS currently uses the ring to provide distribution at DC and rack level by conceptually separating the ring into a distinct logical rings for each DC, a CrushReplicationStrategy could use the ring as its bucketing function to distribute partitions in the topology. This brings me on to (1) and the reasons for our choice of virtual node scheme - choose N random tokens - instead of the Dynamo-like scheme that you suggest where the partitions are fixed in advance. With the Dynamo scheme, the size of a virtual node partition will only ever grow as more data is inserted. Since the number of partitions is fixed when the cluster is created, the partition size is unbounded. There are certain advantages to having a limit on partition size. Streaming failures that cause retries do not have to resend so much data. Streaming operations can be staggered in smaller chunks to minimise the impact on the nodes involved. Load balancing can operate on a finer granularity. In the N tokens per node scheme, adding nodes to the cluster decreases the partition size and so gives some control about how much data is stored in each partition. The average size can be reduced by adding more machines to the cluster. The other concern you mentioned was but you also acknowledge that Our calculations lead us to believe that in fact the shorter rebuild window more than compensates for the increased probability of multiple failure, so with DF=N the probability of data loss is minimised. The CRUSH paper also states: ""With 2-way mirroring these two factors cancel each other out, while overall data safety with more than two replicas increases with declustering [Xin et al. 2004]"" (""declustering"" meaning increasing DF towards N) Regards, -- Sam Overton Acunu |�http://www.acunu.com�| @acunu",existence
2092,"Re: RFC: Cassandra Virtual Nodes Point of clarification: My use of the term ""bucket"" is completely unrelated to the term ""bucket"" used in the CRUSH paper. -- / Peter Schuller (@scode, http://worldmodscode.wordpress.com)",not-ak
2093,"Re: RFC: Cassandra Virtual Nodes I am very happy to see some momentum on this, and I would like to go even further than what you propose. The main reasons why I do not think simply adding vnodes and making random assignments is the best end goal are: (1) The probability of data loss increases linearly with cluster size. (2) It does not take network topology into account. What follows is mostly a half-finished long text that I have been sitting on for a few months but not finished/posted. Unfortunately I do not have the possibility (due to time constraints) to go through everything in detail and update with current information and to specifically address what you already said, so there will be overlap with your original post. However given your E-Mail and the momentum in this thread, I really wanted to post something rather than not. It would be awesome if interested parties had a chance to read the referenced CRUSH paper, and the deltas proposed below. The goals are to address everything you already wanted in your post, while also addressing: (1) Probability of data loss (2) Network topology awareness The following text will first try to paint a picture of the goals that I have in mind, and then go on to the actual proposed solution. The proposition is very very short and undetailed now and there is plenty of discussion and details to fill in. I apologize, but again, I really want to post something now that this is being brought up. BEGIN un-polished text (""we"" = ""I""):= = CRUSHing Cassandra Author: Peter Schuller This is a proposal for a significant re-design of some fundamentals of Cassandra, aimed at addressing a number of current issues as well as anticipating future issues. It is particularly aimed at large clusters, but as a side-effect should improve the small cluster experience as well. == New terminology: Distribution factor A Cassandra cluster is today said to have `N` nodes, and data is replicated at a particular replication factor (`RF`). The placement of replicas is such that all rows that has a certain node `N1` as its primary replica, are located on a specific set of `RF-1` other nodes. In addition, it holds secondary replicas of data for `RF-1` other nodes. In total, it shares data with `2RF - 2` other nodes. The number of nodes with whom a node shares data is the distribution factor. In the case of Cassandra, `DF = 2RF - 2`. == Goals The goals this suggestion attempts to help solve include the following. === Goal: DF should not be tied to RF, nor N `DF` is important for these reasons: * The `DF` determines how many nodes are involved in re-constructing a lost node after failure; the higher the `DF`, the less of a performance impact a reconstruction has on remaining nodes. * The `DF` determines the significance on other nodes, with respect to read/write load, on a node being down. * The `DF` affects the probability of multiple failures causing data loss, since one looses data if any `RF` nodes within a group of `DF` nodes all go down. Having `DF` tied to `RF` like Cassandra does now has its problems. A single node failure has a significant effect on the performance characteristics of neighboring nodes (in terms relative to the normal level of load on the neighbors). On large data sets, a failed node needing reconstruction is a significant event, as it * Increases the load on neighbors just from going down. * Further increases the load on neighbors as they have to stream data (adding I/O and cache thrashing). This typically leads to the desire to throttle / rate limit reconstruction, which adds to the reconstruction window in addition to the fact that it was already naturally bottlenecking on neighbors. The other extreme is to tie `DF` to `N`, such that the data contained on one node, has it's secondary replicas spread out over the entire ring. This is an unacceptable choice because the probabiliy of multiple failures increases linearly with the cluster size. In other words, we want `DF` to be tied to neither `RF` nor `N`. Rather, `DF` should be chosen as a trade-off between the effects of `DF`: * The higher the `DF`, the higher the probability of data loss in case of multiple failures. * The higher the `DF`, the faster to reconstruct/replace a lost node. * The higher the `DF`, the less impact is seen on node failures on the performance requirements on other nodes. In making this determination, one must take into account that if a larger `DF` makes reconstruction/replacement significantly faster, that also decreases the time window in which multiple failures can occurr. Increasing `DF` is thus not *necessarily* increasing the total probability of data loss (for small values of `DF`). === Goal: Topologically aware redundancy We maintain the goal of being topology aware for the purpose of ensuring that we place replicas on ""independent"" nodes (for a definition of ""independent"" that is up to the operator). This is currently implemented in a limited fashion by the DC and rack awareness offered by the `NetworkTopologyStrategy`. We want to go further than that, and allow close to arbitrary topologies to be modeled. For example, we may require, in a single data center, that a piece of data is replicated to 3 distinct racks, at least two of which must be within different cages in the data center. === Goal: Topologically aware locality Somewhat in conflict with the previous goal, there is also a desire to keep replicas ""close"". In a sufficiently large cluster, it becomes cost-prohibitive to pipe all inter-replica traffic through a fast backbone network. Ideally, one want to balance the two. For example, one could arrange for replicas to be distributed across different racks in a cage in a data center, limiting cross-replica network bandwidth requirements to the local switch in said cage, while maintaining independent power supply/networking to racks for redundancy. With gigabit+ speeds from a node, it is very easy to saturate networking infrastructure once you start having hundreds of nodes or more. === Goal: Topologically aware routing Once a cluster grows sufficiently large, even with topologically aware locality, you eventually want to avoid the everybody-talks-to-everybody situtation of current Cassandra, for network efficiency reasons. This includes the clients. Topologically aware routing would enable selection of a co-ordinator node more intelligently (consider ""edge"" router nodes that are Cassandra aware, to which application clients connect to - e.g. you might have one such per data center, or part of a DC), and provided sufficient site-specific integration, allow the routing of traffic to that co-ordinator to be routed efficiently at the networking level. A request could go all the way from a client, to a co-ordinator/router, to responsible replicas, and back - never crossing a backbone switch/router. === Goal: Agility We want adding, removing or re-balancing nodes to be a trivial operation for the operator's perspective, and to have a minimal impact on the performance of the cluster. We want to enable adding individual hosts, groups of hosts, or entire racks of hosts easily and without significant risk of mistakes. There should be no need to carefully plan and co-ordinate upgrades due to performance reasons. The operator should have the flexibility of quickly adding capacity as demands change (which they will, even with careful planning to minimize it). There must not be artificial limitations like requiring a doubling of the cluster in order to avoid very painful and performance degrading operations. The operator should never be in a position to have to consider the trae-off between adding 30% capacity now at great cost in operator effort and risk, vs. waiting another two weeks for that promised delivery of servers, for example. Consider a large deployment with multiple clusters. It is desirable to capacity project each cluster individually, and have a constantly re-populated pool of servers that are used for expansion and/or replacement of nodes. Adding capacity to existing cluters could be done even on a daily basis, in an effort to keap average utilization as smooth as possible (having a varying average utilization contributes is one more factor that contributes to the need to over-provision; in a 1000 node cluster expected to double in size in a year for example, it is efficient to incrementally add capacity rather than, say, add 500 on day one and 500 at the half-way point; if nothing else, doing the latter would imply a 250 node average over-provisioning during a year *just* due to lack of agility in expansion, on top of other factors). === Goal: Heterogenous nodes We want it to be realistic and minimally impactful to have nodes of different performance characteristics in the cluster. === Goal: Operator simplicity The current situation is unacceptably complex. Maintaing a multi-DC cluster with rack awareness requires significant planning, care and often automation on the part of the operator to maintain an appropriately layed out ring, without causing rack hotspots or other issues. Auditing correct ring layout is essentially impossible for a human with the out-of-the-box tools, and currently require site-specific scripting (e.g., `nodetool ring` is close to useless without significant mental or automated post-processing). We want to significantly increase operator simplicity (minimizing the risk for operator error and minimize the effort required by an operator). == Proposed solution The proposal draws inspiration from the CRUSH paper: http://www.ssrc.ucsc.edu/Papers/weil-sc06.pdf Currently, because this is an unfinished document, that paper is pre-requisite reading. Here are the deltas proposed: === Buckets and pre-calculation The key on which we would apply the crush algorithm would not be the Cassandra row key. Instead the Cassandra keyspace is partitioned (by hashing) into N buckets. N must be large enough to accomodate future cluster expansions, and to accomodate probabilistic effects when applying a CRUSH-like algorithm so that we achieve balancing. The main reasons to use buckets are: * It allows pre-calculation of the results of the CRUSH-like algorithm, which removes the CPU/balancing trade-offs from the equation that the CRUSH paper focuses on. We can go with the optimally balanced solution. * A ""bucket"" is tantamount to a ring segment. Similarly to how Cassandra already does it, we want to efficiently be able to transfer a single bucket without having to traverse the entire data set or a node-global index of all data. Thus, buckets directly relate to structuring data on disk in a way which is non-orthogonal to the unit of data being moved around on topology changes. * It helps the balancing/accurace trade-off, see below. === Replica selection In order to cater to Distrihution Factor, we need to use the primary replica, as opposed to the bucket id, in the key when applying the CRUSH-like algorithm on finding secondary replicas. === Balancing accuracy vs. RDF vs. unnecessary movement trade-off When limiting replicas to be among RDF other nodes, you introduce an artificial constraint on replica placement that causes greater imbalance due to the low number of nodes you are distributing over (each node has replicas for data otherwise primary on DF-1 nodes, and assuming DF is not huge, DF-1 is a smallish number, and thus balancing will be limited). An algorithm to get around this is to calculate the placement in a deterministic fashion (such as in order) with resperct to bucket id. If, when assigning a secondary replica, the proposed replica is already above quota, you reject the selection and keep going. This achieves balance, but at the cost of additional data movement because every time you perform a rejection, you are causing the placement of a virtual bucket to be affected by something *other* than the nodes on which it is placed. -- / Peter Schuller (@scode, http://worldmodscode.wordpress.com)",property
2094,"RFC: Cassandra Virtual Nodes Hello cassandra-dev, This is a long email. It concerns a significant change to Cassandra, so deserves a thorough introduction. *The summary is*: we believe virtual nodes are the way forward. We would like to add virtual nodes to Cassandra and we are asking for comments, criticism and collaboration! Cassandra's current partitioning scheme is sub-optimal for bootstrap, decommission, repair and re-balance operations, and places the burden on users to properly calculate tokens (a common cause of mistakes), which is a recurring pain-point. Virtual nodes have a variety of benefits over the one-to-one mapping of host to key range which Cassandra currently supports. Among these benefits are: * Even load balancing when growing and shrinking the cluster A virtual node scheme ensures that all hosts in a cluster have an even portion of the total data, and a new node bootstrapped into the cluster will assume its share of the data. Doubling, or halving the cluster to ensure even load distribution would no longer be necessary. * Distributed rebuild When sizing a cluster, one of the considerations is the amount of time required to recover from a failed node. This is the exposure time, during which a secondary failure could cause data loss. In order to guarantee an upper bound on the exposure time, the amount of data which can be stored on each host is limited by the amount of time taken to recover the required replica count. At Acunu we have found that the exposure time is frequently the limiting factor which dictates the maximum allowed node size in customers' clusters. Using a virtual node scheme, the data stored on one host is not replicated on just RF-1 other physical hosts. Each virtual node is replicated to RF-1 other virtual nodes which may be on a different set of physical hosts to replicas of other virtual nodes stored on the same host. This means data for one host is replicated evenly across the entire cluster. In the event of a failure then, restoring the replica count can be done in a fully distributed way. Each host in the cluster participates in the rebuild, drastically reducing the exposure time, allowing more data to be stored on a single host while still maintaining an acceptable upper bound on the likelihood of secondary failure. This reduces TCO concerns. * Greater failure tolerance in streaming Operations which require streaming of a large range of data, eg. bootstrap, decommission, repair, etc. incur a heavy cost if an error (eg. dropped network connection) is encountered during the streaming. Currently the whole range must be re-streamed, and this could constitute a very large amount of data. Virtual nodes reduce the impact of streaming failures, since each virtual node is a much smaller range of the key-space, so re-streaming a whole virtual node is a much cheaper process. * Evenly distributed impact of streaming operations Streaming operations such as bootstrap, repair, et al. would involve every node in the cluster. This would distribute the load of these operations across the whole cluster, and could be staggered so that only a small subset of nodes were affected at once, similar to staggered repair[1]. * Possibility for active load balancing Load balancing in Cassandra currently involves moving a token to increase/reduce the amount of key-space for which a host is responsible. This only allows load balancing between neighbouring nodes, so it could involve moving more than one token just to redistribute a single overloaded node. Virtual nodes could allow load balancing on a much finer granularity, so heavily loaded portions of the key-space could be redistributed to lighter-loaded hosts by reassigning one or more virtual nodes. Implementing a virtual node scheme in Cassandra is not an insignificant amount of work, and it will touch a large amount of the codebase related to partitioning, placement, routing, gossip, and so on. We do believe that this is possible to do incrementally, and in such a way that there is an easy upgrade path for pre-virtual-node deployments. It would not however touch the storage layer. The virtual node concept is solely for partitioning and placement, not for segregating the data storage of the host, so all keys for all virtual nodes on a host would be stored in the same SSTables. We are not proposing the adoption of the same scheme used by Voldemort[2] and described in the Dynamo paper[3]. We feel this scheme is too different from Cassandra's current distribution model to be a viable target for incremental development. Their scheme also fixes the number of virtual nodes for the lifetime of the cluster, which can prove to be a ceiling to scaling the cluster if the virtual nodes grow too large. The proposed design is: * Assign each host T random tokens. * A partition is assigned to a host for each of its tokens, where the partition is defined by the interval between a token and the previous token on the ring. * When a host joins the ring it is assigned T random tokens which will result in a portion of an existing partition being assigned to that host. * When a host leaves the ring it relinquishes its tokens which will result in its partitions becoming part of the neighbouring partitions. This is just a basic extension of Cassandra's existing distribution model, where instead of having 1 token per host, there are many tokens per host. It is the same scheme used by libketama[4] for consistent hashing among memcached instances, and is also the original scheme used by Dynamo as described in [3] before they migrated to their current scheme with fixed partitions. The random assignment of tokens may seem unintuitive given that currently in Cassandra a random token assigment leads to an unbalanced cluster. With many virtual nodes, a random token assignment leads to load being evenly balanced across the hosts in the cluster with high probability. As the number of virtual nodes is increased, the variance in load across hosts decreases, as demonstrated by simulation in [5]. This scheme has the following properties - (where N is the number of hosts and B is the total data stored in the cluster): * placement metadata size is O(N) which is the same as in Cassandra currently * partition size is O(B/N) so as data is inserted, if individual partitions become too large then adding nodes to the cluster reduces this. * the strategy shares the following properties in common with Cassandra currently ** tokens are randomly assigned ** partitioning is determined by placement (and vice-versa) ** no two nodes may share the same token ** when a node leaves the ring, all of its tokens are removed - there is no exchanging of partitions between nodes One design concern is that replicas of a key range are not stored on the same physical host, as failure of that host could cause the loss of more than one replica of the data. This will be achieved by using a placement strategy very similar the the existing NetworkTopologyStrategy, which treats each individual host the same way as NTS treats a rack - that is replicas are not assigned to two hosts on the same rack. I will shortly create a ticket in JIRA to track discussion of this design. We have also done some simulation of this scheme to observe the load balancing properties, node size distribution, cluster resizing and so on. I will attach some results of this simulation to the JIRA ticket in due course. We are keen to get the ball rolling on this and we look forward to your input, ideas and recommendations. Best Regards, Sam Overton [1] Staggering repair: https://issues.apache.org/jira/browse/CASSANDRA-3721 [2] Project Voldemort, Design: http://project-voldemort.com/design.php [3] Dynamo: http://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf [4] Ketama: Consistent Hashing: http://www.audioscrobbler.net/development/ketama/ [5] Consistent Hashing: http://www.lexemetech.com/2007/11/consistent-hashing.html -- Sam Overton Acunu | http://www.acunu.com | @acunu",existence
1892,"Re: Replacing the JSP web UIs to HTML 5 applications Hi Colin, I put up a command line tool today to query the information of the HDFS through JMX. The code is available at https://github.com/haohui/dfshealth-cli I did it within a day. Obviously the tool can be more polished, but what I'm trying to demonstrate is that it is feasible to reuse some of the code of new web UI to build such a tool with minimal effort. Right now the tool is based on node.js. However, it is possible to use java+rhino to run the same code, so that it can be integrated in the main repository. Thanks, Haohui ",not-ak
1893,"Re: Replacing the JSP web UIs to HTML 5 applications Right now, if you do a search on Google for dfshealth.jsp, you will find many unsecured NameNode web UIs which were accidentally exposed to the internet. If the UIs were client-side, accessing these pages would not work, since the client-side Javascript would fail to make the JMX access. Nearly all firewalls block JMX. So in that sense, the new UI is more secure, not less. My understanding is that most cross-site scripting vulnerabilities arise when the server uses data from the client in page display without properly escaping it. According to wikipedia, a persistent XSS vulnerability arises ""when the data provided by the attacker is saved by the server, and then permanently displayed on 'normal' pages returned to other users in the course of regular browsing, without proper HTML escaping."" Nobody has proposed doing this on the NameNode. It seems to me that we are already exposed to any theoretical JMX security vulnerabilities already, since we support JMX. The client-side UI just adds a convenient way of calling into the pre-existing hooks. My big concern, like I said earlier, is that we have reasonable command-line tools. I think this is a solvable problem. Running links in a terminal is not exactly the gold standard of command-line excellence. It would be a shame to block progress just to support that. Colin ",executive
1894,"Re: Replacing the JSP web UIs to HTML 5 applications Hi Andrew, You always have the option to access the old JSP UI using the same URLs, if you want to access the UI with a text-based browser. ~Haohui ",not-ak
1895,"Re: Replacing the JSP web UIs to HTML 5 applications I'm also not convinced that a Javascript-based approach is the way to go. We shouldn't switch the default UI until (at a minimum) we have the command-line tools that Colin requested, and even then I'd still want to retain support for text-based browsers like elinks unless there are compelling technical reasons not to. Haohui, I'm sympathetic since you've already done all this work on a pure-JS version, but it's also true that the existing JSP pages could be cleaned up to achieve basically the same visual effect while also still working in text-only browsers. Thanks, Andrew ",property
1896,"Re: Replacing the JSP web UIs to HTML 5 applications I don't think that we have reached a consensus that the new javascript only UI is the right direction to go. Most people considered it ""interesting"". I personally think it's inappropriate for core Hadoop UI, as it increases attack surface of the UI and taking away existing mitigation options from users unnecessarily. See my latest comments on HDFS-5333 for ""concrete"" examples. __Luke ",not-ak
1898,"Re: Replacing the JSP web UIs to HTML 5 applications I would like to summarize the discussions so far. It seems that we have reached two consensus: 1. The new JavaScript-based UI is the right direction to go. 2. For now we should keep the old JSP pages around for compatibility reasons. There're some debates on the usages of the JMX / JSON APIs, but this is orthogonal to switching the UI, thus I consider it as a technical detail. We can continue the discussions in the public jira. The new UI has already landed in the trunk, based on the consensus it seems that we can switch the default UI to the new one shortly. The user can still access the old web UI using the same URLs. The only question remain is that who is going to maintain the old web UI. My answer is that we should leave them as deprecated and focus the effort on the new web UI. Thanks, Haohui ",executive
1900,"Re: Replacing the JSP web UIs to HTML 5 applications So, if I understand correctly, we are using an HTTP based API to access JMX data. The API isn't strictly designed to REST principals but does reflect the management API and query parameters of JMX. While unfortunate that we don't have a better REST based design for it, it may not add enough value to add another API that would be less familiar to those familiar with JMX. I believe that this is the servlet in question: https://hadoop.apache.org/docs/r1.0.4/api/org/apache/hadoop/jmx/JMXJsonServlet.html Now, as far as gateway deployments, if/when we are able to get access to the Web UIs from outside the Hadoop cluster and firewalls than all AJAX calls will need to be routed through the gateway. I think that this seems like a great step in the right direction of using Web APIs for the Web UIs and may provide us with interesting ways to provide additional security and auditing, etc. ",not-ak
1901,"Re: Replacing the JSP web UIs to HTML 5 applications Just to provide some data point to make the discussion concrete. Here is a part of the dump of the JMX information: curl "" http://localhost:50070/jmx?qry=Hadoop:service=NameNode,name=NameNodeInfo"" { ""beans"" : [ { ""name"" : ""Hadoop:service=NameNode,name=NameNodeInfo"", ""modelerType"" : ""org.apache.hadoop.hdfs.server.namenode.FSNamesystem"", ""Threads"" : 32, ""Used"" : 0, ""Version"" : ""3.0.0-SNAPSHOT, rd56cd7ab85de00cfda62698e66bd6f0fef00ff61"", ""Total"" : 0, ""ClusterId"" : ""CID-ddaec89d-7801-40a9-b14c-f82d225746e1"", ""PercentUsed"" : 100.0, ""PercentRemaining"" : 0.0, ""Free"" : 0, ""Safemode"" : """", ... } The new web UI only extracts the values of the fields and renders them as HTML. Thanks, Haohui ",not-ak
1902,"Re: Replacing the JSP web UIs to HTML 5 applications I think it is important that we make provisions for all Ajax calls to be able to go through gateway deployments like Knox with the cluster firewalled off. As I have commented on the Jira, any calls that are currently on the serverside but are moving to the browser will need to either require punching holes in filewalls (unfortunate) or directing through a given REST API gateway. ",existence
1903,"Re: Replacing the JSP web UIs to HTML 5 applications Neither of them will go through JMX. The new Web UI implements hdfs browsing through WebHDFS. The logs are available through the static servlets, which is exactly the same as what we have today. Thanks, Haohui ",not-ak
1904,"Re: Replacing the JSP web UIs to HTML 5 applications are you planning to expose things like hdfs browsing and nn/dn logs over jmx? thx Alejandro (phone typing) On Oct 28, 2013, at 17:48, Haohui Mai wrote:",not-ak
1905,"Re: Replacing the JSP web UIs to HTML 5 applications It seems more appealing to me that the UI should JMX directly, because: * We're support the JMX in the long term for other management software. * The information provided by the JMX API will be mostly identical of the JSON API. Today the Web UI covers most of the information provided by JMX. The Web UI does some trivial work to extract the information and renders it as HTML. * We can compatibility and unit tests for free. I do agree that the JMX APIs are imperfect and they should be revisited in the 3.0 timeframe. However, this is orthogonal of the discussions of transitioning from JSP-based Web UI to client-side JavaScript Web UI. The architecture of the new Web UI allows easy migration to any JSON-based APIs whenever they land in the trunk. Thanks, Haohui ",property
1906,Re: Replacing the JSP web UIs to HTML 5 applications Isn't using JMX to expose JSON for the web UI misusing JMX? I would think a more appropriate approach would be having /JMX for monitoring integration and a /JSON end point for the UI data. Thanks. ,not-ak
1907,"Re: Replacing the JSP web UIs to HTML 5 applications Alejandro, If I understand correctly, that is the exact approach that the new web UI is taking. The new web UI takes the output from JMX and renders them as HTML at the client side. ~Haohui ",not-ak
1908,"Re: Replacing the JSP web UIs to HTML 5 applications Haohui, If you have NN and DNs producing JSON instead HTML, then you can build JS based web UIs. Take for example Oozie, Oozie produces JSON, it has a built in JS web ui that consumes JSON and Hue has built an external web UI that also consumes JSON. In the case of Hue UI, Oozie didn't have to change anything to get that UI and improvements on the Hue UI don't require changes in Oozie unless it is to produce additional information. hope this clarifies. Thx ",executive
1909,"Re: Replacing the JSP web UIs to HTML 5 applications Hi Alejandro, Can you please elaborate on producing JSON? All information presented in the new Web UIs directly comes from the JMX side. I'm okay with leaving the current JSP right now, since both the old and the new Web UI can happily coexist. When do you think it is a good time to switch the default web UI to the new one, and to mark the JSP pages as deprecated? Thanks, Haohui ",not-ak
1910,"Re: Replacing the JSP web UIs to HTML 5 applications Echo my comments on HDFS-5402: bq. If we're going to remove the old web UI, I think the new web UI has to have the same level of unit testing. We shouldn't go backwards in terms of unit testing. I take a look at TestNamenodeJspHelper / TestDatanodeJspHelper / TestClusterJspHelper. It seems to me that we can merge these tests with the unit tests on JMX. bq. If we are going to remove this capability, we need to add some other command-line tools to get the same functionality. These tools could use REST if we have that, or JMX, but they need to exist before we can consider removing the old UI. This is a good point. Since all information are available through JMX, the easiest way to approach it is to write some scripts using Node.js. The architecture of the new Web UIs is ready for this. ",not-ak
1911,Re: Replacing the JSP web UIs to HTML 5 applications Producing JSON would be great. Agree with Colin that we should leave for now the current JSP based web ui. thx ,not-ak
1912,"Re: Replacing the JSP web UIs to HTML 5 applications This is a really interesting project, Haohui. I think it will make our web UI much nicer. I have a few concerns about removing the old web UI, however: * If we're going to remove the old web UI, I think the new web UI has to have the same level of unit testing. We shouldn't go backwards in terms of unit testing. * Most of the deployments of elinks and links out there don't support Javascript. This is just a reality of life when using CentOS 5 or 6, which many users are still using. I have used ""links"" to diagnose problems through the web UI in the past, in systems where access to the cluster was available only through telnet. If we are going to remove this capability, we need to add some other command-line tools to get the same functionality. These tools could use REST if we have that, or JMX, but they need to exist before we can consider removing the old UI. best, Colin ",property
1913,"Re: Replacing the JSP web UIs to HTML 5 applications Thanks for the reply, Luke. Here I just echo my response from the jira: bq. this client-side js only approach, which is less secure than a progressively enhanced hybrid approach used by YARN. The recent gmail XSS fiasco highlights the issue. I'm presenting an informal security analysis to compare the security of the old and the new web UIs. An attacker launches an XSS attack by injecting malicious code which are usually HTML or JavaScript fragments into the web page, so that the malicious code can have the same privileges of the web page. First, in the scope of XSS attacks, note that the threat models of launching XSS attacks on Internet sites Gmail/Linkedin and the one of the Hadoop UIs are different. They have fundamental different sets of external inputs that the attackers have control to. Internet sites have little control of these inputs. In the case of Gmail / Linkedin, an attack can send you a crafted e-mail, or put malicious description in his / her Linkedin profile. The sets of external inputs are *restricted* in Hadoop UIs. The new web UIs take JMX and WebHDFS as inputs. The attacker has to launch a XSS attack by: * Compromise the jars so that the output of JMX / WebHDFS have the malicious code. * Replace the web UIs completely to include the malicious code. In either case *the attacker has to compromise the hadoop core or the namenode*. That means the new web UIs are at least as secure as the hadoop core, and the namenode machine. Second, I argue that using client-side templates are more secure than the current JSP-based server-side templates. To defend against XSS attacks, both techniques have to filter the external inputs at *every* possible execution paths. Several facts much be taken into plays when evaluating the security of both approaches in real-world environments: * The JavaScript libraries used in the new web UIs have survived in extremely large-scale production tests. jQuery is used by Google and Microsoft, bootstrap is used by Twitter, and dust.js is used by Linkedin. All libraries survived from hundreds of thousands of attack attempts on a daily basis. I agree that the libraries might still be imperfect, but there's no way that we can test the JSP web UIs to achieve the same level of assurances given the amount of resources the community has. * Client-side templates consolidate all filtering logic in one central place. Recall that the goal is to filter all external inputs at every execution paths, this is a much more systematic approach compared to the server-side templates we have today. It is difficult (if not impossible) to do it in a JSP/ASP/PHP application, since such filtering can be only achieved via ad-hoc approaches ([1] shows some empirical data). Also, HDFS-4901 recently describes a XSS vulnerability in browseDirectory.jsp. bq. You'd require proper SSL (not self signed) setup to avoid JS injection Commodity browsers enforce Same-Origin Policy to defend against code injections. It has nothing to do with what kinds of SSL certificates you hold. bq. I also have concerns that we commit these changes without matching unit tests The JavaScript code can be automatically tested. The same code can be run by node.js and the test can compared with pre-defined results. It is also possible to write an adapter to use Rhino to accomplish the same task. We can discuss how to integrate them into the maven test routines in a different thread. bq. Client side rendering completely breaks the workflows for ops who rely on text based terminal/emacs/vim browsers (no js support) to monitor component UI. links / elinks (http://elinks.or.cz/) are text-based web browsers that support JavaScript. bq. The priority/requirements for UI in core Hadoop should be security and correctness, which client side templating cannot address properly so far. I agree that we should focus on security and correctness. The paragraphs above explain that how the architecture of the new UIs makes the UIs more secure in real-world settings compared to the UI we have today. References: 1. A. Yip et al. Improving Application Security with Data Flow Assertions. In SOSP'2009. ",executive
1914,"Re: Replacing the JSP web UIs to HTML 5 applications Echoing my comments on HDFS-3555: I have concerns with this client-side js only approach, which is less secure than a progressively enhanced hybrid approach used by YARN. The recent gmail XSS fiasco highlights the issue. I also have concerns that we commit these changes without matching unit tests � the fact you cannot effectively unit test these changes should tell you something about this approach. *Requiring* JS means that an admin cannot turn off js to (partially) use core Hadoop UI. You'd *require* proper SSL (not self signed) setup to avoid JS injection, even if security of js libraries used is perfect, which I doubt (search gmail/linkedin XSS). Client side rendering completely breaks the workflows for ops who rely on text based terminal/emacs/vim browsers (no js support) to monitor component UI. IMO, JS-only rendering belongs to social networking sites and/or SaaS front-ends, where full time UI/security specialists babysits UI changes. I think eventually most users will use a self servicing UI in a SaaS front-end that uses REST/JMX API to get data from back-end components, besides their own app master/service UI. The priority/requirements for UI in core Hadoop should be security and correctness, which client side templating cannot address properly so far. ",executive
1915,"Replacing the JSP web UIs to HTML 5 applications Hi all, Jing Zhao and I recently have reimplemented the JSP-based web UIs in HTML 5 applications (HDFS-5333). Based on our prelimanary testing results we believe thst the new web UIs of the namenodes and the datanode are ready for everyday uses. You're more than welcome to try it out on trunk by visiting http:// /dfshealth.html There are a number of benefits from this transition. From a developer's prospective, the most notable one is *maintainability*: (1) The abstractions between the UI and the core server are well-defined, decoupling the UI and the core hadoop servers. (2) It allows us to deprecate the logic in the JSP pages. The old web UIs have to duplicate the logic in the JSPs. The logic is often out-of-dated and not well-tested, which leads to broken pages and security vulnerabilities(e.g. HDFS-5251, HDFS-5307, HDFS-5308, HDFS-5317 and HDFS-4901). The architecture of the new UIs prevent these bugs at the very beginning. I propose that deprecate the old, JSP-based web UIs in 2.3. I opened HDFS-5402 to track the relevant discussions. Your feedbacks are highly appreciated. Sincerely, Haohui -- CONFIDENTIALITY NOTICE NOTICE: This message is intended for the use of the individual or entity to which it is addressed and may contain information that is confidential, privileged and exempt from disclosure under applicable law. If the reader of this message is not the intended recipient, you are hereby notified that any printing, copying, dissemination, distribution, disclosure or forwarding of this communication is strictly prohibited. If you have received this communication in error, please contact the sender immediately and delete it from your system. Thank You.",executive
2289,"Re: hadoop tasks reading from cassandra For those of you playing at home, a ""stupid"" version of the hadoop support has been attached to CASSANDRA-342. I mention it here for the curious, but please keep discussion of it in the ticket. Thanks! https://issues.apache.org/jira/browse/CASSANDRA-342?focusedCommentId=12744001&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#action_12744001 -- Jeff ",not-ak
2290,"Re: hadoop tasks reading from cassandra yes, get_string_property is our information-about-the-cluster gateway. the rest of the thrift api is for manipulating columns and so forth. we shouldn't mix the two. ",not-ak
2291,Re: hadoop tasks reading from cassandra Is there any difference between get_string_property and other thrift APIs? They are both exposed to the client through thrift. Jun,not-ak
2292,Re: hadoop tasks reading from cassandra ,not-ak
2293,"Re: hadoop tasks reading from cassandra (Er, let me be more clear here. I'm not talking about the data model or how and what IO is done. I meant that I'm not familiar enough to know well what responsibilities the various object have, nor how they fit together.) -- Jeff",not-ak
2294,Re: hadoop tasks reading from cassandra Comments inline. ,existence
2295,Re: hadoop tasks reading from cassandra ,property
2296,"Re: hadoop tasks reading from cassandra Jeff, This looks like a great start. A few comments. 1. In addition to OrderPreservingPartitioner, it would be useful to support MapReduce on RandomPartitioned Cassandra as well. We had a rough prototype that sort-of works at this moment. The difficulty with random partitioner is that it's a bit hard to generate the splits. In our prototype, we simply map each row to a split. This is ok for fat rows (e.g., a row includes all info for a user), but may be too fine-grained for other cases. Another possibility is to generate a split that corresponds to a set of rows in a hash-range (instead of key range). This requires some new apis in cassandra. 2. For better performance, in the future, it would be useful to expose and exploit data locality in cassandra so that a map task is executed on a cassandra node that owns the data locally. A related issue is https://issues.apache.org/jira/browse/CASSANDRA-197. It breaks encapsulation, but it's worth thinking about. Google's DFS and Bigtable both expose certain locality info for better performance. Jun IBM Almaden Research Center K55/B1, 650 Harry Road, San Jose, CA 95120-6099 junrao@almaden.ibm.com Jeff Hodges wrote on 07/24/2009 01:23:48 AM:",existence
2297,"hadoop tasks reading from cassandra Hey, Getting Hadoop to play nice with Cassandra has been a desire for many folks on this list and probably more on the other one. For the purposes of this email, I'm going to restrict this goal of getting Hadoop to read from Cassandra in a not-stupid way. ""Not-stupid"" has a very specific meaning. ""Not-stupid"" means that: 1) Each Hadoop Mapper sees only a small subset of the entire desired dataset from Cassandra and that the entire desired dataset will never be seen by any one phase of the Hadoop process. 2) Every portion of the desired dataset will be unique to the Mapper it is delivered to. No two Mappers will ever overlap. 3) There will be no portion of the desired dataset that is not seen by a Mapper. 4) Partitioning of the dataset to the Mappers should try to efficiently use the Cassandra nodes. This means attempting to keep partitions on to one node solely. Conspicuously not on this list is data locality. That is, keeping the data passed from a node to a given Mapper at or near the same machine. This requires further investigation outside the scope of this initial project. Also, please remember that ""not-stupid"" is not the same as ""smart"". = How Hadoop Wants It And How It's Been Done By HBase I've dug around the Hadoop and HBase codebases and while my understanding is not yet perfect, this seems to be the general layout of the problem. First, a subclass of InputFormat needs to be written. This class's job is to split up the dataset for a Hadoop job into InputSplits, or more accurately, subclasses of InputSplits. These InputSplits are serialized to disk in HDFS in files named so that each is picked up by just one Mapper. Okay, actually the Mapper has no idea about InputSplits. A InputSplit is loaded up by on a machine running a Mapper, and then getRecordReader() is called on the subclass of InputFormat, and the Mapper's InputSplit is passed in as well as various hadoop job information. getRecordReader() returns a subclass of RecordReader that allows the Mapper to call next() on it over and over again to run through the portion of the dataset represented by InputSplit. In the 0.19.3 version of the HBase codebase, InputSplits are created by gathering all the start keys for each ""region"" (which conceptually maps, roughly, to a Cassandra node) in the database and divvying up the keys approximately evenly across the number of Mappers desired. Each TableSplits (the HBase subclass of InputSplit) created has information about the start key of the region, the end key of the region and the region location (the ""name"" of the node the dataset is on). This splitting on keys works because HBase keys are always stored in an ordered fashion. Basically, HBase always partitions using something akin to Cassandra's OrderPreservingPartitioner. I've posted a gist with just the method that does this divvying up, by the by[1]. (Interestingly, the region location seems to only be encoded to allow for a nice toString() method on InputSplit to be used during logging.) HBase's subclass of RecordReader uses an instance of the ClientScanner class to keep state about where they are in the Mapper's portion of the dataset. This ClientScanner queries HBase's META server (which contains information about all regions) with the start key and table name to gather what HBase region to talk to and caches that information. Note, that this is done for each Mapper on each machine. Note, too, that the region information encoded in the TableSplit doesn't seem to be used. These last few points are where the code gets really hairy. I could be wrong about some of it and corrections would be appreciated. The important parts, anyway, are the subclassing of InputFormat, RecordReader and InputSplit. = How To Do It With Cassandra (Maybe) So, I spoke to Jonathan on #cassandra about this and we tried to see how we could take the HBase method and turn it into something that would work with Cassandra. Our initial assumption is that the Cassandra database to be mapped over has to use the OrderPreservingPartitioner to keep the input splitting consistent. Now, Cassandra nodes don't really have a concept of a ""start"" and ""end"" key. We could, however, get a start key for a given node by taking the first key returned from SSTableReader#getIndexedKeys(). We would then gather up the start keys from each of the nodes, and sort them. We could then use each key in this gathered list as a start key for a ""region"" and, given an addition to the slice API, slice from start key to the next start key (the end key, in HBase terminology). We would need to modify the slice API to provide slices where the end key given is exclusive to the set returned, instead of inclusive. In terms of actual code to be written, our subclass of InputFormat is what would gather this list of start keys, and we would serialize the start/finish key pairs with our own subclass of InputSplit. And, of course, our subclass of RecordReader would make the finish-key-exclusive slice call. This method satisifies property 1 of our not-stupid definition. At no point in our Hadoop job are we accessing the entire dataset or even all of the keys (if I'm remembering how getIndexedKeys works correctly). This satisifies property 2 and 3 because we are clearly slicing everything once and only once unless I'm misremembering how replication works w.r.t. ordered partitioning. If I am misremembering and start keys are duplicated, we can just return a sorted set instead of a sorted array. This satisfies property 4 because we are slicing along the seams given us by the nodes themselves. = Back To The Game Right, so that's the first pass. What sucks about this? What rules about it? Questions? [1] http://gist.github.com/150217 -- Jeff",executive
65,"Re: Apache Cassandra fuzz testing > There are many tests that are currently purely manual, and some are just hard to maintain�.. And whenever we add support for, say, UDTs, overnight you'll just get UDTs for all existing tests Yes, something worth really highlighting here is that many of our tests are flaky because we have so many tests, many of low quality, where determinism/reliability has been too costly to deliver. With fewer tests able to cover more functionality, investment in reliability and determinism more easily pay off. Also, by moving to frameworks that have done some of this heavy lifting, it is anyway easier to achieve. I agree that some areas of the codebase might be quite ripe for this kind of work, particularly for more complex CQL features and ones being invested in today, or in the near future. MVs seem an obvious example, as part of work to move them out of experimental status. I�m uncertain if SAI is suitable for use with Harry, but it could be explored. ",not-ak
66,"Re: Apache Cassandra fuzz testing I did not intend to imply that we should migrate all tests. To be more specific than I was, we can pick up only ones where Harry just makes more sense than manual tests, where it can cover more ground. GROUP BY comes to mind as a perfect example: its current test suite is rather limited. Fuzzing it can yield a lot of useful things, with very little risk for flakiness. It can completely replace existing test suite and test many more cases.Another example - SelectTest and many tests like it, which is just a manual way to go through a bunch of cases, while leaving out many other potential edge-cases. TTL tests would be the next example. Range tombstones - yet another. Read repair tests would also be good to expand. Many python dtests that use stress to load data are another potential candidate.There are many tests that are currently purely manual, and some are just hard to maintain. Many of those can be good candidates for switching to property-based. But, as Benedict mentioned, we don't have much bandwidth to migrate the tests anyways.It could be that you are skeptical since you haven't had much experience with Harry just yet. While many features are still missing, it still is more powerful than many existing manually written tests. And whenever we add support for, say, UDTs, overnight you'll just get UDTs for all existing tests, followed by collections, and other things. Moreover, we will be able to see if all our tests pass under failure conditions, and test them with different sets of parameters. Maybe if I reframe it and say that we add fuzz tests for the mentioned areas of code and, if we, at some point in the future, decide that manually-written tests are redundant, we can consider deprecating them. ",existence
67,"Re: Apache Cassandra fuzz testing I�m not sure we have lots of bandwidth for upgrading existing tests anyway. However, the source of flakiness in existing tests is primarily either environmental or poor test design (relying on timings being a major culprit). If Harry were to produce flakiness it would have a higher likelihood of being real problems, and they would be reproducible if the tests were deterministic. The Simulator on the other hand might be helpful for flaky tests, by being deterministic. We might want to develop a JUnitRunner that is backed by the simulator so we can easily switch it on to help diagnose flaky tests, and also for improved testing of concurrent code unit tests. We probably would not want to use it for all tests, however, as it might well slow down execution. ",not-ak
68,Re: Apache Cassandra fuzz testing Benjamin's email could be written by myself :) Fully agree. ,not-ak
69,"Re: Apache Cassandra fuzz testing Thanks a lot for raising that topic Alex.I did not have the chance to use Harry yet and I guess it is the case for most of us.Starting to use it in our new tests makes total sense to me. I am more concerned about starting to migrate/update existing tests. It took us time to build some reliable and non flaky tests to guarantee the correctness of the codebase. As far as I can see from Harry's documentation some features are still missing. The people lack experience with this tool and it will take a bit of time for them to build that knowledge. Along the way we might also discover some issues with Harry that need to be addressed.So I am +1 for starting to use it in our new tests and build our knowledge of Harry. Regarding a migration of existing tests to it, I would wait a bit before choosing to go down that path.��Le�mer. 16 f�vr. 2022 �16:30, benedict@apache.org <benedict@apache.org> a �crit�: +1 � The Simulator is hopefully going to be another powerful tool for this kind of work, and we should be encouraging the use of both for large or complex pieces of work. � � ",not-ak
72,"Re: Apache Cassandra fuzz testing +1 The Simulator is hopefully going to be another powerful tool for this kind of work, and we should be encouraging the use of both for large or complex pieces of work. ",not-ak
73,"Re: Apache Cassandra fuzz testing (apologies for sending an incomplete email) Hi everyone,As you may know, we�ve been actively working on fuzz testing Apache Cassandra for the past several years and made quite a large progress on that front.We�ve cut a 0.0.1 release of Harry [1], a fuzz testing tool for apache Cassandra and merged CASSANDRA-16262 [2].I�d recommend us as a community to take the next logical step and demand fuzz / property-based tests for all marjor patches, and start migrating/updating existing tests to be property-based rather than using hardoced values.Harry can be used to generate data, and then check that a sequence of events corresponds to Cassandra resolution rules. We will continue expanding Harry coverage and writing new models and checkers, too.If you would like to learn more about Harry, you can refer to a recent blog post [3]. I will also be happy to answer any questions you may have about Harry and assist you in writing your tests, and helping to extend Harry in case there�s a feature you may need to accomplish it.Thank you,�Alex[1] [GitHub - apache/cassandra-harry: Apache Cassandra - Harry](https://github.com/apache/cassandra-harry)[2] [CASSANDRA-16262 4.0 Quality: Coordination & Replication Fuzz Testing - ASF JIRA](https://issues.apache.org/jira/browse/CASSANDRA-16262)[3] [Apache Cassandra | Apache Cassandra Documentation](https://cassandra.apache.org/_/blog/Harry-an-Open-Source-Fuzz-Testing-and-Verification-Tool-for-Apache-Cassandra.html)",existence
74,"Apache Cassandra fuzz testing Hi everyone,As you may know, we've been actively working on fuzz testing Apache Cassandra for the past several years and made quite a large progress on that front.",not-ak
2170,Re: [VOTE] Release Apache Cassandra 0.8.0-beta1 artifacts in Maven Central ,not-ak
2171,"Re: [VOTE] Release Apache Cassandra 0.8.0-beta1 artifacts in Maven Central On Thu, 2011-04-28 at 20:42 +0100, Stephen Connolly wrote: +1 -- Eric Evans eevans@rackspace.com",not-ak
2173,"Re: [VOTE] Release Apache Cassandra 0.8.0-beta1 artifacts in Maven Central ping. still waiting for two more +1's from cassandra committers - Stephen --- Sent from my Android phone, so random spelling mistakes, random nonsense words and other nonsense are a direct result of using swype to type on the screen On 29 Apr 2011 14:02, ""Stephen Connolly"" wrote: the not",not-ak
2174,"Re: [VOTE] Release Apache Cassandra 0.8.0-beta1 artifacts in Maven Central OK CQL has been dropped from this release, I need two more binding +1's to release what remains (all & thrift) On 28 April 2011 20:42, Stephen Connolly wrote:",existence
2178,"Re: [VOTE] Release Apache Cassandra 0.8.0-beta1 artifacts in Maven Central ok well I will see about deleting it from the staging repo, can I get a conditional + 1 on that basis? - Stephen --- Sent from my Android phone, so random spelling mistakes, random nonsense words and other nonsense are a direct result of using swype to type on the screen On 28 Apr 2011 20:31, ""Eric Evans"" wrote:",not-ak
2179,"Re: [VOTE] Release Apache Cassandra 0.8.0-beta1 artifacts in Maven Central On Thu, 2011-04-28 at 16:44 +0100, Stephen Connolly wrote: It sounds to me like you need to omit the CQL jar entirely then, and not add it to Maven Central except as a different project. -- Eric Evans eevans@rackspace.com",existence
2180,"Re: [VOTE] Release Apache Cassandra 0.8.0-beta1 artifacts in Maven Central On 28 April 2011 15:23, Eric Evans wrote: This version number is all about versioning the information in the __pom__. The pom defines transitive dependencies. You might not rebuild the cql jar at all, but keep redeploying with different poms (each getting their own version number... because we can only use a version number once)... yes that is somewhat wasteful of space on the central repository, but that's the way it works... [1] The 0.8.0-beta1 version number is only for the coordinates of the pom of cassandra-cql that will pull down the dependencies for using cql with cassandra 0.8.0-beta1. If that subtlety helps you understand the versioning I have chosen for the poms, well that is better. When the next release of cassandra hits, there may be a different tree of dependencies for cql, _even_if_you_don't_modify_a_single_cql_class_, in any case there will be different versions of the artifacts in the dependency tree, so, if you like, you need to release a new version of the dependency metadata for cql with every release of cassandra... at least until you remove the dependencies on cassandra core classes and probably the backing thrift transport. [1] we could do a more optimized space version where we have a shim jar (think manifest only) that is very small and pulls in the cassandra deps and the apache-cassandra-cql-1.0.0 jar but that does not really gain us much, we'd still be deploying a cql jar with every release... just not _the_ apache-cql-1.0.0.jar",executive
2181,"Re: [VOTE] Release Apache Cassandra 0.8.0-beta1 artifacts in Maven Central On Thu, 2011-04-28 at 06:52 +0100, Stephen Connolly wrote: Neither of those is a good reason. The likelihood that that driver won't receive even a minor bug fix (resulting in version 1.0.1) is low but not non-existent, so whatever the process, it shouldn't absolutely require that driver releases occur when Cassandra releases do. It sounds like that is your problem. Unlike the RPC, CQL is meant to be stable. It is a significant feature that you should be able to use the same version of a driver across many versions of Cassandra. This is why the versions must be different, so that you can evaluate each new driver version in the context of how it changed, not (necessarily )how Cassandra changed during some arbitrary release. I don't know if driver releases will be made in the time between Cassandra releases, but I suspect that at some point they probably will be. I don't that every driver will need to be released every time that Cassandra does, they probably won't. None of of this should prevent them all from living in the same tree. -- Eric Evans eevans@rackspace.com",executive
2182,"Re: [VOTE] Release Apache Cassandra 0.8.0-beta1 artifacts in Maven Central On 28 April 2011 00:55, Eric Evans wrote: 1. because that version of the driver has a hard dependency on the other two jars, and because it is still in tree, therefore it is released in sync. 2. I cannot release another 1.0.0 artifact as you cannot overwrite versions in maven central. once you release a version it is released, so unless 0.8.0-beta2 comes with cql 1.0.1 then we are in trouble. You will literally have to increment the cql version for _every single release of the main jars_ or else I will have to make two sets of build targets one which releases cql only and the other which releases everything but cql. That is a messy release process to follow, but if that's what you want... from my PoV, there will be many issues releasing (oh why is this fix for cql not in the new release... yes it is... no it isn't... oh, somebody forgot to increment the cql version when doing the release and you are using maven central) unless you do one of several options: * move cql out of tree (so that it is released on its own schedule... we do this @maven for everything... many trees with many independent release schedules) * tie the cql version to the main tree version (what I did) * make the cql version a combo of the main and the cql version (i.e. 1.0.0-0.8.0-beta1) * keep cql in tree but make the build have two targets, 1st for everything but cql, 2nd for only cql (that will be a mess but it is a solution) We can bemoan Maven Central's policy (you can only release a specific version number once and only once), but that does not solve the issue that users want dependencies from a Maven repository, and Maven's architecture will not re-download a release version because of it's central assumption that releases do not change, so even if you could re-release a 1.0.0, anyone who used the old 1.0.0 would not get the new release (this is why -SNAPSHOTs are different from releases, Maven expects -SNAPSHOTs might change and will check for new versions... but you cannot put -SNAPSHOTs in a release repository) -Stephen",executive
2185,"Re: [VOTE] Release Apache Cassandra 0.8.0-beta1 artifacts in Maven Central On Tue, 2011-04-26 at 14:44 +0100, Stephen Connolly wrote: -1 Why are we making up a different version number for the client code? -- Eric Evans eevans@rackspace.com",not-ak
2188,Re: [VOTE] Release Apache Cassandra 0.8.0-beta1 artifacts in Maven Central +1 ,not-ak
2207,"[VOTE] Release Apache Cassandra 0.8.0-beta1 artifacts in Maven Central Per the Apache release rules, only artifacts which have been voted on can be released. Thus, as I missed the main release vote, I cannot tag onto the end. The artifacts I want to release are: https://repository.apache.org/content/repositories/orgapachecassandra-114/ Notes: * The tar.gz files are different from the main as the -src.tar.gz includes my patch and the -bin.tar.gz has different timestamps on the javadocs (previously I had just been reusing eric's tar.gz's and hacking the patch to no overwrite them... but I think it is better to have the actual source of what is used to generate all the artifacts that make up this staging repo) * I have given the CQL driver jar the same version number as everything else, because it is only going to work with the 0.8.0-beta1 jars anyway. Please vote (see http://www.apache.org/foundation/voting.html#ReleaseVotes) +1: Go ahead and release it 0: I have some issues with the release -1: I have something I think merits re-spinning this release Vote will be open for 72 hours unless the PMC says we can finish quicker and we have met the 3 or more binding +1's minimum -Stephen P.S. I do not have a binding vote at Cassandra, but here is my +1 anyway",executive
1567,"Re: ""Reservation"" ambiguity Thinking more about it, kind of agree with you Chris and Vinod on not removing old metrics in Hadoop-3. Would it be reasonable to keep them around but deprecate them? Or, should we just not mess with them at all? Internal variables could be changed for better readability irrespective; we might end up doing that for FairScheduler anyhow. ",existence
1568,"Re: ""Reservation"" ambiguity It wasn�t confusing to me given we know the internals, but I can see why it would be. In my mind, what existed for a long time was �internal reservation of resources for individual containers within an application� and the newer feature is about user-driven reservation of resources at application / workload granularity. For the newer metrics if/when we add, we should just make the distinction explicit - for e.g. numUserReservedResources. Agreeing with others, this doesn�t warrant us to break existing metrics even in the next major release. Thanks +Vinod On Aug 5, 2015, at 10:16 AM, Carlo Curino > wrote: +1 on keeping the name ""reservation"" for the user-visible (2). On top of the external/internal argument that Chris makes (which I completely agree with), I noticed the following: While developing (2) we spoke with lots and lots of folks both in industry and academia, and the term ""reservation"" was very evocative and intuitive. Within seconds people were using it to refer to the functionality and easily grasping the idea. On the other hand, every time I spoke about (1) using the keyword ""reservation"", I had to add a bunch of context, expand, explain, and even then people were naturally drawn to refer to it as ""hoarding of resources for large containers"", or ""large container management"". Other alternative names for (1) could be: ""hoarded"" or ""prefecthed"" resources. My 2 cents... Cheers, Carlo",existence
1570,"Re: ""Reservation"" ambiguity Inline. ",existence
1571,"Re: ""Reservation"" ambiguity How visible are (1) reservations? They're an internal, implementation detail exposed in metrics only to explain the edge cases they create. Are users typically aware of them? SLA reservations (2) are user-visible, and express the contract with users/operators symmetrically. While (1) is a concept, renaming (2) would require user-breaking code changes. Unless you're discussing the intersection- the effect of reservations (1) on a reservation (2)- it's usually clear from context... I'd rather avoid breaking anyone listening to the metrics in Hadoop-3. Maybe reservations (2) could have been named ""sessions"", but that collided with applications that already used it for a similar concept. -C ",existence
1572,"Re: ""Reservation"" ambiguity On Jul 29, 2015, at 10:37 AM, Karthik Kambatla wrote: Whichever one got checked in first gets �reservation�.",not-ak
1573,"Re: ""Reservation"" ambiguity Sorry for the delayed response. My two cents: 1) ""Hold"" has some ambiguity as a word, since it can be both a noun and a verb. Using ""hold"" in a sentence will be confusing in documentation. 2) Here are some alternatives. Sadly, a lot of these words are quite long and could be painful for coding: - accomodation - allowance - booking - prerequisite - settlement - withholding -Ray ",existence
1575,"""Reservation"" ambiguity Hi folks We use the word ""reservation"" to mean both (1) reservations on nodes to avoid starvation of big container asks, and (2) the recent SLA work. This is confusing both to developers and end-users. I was wondering if people are open to calling the first one a ""hold"" and the second one a ""reservation"". We can change the terminology in the code and add new metrics for hold in branch-2 and remove the metrics for reserved* in Hadoop-3? Thoughts?",existence
1524,"Re: DomainSocket issues on Solaris Alan, thank you for picking up HADOOP-11127. I think it has needed a strong use case to kick it back into action, and maybe Solaris support is that use case. I'll join the discussion on the JIRA. --Chris Nauroth On 10/8/15, 9:40 AM, ""Alan Burlison"" wrote:",not-ak
1525,Re: DomainSocket issues on Solaris ,not-ak
1526,Re: DomainSocket issues on Solaris ,not-ak
1527,Re: DomainSocket issues on Solaris ,not-ak
1528,Re: DomainSocket issues on Solaris ,not-ak
1529,"Re: DomainSocket issues on Solaris Ok, we just hadn't noticed the bridge was on fire...",not-ak
1530,Re: DomainSocket issues on Solaris ,not-ak
1531,"Re: DomainSocket issues on Solaris I just spotted one: HADOOP-10027. A field was removed from the Java layer, which still could get referenced by an older version of the native layer. A backwards-compatible version of that patch would preserve the old fields in the Java layer. Full disclosure: I was the one who committed that patch, so this was a miss by me during the code review. --Chris Nauroth On 10/6/15, 9:03 AM, ""Chris Nauroth"" wrote:",not-ak
1532,"Re: DomainSocket issues on Solaris Alan, would you please list the specific patches/JIRA issues that broke compatibility? I have not been reviewing the native code lately, so it would help me catch up quickly if you already know which specific patches have introduced problems. If those patches currently reside only on trunk and branch-2, then they have not yet shipped in an Apache release. We'd still have an opportunity to fix them and avoid ""dropping the match"" before shipping 2.8.0. Yes, we are aware that binary compatibility goes beyond the function signatures and into data layout and semantics. --Chris Nauroth On 10/6/15, 8:25 AM, ""Alan Burlison"" wrote:",not-ak
1533,Re: DomainSocket issues on Solaris ,not-ak
1534,Re: DomainSocket issues on Solaris ,not-ak
1535,Re: DomainSocket issues on Solaris ,not-ak
1536,"Re: DomainSocket issues on Solaris We've done it before, simply by retaining the older method entry points. Moving from static to instance-specific is a bigger change. If the old entry points are there and retained, even if all uses have been ripped out of the hadoop code, then the new methods will get used. It's just that old stuff will still link. You mean jni code built for java7 isn't guaranteed to work on Java 8? If so, that's not something we knew of �and something to worry about. it arises whenever you try to deploy to YARN any application containing directly or indirectly (e.g. inside the spark-assembly JAR) the Hadoop java classes of a previous Java version. libhadoop is on the PATH of the far end, your app uploads their hadoop JARs, and the moment something tries to use the JNI-backed method you get to see a stack trace. https://issues.apache.org/jira/browse/HADOOP-11064 if you look at the patch there, that's the kind of thing I'd like to see to address your solaris issues. We've covered the bridge in petrol but not quite dropped a match on it. HADOOP-11127, ""Improve versioning and compatibility support in native library for downstream hadoop-common users."" says ""we need to do better here"", which is probably some way of packaging native libs. Now, if you look at our compatibility statement, we don't say anything about native binary linking: http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/Compatibility.html We have managed to avoid addressing this issue to date: the HADOOP-11064 problem was caught before 2.6 shipped, and the patch put in without setting an immutable guarantee of compatibility going forward. We just don't want to light that bridge when a lot of users are on the other side of it. -Steve",executive
1537,Re: DomainSocket issues on Solaris ,not-ak
1538,"Re: DomainSocket issues on Solaris Hi Alan, As Chris commented earlier, the main use of DomainSocket is to transfer file descriptors from the DataNode to the DFSClient. As you know, this is something that can only be done through domain sockets, not through inet sockets. We do support passing data over domain sockets, but in practice we rarely turn it on since we haven't seen a performance advantage. As I see it, you have a few different options here for getting this working on Solaris. 1. Don't get DomainSocket working on Solaris. Rely on the legacy short-circuit read instead. It has poorer security guarantees, but doesn't require domain sockets. You can add a line of code to the failing junit tests to skip them on Solaris. 2. Use a separate ""timer wheel"" thread which implements coarse-grained timeouts by calling shutdown() on domain sockets that have been active for too long. This thread could be global (one per JVM). 3. Implement the poll/select loop you discussed earlier. As Steve commented, it would be easier to do this by adding new functions, rather than by changing existing ones. I don't think ""ifdef skid marks"" are necessary since poll and select are supported on Linux and so forth as well as Solaris. You would just need some code in DomainSocket.java to select the appropriate implementation at runtime based on the OS. Since you commented that Solaris is implementing timeout support in the future, approaches #1 or #2 could be placeholders until that's finished. I agree that there is no formal libhadoop.so compatibility policy and that is frustrating. This has been an issue for those who want to run jars compiled against multiple different versions of hadoop through the same YARN instance. We've discussed it in the past, but never really come up with a great solution. The best approach really would be to bundle libhadoop.so inside the hadoop jar files, so that it could be integral to the Hadoop version itself. However, nobody has done the work to make that happen. The second-best approach would be to include the Hadoop version in the libhadoop name itself (so we'd have libhadoop28.so for hadoop 2.8, and so forth.) Anyway, I think we can solve this particular issue without going down that rathole... best, Colin ",executive
1541,Re: DomainSocket issues on Solaris ,not-ak
1542,"Re: DomainSocket issues on Solaris I don't think anyone would object for the changes, except for one big caveat: a lot of us would like that binary file to be backwards compatible; a Hadoop 2.6 JAR should be able to link to the 2.8+ libhadoop. So whatever gets changed, the old methods are still going to hang around",not-ak
1543,Re: DomainSocket issues on Solaris ,not-ak
1544,Re: DomainSocket issues on Solaris ,not-ak
1545,"Re: DomainSocket issues on Solaris That's an interesting find, though I don't think we'd be able to swap in INET sockets in this part of the code. We use Unix domain sockets to share an open file descriptor from the DataNode process to the HDFS client process, and then the client reads directly from that open file descriptor. I think file descriptor sharing is a capability of Unix domain sockets only, and not INET sockets. As you said, I wouldn't expect throughput on the Unix domain socket to be a bottleneck, because there is very little data transferred. --Chris Nauroth On 9/30/15, 9:12 AM, ""Alan Burlison"" wrote:",existence
1546,Re: DomainSocket issues on Solaris ,not-ak
1547,"Re: DomainSocket issues on Solaris Alan, I also meant to say that I didn't understand the comment about ""in production it seems that DomainSocket is less commonly used"". The current implementation of short-circuit read definitely utilizes DomainSocket, and it's very common to enable this in production clusters. The documentation page you mentioned includes discussion of a legacy short-circuit read implementation, which did not utilize UNIX domain sockets, but the legacy implementation is rarely used in practice now. --Chris Nauroth On 9/30/15, 8:46 AM, ""Chris Nauroth"" wrote:",not-ak
1548,"Re: DomainSocket issues on Solaris Hello Alan, I think this sounds like a reasonable approach. I recommend that you file a JIRA with the proposal (copy-paste the content of your email into a comment) and then wait a few days before starting work in earnest to see if anyone else wants to discuss it first. I also recommend notifying Colin Patrick McCabe on that JIRA. It would be good to get a second opinion from him, since he is the original author of much of this code. --Chris Nauroth On 9/30/15, 1:14 AM, ""Alan Burlison"" wrote:",not-ak
1549,"DomainSocket issues on Solaris Now that the Hadoop native code builds on Solaris I've been chipping away at all the test failures. About 50% of the failures involve DomainSocket, either directly or indirectly. That seems to be mainly because the tests use DomainSocket to do single-node testing, whereas in production it seems that DomainSocket is less commonly used (https://hadoop.apache.org/docs/r2.7.1/hadoop-project-dist/hadoop-hdfs/ShortCircuitLocalReads.html). The particular problem on Solaris is that socket read/write timeouts (the SO_SNDTIMEO and SO_RCVTIMEO socket options) are not supported for UNIX domain (PF_UNIX) sockets. Those options are however supported for PF_INET sockets. That's because the socket implementation on Solaris is split roughly into two parts, for inet sockets and for STREAMS sockets, and the STREAMS implementation lacks support for SO_SNDTIMEO and SO_RCVTIMEO. As an aside, performance of sockets that use loopback or the host's own IP is slightly better than that of UNIX domain sockets on Solaris. I'm investigating getting timeouts supported for PF_UNIX sockets added to Solaris, but in the meantime I'm also looking how this might be worked around in Hadoop. One way would be to implement timeouts by wrapping all the read/write/send/recv etc calls in DomainSocket.c with either poll() or select(). The basic idea is to add two new fields to DomainSocket.c to hold the read/write timeouts. On platforms that support SO_SNDTIMEO and SO_RCVTIMEO these would be unused as setsockopt() would be used to set the socket timeouts. On platforms such as Solaris the JNI code would use the values to implement the timeouts appropriately. To prevent the code in DomainSocket.c becoming a #ifdef hairball, the current socket IO function calls such as accept(), send(), read() etc would be replaced with a macros such as HD_ACCEPT. On platforms that provide timeouts these would just expand to the normal socket functions, on platforms that don't support timeouts it would expand to wrappers that implements timeouts for them. The only caveats are that all code that does anything to a PF_UNIX socket would *always* have to do so via DomainSocket. As far as I can tell that's not an issue, but it would have to be borne in mind if any changes were made in this area. Before I set about doing this, does the approach seem reasonable? Thanks, -- Alan Burlison --",not-ak
1101,"Re: Cassandra pluggable storage engine (update) Hi DuyHai, Good point! At this moment, I do not see anything really prevent us from having one storage engine type per table, we are using one RocksDB instance per table anyway. However, we want to do simple things first, and it's easier for us to have storage engine per keyspace, for both development and our internal deployment. We can revisit the choice if there are strong needs for storage engine per table. Thanks Dikang. ",existence
1102,"Re: Cassandra pluggable storage engine (update) Excellent docs, thanks for the update Dikang. A question about a design choice, is there any technical reason to specify the storage engine at keyspace level rather than table level ? It's not overly complicated to move all tables sharing the same storage engine into the same keyspace but then it makes tables organization strongly tied to technical storage engine choice rather than functional splitting Regards ",existence
1103,"Re: Cassandra pluggable storage engine (update) Hi Blake, Great questions! 1. Yeah, we implement the encoding algorithms, which could encode C* data types into byte array, and keep the same sorting order. Our implementation is based on the orderly lib used in HBase, https://github.com/ndimiduk/orderly . 2. Repair is not supported yet, we are still working on figure out the work need to be done to support repair or incremental repair. Thanks Dikang. ",existence
1104,"Re: Cassandra pluggable storage engine (update) Hi Dikang, Cool stuff. 2 questions. Based on your presentation at ngcc, it seems like rocks db stores things in byte order. Does this mean that you have code that makes each of the existing types byte comparable, or is clustering order implementation dependent? Also, I don't see anything in the draft api that seems to support splitting the data set into arbitrary categories (ie repaired and unrepaired data living in the same token range). Is support for incremental repair planned for v1? Thanks, Blake On October 4, 2017 at 1:28:01 PM, Dikang Gu (dikang85@gmail.com) wrote: Hello C* developers:� In my previous email (https://www.mail-archive.com/dev@cassandra.apache.org/msg11024.html), I presented that Instagram was kicking off a project to make C*'s storage engine to be pluggable, as other modern databases, like mysql, mongoDB etc, so that users will be able to choose most suitable storage engine for different work load, or to use different features. In addition to that, a pluggable storage engine architecture will improve the modularity of the system, help to increase the testability and reliability of Cassandra. After months of development and testing, we'd like to share the work we have done, including the first(draft) version of the C* storage engine API, and the first version of the RocksDB based storage engine. ? For the C* storage engine API, here is the draft version we proposed, https://docs.google.com/document/d/1PxYm9oXW2jJtSDiZ-SR9O20jud_0jnA-mW7ttp2dVmk/edit. It contains the APIs for read/write requests, streaming, and table management. The storage engine related functionalities, like data encoding/decoding format, on-disk data read/write, compaction, etc, will be taken care by the storage engine implementation. Each storage engine is a class with each instance of the class is stored in the Keyspace instance. So all the column families within a keyspace will share one storage engine instance. Once a storage engine instance is created, Cassandra sever issues commands to the engine instance to performance data storage and retrieval tasks such as opening a column family, managing column families and streaming. How to config storage engine for different keyspaces? It's still open for discussion. One proposal is that we can add the storage engine option in the create keyspace cql command, and potentially we can overwrite the option per C* node in its config file. Under that API, we implemented a new storage engine, based on RocksDB, called RocksEngine. In long term, we want to support most of C* existing features in RocksEngine, and we want to build it in a progressive manner. For the first version of the RocksDBEngine, we support following features: Most of non-nested data types Table schema Point query Range query Mutations Timestamp TTL Deletions/Cell tombstones Streaming We do not supported following features in first version yet: Multi-partition query Nested data types Counters Range tombstone Materialized views Secondary indexes SASI Repair At this moment, we've implemented the V1 features, and deployed it to our shadow cluster. Using shadowing traffic of our production use cases, we saw ~3X P99 read latency drop, compared to our C* 2.2 prod clusters. Here are some detailed metrics: https://docs.google.com/document/d/1DojHPteDPSphO0_N2meZ3zkmqlidRwwe_cJpsXLcp10. So if you need the features in existing storage engine, please keep using the existing storage engine. If you want to have a more predictable and lower read latency, also the features supported by RocksEngine are enough for your use cases, then RocksEngine could be a fit for you. The work is 1% finished, and we want to work together with community to make it happen. We presented the work in NGCC last week, and also pushed the beta version of the pluggable storage engine to Instagram github Cassandra repo, rocks_3.0 branch (https://github.com/Instagram/cassandra/tree/rocks_3.0), which is based on C* 3.0.12, please feel free to play with it! You can download it and follow the instructions (https://github.com/Instagram/cassandra/blob/rocks_3.0/StorageEngine.md) to try it out in your test environment, your feedback will be very valuable to us. Thanks Dikang.",existence
1105,"Cassandra pluggable storage engine (update) Hello C* developers:� In my previous email (https://www.mail-archive.com/dev@cassandra.apache.org/msg11024.html), I presented that Instagram was kicking off a project to make C*'s storage engine to be pluggable, as other modern databases, like mysql, mongoDB etc, so that users will be able to choose most suitable storage engine for different work load, or to use different features. In addition to that, a pluggable storage engine architecture will improve the modularity of the system, help to increase the testability and reliability of Cassandra. After months of development and testing, we'd like to share the work we have done, including the first(draft) version of the C* storage engine API, and the first version of the RocksDB based storage engine. ? For the C* storage engine API, here is the draft version we proposed, https://docs.google.com/document/d/1PxYm9oXW2jJtSDiZ-SR9O20jud_0jnA-mW7ttp2dVmk/edit. It contains the APIs for read/write requests, streaming, and table management. The storage engine related functionalities, like data encoding/decoding format, on-disk data read/write, compaction, etc, will be taken care by the storage engine implementation. Each storage engine is a class with each instance of the class is stored in the Keyspace instance. So all the column families within a keyspace will share one storage engine instance. Once a storage engine instance is created, Cassandra sever issues commands to the engine instance to performance data storage and retrieval tasks such as opening a column family, managing column families and streaming. How to config storage engine for different keyspaces? It's still open for discussion. One proposal is that we can add the storage engine option in the create keyspace cql command, and potentially we can overwrite the option per C* node in its config file. Under that API, we implemented a new storage engine, based on RocksDB, called RocksEngine. In long term, we want to support most of C* existing features in RocksEngine, and we want to build it in a progressive manner. For the first version of the RocksDBEngine, we support following features: Most of non-nested data typesTable schemaPoint queryRange queryMutationsTimestampTTLDeletions/Cell tombstonesStreaming We do not supported following features in first version yet: Multi-partition queryNested data typesCountersRange tombstoneMaterialized viewsSecondary indexesSASIRepair At this moment, we've implemented the V1 features, and deployed it to our shadow cluster. Using shadowing traffic of our production use cases, we saw ~3X P99 read latency drop, compared to our C* 2.2 prod clusters. Here are some detailed metrics: https://docs.google.com/document/d/1DojHPteDPSphO0_N2meZ3zkmqlidRwwe_cJpsXLcp10. So if you need the features in existing storage engine, please keep using the existing storage engine. If you want to have a more predictable and lower read latency, also the features supported by RocksEngine are enough for your use cases, then RocksEngine could be a fit for you. The work is 1% finished, and we want to work together with community to make it happen. We presented the work in NGCC last week, and also pushed the beta version of the pluggable storage engine to Instagram github Cassandra repo, rocks_3.0 branch (https://github.com/Instagram/cassandra/tree/rocks_3.0), which is based on C* 3.0.12, please feel free to play with it! You can download it and follow the instructions (https://github.com/Instagram/cassandra/blob/rocks_3.0/StorageEngine.md) to try it out in your test environment, your feedback will be very valuable to us. Thanks Dikang.",property
686,Re: Changing the default Datanode Volume Choosing policy +1 to switch it on in Hadoop 3.4.0 (1) it doesn't break any existing applications I am aware of. (2) No noticeable performance regression in any cases observed. I feel compelled to make a feature the default if it is strictly better. Hopefully we can make Hadoop easier to use in this way too. ,property
687,"Changing the default Datanode Volume Choosing policy Hi, A long time back there was a Jira raised to change the default volume choosing policy from Round Robin to Available Space: https://issues.apache.org/jira/browse/HDFS-8538 At the time there were some objections / concerns about using available space. In the 5 years since then, at Cloudera we have seen about 1000 clusters running with Available Space enabled, and we have not seen any issues caused by it. It feels like this policy should be the default, as we have to change it more often than not. To recap, the Available Space places blocks on disks with more free space with a higher probability until all disks are within a threshold of free space from each other. After that it behaves in a round robin fashion. This means if a disk is replaced, it will slowly catch up to the usage of the others, and if you have disks of different sizes, they will self balance. I would like to ask: 1. Are there others in the community running the Available Space volume choosing policy, and if so, have you seen any issues, or does it run smoothly? 2. Does anyone have any strong objections in changing the default to Available Space from 3.4 onwards? Thanks, Stephen.",existence
2169,Re: [Discuss] Merge federation branch HDFS-1052 into trunk We have been testing federation regularly with MapReduce with yahoo-merge branches. With trunk we missed the contrib (raid). The dependency with project splits has been crazy. Not sure how large changes can keep on top of all these things. I am working on fixing the raid contrib. ,not-ak
2172,Re: [Discuss] Merge federation branch HDFS-1052 into trunk Apparently this merge wasn't tested against MapReduce trunk at all -- MR trunk has been failing to compile for several days. Please see MAPREDUCE-2465. I attempted to fix it myself but don't have enough background in the new federation code or in RAID. -Todd ,not-ak
2175,"Re: [Discuss] Merge federation branch HDFS-1052 into trunk Thanks for clarifying, Owen. Should we have the bylaws somewhere on wiki? --Konstantin ",not-ak
2176,"Re: [Discuss] Merge federation branch HDFS-1052 into trunk Owen, thanks for clarification. I have attached the patch to the jira HDFS-1052. Please use the jira to cast your vote or post objections. If you have objections please be specific on how I can address it and move forward with this issue. Regards, Suresh ",not-ak
2177,"Re: [Discuss] Merge federation branch HDFS-1052 into trunk On Apr 27, 2011, at 10:12 PM, Konstantin Shvachko wrote: This is a code change, just like all of our jiras. The standard rules of at least one +1 on the jira and no -1's apply. Adoption of new codebase is adopting a new subproject or completely replacing trunk. This was clarified in the bylaws back in November. http://mail-archives.apache.org/mod_mbox/hadoop-general/201011.mbox/%3C159E99C4-B71C-437E-9640-AA24C50D636E@apache.org%3E Where it was modified to: Lazy consensus of active committers, but with a minimum of one +1. The code can be committed after the first +1. -- Owen",executive
2183,"Re: [Discuss] Merge federation branch HDFS-1052 into trunk Owen, The question is whether this is a * Code Change, which requires Lazy consensus of active committers or a * Adoption of New Codebase, which needs Lazy 2/3 majority of PMC members Lazy consensus requires 3 binding +1 votes and no binding vetoes. If I am looking at the current bylaws, then it tells me this needs a vote. Did I miss anything? Konstantin ",executive
2184,Re: [Discuss] Merge federation branch HDFS-1052 into trunk Thanks Eli. The merge of latest changes in trunk is not straight forward. I will get it done tonight and post a new patch. That means the earlier the merge can happen is tomorrow. ,not-ak
2186,"Re: [Discuss] Merge federation branch HDFS-1052 into trunk If there are no further issues by tonight, I will merge the branch into trunk. Regards, Suresh ",not-ak
2187,"Re: [Discuss] Merge federation branch HDFS-1052 into trunk Hey Suresh, Do you plan to update the patch on HDFS-1052 soon? Trunk has moved on a little bit since the last patch. I assume we vote on the patch there. I think additional review feedback (beyond what's already been done) can be handled after the code is merged, I know what a pain it is to keep a patch out of mainline. What I've looked at so far looks great btw. For those of you who missed the design doc you should check it out: https://issues.apache.org/jira/secure/attachment/12442372/Mulitple+Namespaces5.pdf Thanks, Eli ",not-ak
2189,"Re: [Discuss] Merge federation branch HDFS-1052 into trunk On Apr 26, 2011, at 11:34 PM, suresh srinivas wrote: Merging a branch back in doesn't require an explicit vote. It is just a code commit. This discussion thread is enough to establish that there is consensus in the dev community. -- Owen",executive
2190,"Re: [Discuss] Merge federation branch HDFS-1052 into trunk On Apr 26, 2011, at 10:40 PM, Konstantin Boudnik wrote: Yes absolutely. We have tested upgrades . Besides our ops will throw us out of the window if we even hint that there isn't an automatic upgrade for the next release :-) sanjay",not-ak
2191,"Re: [Discuss] Merge federation branch HDFS-1052 into trunk Konstantin, Could you provide me link to how this was done on a big feature, like say append and how benchmark info was captured? I am planning to run dfsio tests, btw. Regards, Suresh ",not-ak
2192,"Re: [Discuss] Merge federation branch HDFS-1052 into trunk Konstantin, ",not-ak
2193,Re: [Discuss] Merge federation branch HDFS-1052 into trunk Upgrades from earlier version is supported. The existing configuration should run without any change. ,not-ak
2194,"Re: [Discuss] Merge federation branch HDFS-1052 into trunk Oops, the message came out garbled. I meant to say I assume the outlined changes won't prevent an earlier version of HDFS from upgrades to the federation version, right? Thanks in advance, Cos On Tue, Apr 26, 2011 at 17:59, Konstantin Boudnik wrote:",not-ak
2195,"Re: [Discuss] Merge federation branch HDFS-1052 into trunk Dhruba, It would be very valuable for the community to share your experience if you performed any independent testing of the federation branch. Thanks, --Konstantin ",not-ak
2196,"Re: [Discuss] Merge federation branch HDFS-1052 into trunk Suresh, Sanjay. 1. I asked for benchmarks many times over the course of different discussions on the topic. I don't see any numbers attached to jira, and I was getting the same response, Doug just got from you, guys: which is ""why would the performance be worse"". And this is not an argument for me. 2. I assume that merging requires a vote. I am sure people who know bylaws better than I do will correct me if it is not true. Did I miss the vote? It feels like you are rushing this and are not doing what you would expect others to do in the same position, and what has been done in the past for such large projects. Thanks, --Konstantin ",not-ak
2197,"Re: [Discuss] Merge federation branch HDFS-1052 into trunk Agree. It is a step forward to distributed namespace. Regards, Nicholas ________________________________ From: Dhruba Borthakur To: hdfs-dev@hadoop.apache.org Cc: sradia@yahoo-inc.com; Doug Cutting Sent: Wed, April 27, 2011 12:27:30 AM Subject: Re: [Discuss] Merge federation branch HDFS-1052 into trunk I feel that making the datanode talk to multiple namenodes is very valuable, especially when there is plenty of storage available on a single datanode machine (think 24 TB to 36 TB) and a single namenode does not have enough memory to hold all file metadata for such a large cluster in memory. This is a feature that we are in dire need of, and could put it to good use starting ""yesterday""! thanks, dhruba ",not-ak
2198,"Re: [Discuss] Merge federation branch HDFS-1052 into trunk Suresh, Sanjay, Thank you very much for addressing my questions. Cheers, Doug On 04/26/2011 10:29 AM, suresh srinivas wrote:",not-ak
2199,"Re: [Discuss] Merge federation branch HDFS-1052 into trunk I feel that making the datanode talk to multiple namenodes is very valuable, especially when there is plenty of storage available on a single datanode machine (think 24 TB to 36 TB) and a single namenode does not have enough memory to hold all file metadata for such a large cluster in memory. This is a feature that we are in dire need of, and could put it to good use starting ""yesterday""! thanks, dhruba ",not-ak
2200,"Re: [Discuss] Merge federation branch HDFS-1052 into trunk Sanjay, I assume the outlined changes won't an earlier version of HDFS from upgrads to the federation version, right? Cos On Tue, Apr 26, 2011 at 17:26, Sanjay Radia wrote:",not-ak
2201,"Re: [Discuss] Merge federation branch HDFS-1052 into trunk On Apr 25, 2011, at 2:36 PM, Doug Cutting wrote: Doug, There are two separate issues; your email seems to suggest that these are joined. (1) creating (or not ) a unified namespace (2) sharing the storage and the block storage layer across NameNodes - the architecture document covers this layering in great detail. This separation reflects architecture of HDFS (derived from GFS) where the namespace layer is separate from the block storage layer (although the HDFS implementation violates the layers in many places). HDFS-1052 deals with (2) - allowing multiple NameNodes to share the block storage layer. As far as (1), creating a unified namespace, federation does NOT dictate how you create a unified namespace or whether you even create a unified namespace in the first place. Indeed you may want to share the physical storage but want independent namespaces. For example, you may want to run a private namespace for HBase files within the same Hadoop cluster. Two different tenants sharing a cluster may choose to have their independent namespaces for isolation. Of course in many situations one wants to create a unified namespace. One could create a unified namespace using symbolic links as you suggest. The federation work has also added client-side mount tables (HDFS-1053) (it is an implementation of FileSystem and AbstractFileSystem). It offers advantages over symbolic links but this is separable and you can use symbolic links if you like. HDFS-1053 (client-side mount tables) makes no changes to any existing file system. Now getting to (2), sharing the physical storage and the block storage layer. The approach you describe (run multiple DNs on the same machine which is essentially multiple super-imposed HDFS clusters) is the most common reaction to this work and one which we also explored. Unfortunately this approach runs into several issues and when you start exploring the details you realize that it is essentially a hack. - Extra processes running the DN on the same machine taking precious memory away from MR tasks. - Independent pools of threads for each DN - Not being able to schedule disk operations across multiple DNs - Not being able to provide a unified view of balancing or decommissioning. For example, one could run multiple balancers but this will give you less control of bandwidth used for balancing. - The disk-fail-in-place work and the balance-disks-on-introducing-a- new-disk would become more complicated to coordinate across DNs. - Federation allows the cluster to be managed as a unit rather then as a a bunch of overlapping HDFS clusters. Overlapping HDFS clusters will be operationally taxing. On the other hand, the new architecture generalizes the block storage layer and allow us to evolve it to address new needs. For example, it will allow us to address issues like offering tmp storage for intermediate MR output - one can allocate a block pool for MR tmp storage on each DN. HBase could also use the block storage layer directly without going through a name node. Changes to the code base - The fundamental code change is to extend the notion of block id to now include a block pool id. - The NN had little change, the protocols did change to include the block pool id. - The DN code did change. Each data structure is now indexed by the block pool id -- while this is a code change, it is architecturally very simple and low risk. - We also did a fair amount of cleanup of threads used to send block reports - while it was not strictly necessary to do the cleanup we took the extra effort to pay the technical debt. As Dhruba recently noted, adding support to send block reports to primary and secondary NN for HA will be now much easier to do. The write and read pipelines - which are performance critical, have NOT changed. Risk, Quality & Testing Besides the amount of code change one has to ask the fundamental question: how good is the design and how is the project managed. Conceptually, federation is very simple: pools of blocks are owned by a service (a NN in this case) and the block id is extended by an identifier called the block-pool id. First and foremost - we wrote a very extensive architecture document - more comprehensive than any other document in Hadoop in the past. This was published very early: version 1 in march 2010 and version 5 in april 2010 based on feedback we received from the community. We sought and incorporated feedback from other HDFs developers outside of Yahoo. The project was managed as a separate branch rather than introduce the code to trunk incrementally. The branch has also been tested as a separate unit by us - this ensures that it does not destabilize trunk. More details on testing. The same QA process that drove and tested key stable Apache Hadoop releases (16, 17, 18, 20, 20-security) is being used for testing the federation feature. We have been running integrated tests with federation for a few months and continue to do so. We will not deploy a Hadoop release with the federation feature in Yahoo clusters until we are confident that it is stable and reliable for our clusters. Indeed the level of testing is significantly more than in previous releases. Hopefully the above addresses your concerns. regards sanjay",executive
2202,"Re: [Discuss] Merge federation branch HDFS-1052 into trunk Doug, please reply back. I am planning to commit this by tonight, as I would like to avoid unnecessary merge work and also avoid having to redo the merge if SVN is re-organized. ",not-ak
2203,"Re: [Discuss] Merge federation branch HDFS-1052 into trunk Doug, Federation is complementary with symlink approach. You could choose to provide integrated namespace using symlinks. However, client side mount tables seems a better approach for many reasons: # Unlike symbolic links, client side mount tables can choose to go to right namenode based on configuration. This avoids unnecessary RPCs to the namenodes to discover the targer of symlink. # The unavailability of a namenode where a symbolic link is configured does not affect reaching the symlink target. # Symbolic links need not be configured on every namenode in the cluster and future changes to symlinks need not be propagated to multiple namenodes. In client side mount tables, this information is in a central configuration. If a deployment still wants to use symbolic link, federation does not preclude it. and run multile datanode processes per storage box There are several advantages to using a single datanode: # When you have large number of namenodes (say 20), the cost of running separate datanodes in terms of process resources such as memory is huge. # The disk i/o management and storage utilization using a single datanode is much better, as it has complete view the storage. # In the approach you are proposing, you have several clusters to manage. However with federation, all datanodes are in a single cluster; with single configuration and operationally easier to manage. which the performance and reliability of most other components of the ecosystem depend. That is not true. # Namenode is mostly unchanged in this feature. # Read/write pipelines are unchanged. # The changes are mainly in datanode: #* the storage, FSDataset, Directory and Disk scanners now have another level to incorporate block pool ID into the hierarchy. This is not a significant change that should cause performance or stability concerns. #* datanodes use a separate thread per NN, just like the existing thread that communicates with NN. As regards to testing, we have passed 600+ tests. In hadoop, these tests are mostly integration tests and not pure unit tests. While these tests have been extensive, we have also been testing this branch for last 4 months, with QA validation that reflects our production environment. We have found the system to be stable, performing well and have not found any blockers with the branch so far. HDFS-1052 has been open more than a year now. I had also sent an email about this merge around 2 months ago. There are 90 subtasks that have been worked on last couple of months under HDFS-1052. Given that there was enough time to ask these questions, your email a day before I am planning to merge the branch into trunk seems late! -- Regards, Suresh",existence
2208,"Re: [Discuss] Merge federation branch HDFS-1052 into trunk On 04/22/2011 09:48 AM, Suresh Srinivas wrote: A couple of questions: 1. Can you please describe the significant advantages this approach has over a symlink-based approach? It seems to me that one could run multiple namenodes on separate boxes and run multile datanode processes per storage box configured with something like: first datanode process configuraton fs.default.name = hdfs://nn1/ dfs.data.dir = /drive1/nn1/,drive2/nn1/... second datanode process configuraton fs.default.name = hdfs://nn2/ dfs.data.dir = /drive1/nn2/,drive2/nn2/... ... Then symlinks could be used between nn1, nn2, etc to provide a reasonably unified namespace. From the benefits listed in the design document it is not clear to me what the clear, substantial benefits are over such a configuration. 2. How much testing has been performed on this? The patch modifies much of the logic of Hadoop's central component, upon which the performance and reliability of most other components of the ecosystem depend. It seems to me that such an invasive change should be well tested before it is merged to trunk. Can you please tell me how this has been tested beyond unit tests? Thanks! Doug",not-ak
2209,"Re: [Discuss] Merge federation branch HDFS-1052 into trunk Given that we will be re-organizing the svn tree very soon and the fact that the design and most of the implementation is complete, let's merge it into trunk! -dhruba ",not-ak
2210,"[Discuss] Merge federation branch HDFS-1052 into trunk A few weeks ago, I had sent an email about the progress of HDFS federation development in HDFS-1052 branch. I am happy to announce that all the tasks related to this feature development is complete and it is ready to be integrated into trunk. I have a merge patch attached to HDFS-1052 jira. All Hudson tests pass except for two test failures. We will fix these unit test failures in trunk, post merge. I plan on completing merge to trunk early next week. I would like to do this ASAP to avoid having to keep the patch up to date (which has been time consuming). This also avoids need for re-merging, due to SVN changes proposed by Nigel, scheduled late next week. Comments are welcome. Regards, Suresh",not-ak
1465,"Re: Google Cloud Storage connector into Hadoop See also the HCFS wiki page https://wiki.apache.org/hadoop/HCFS/Progress which attempts to explain this stuff for the community, maybe it needs some updates as well, i haven't looked in a while as ive moved onto working on other products nowadays ",not-ak
1477,"Re: Google Cloud Storage connector into Hadoop 1. do what chris says: go for the abstract contract tests. They'll find the troublespots in your code, like the way seek(-1) appears to have entertaining results, what happens on operations to closed files, etc, and help identify where the semantics of your FS varies from HDFS. 2. You will need to stay with the versions of artifacts in the Hadoop codebase. Troublespots there are protobuf (frozen @ 2.5) and guava (shipping with 11.02, code must run against 18.x + if someone upgrades). If this is problematic you may want discuss the versioning issues there with your colleagues; see https://issues.apache.org/jira/browse/HADOOP-10101 for the details. 3. the object stores get undertested: jenkins doesn't touch them for patch review or nightly runs �you can't give jenkins the right credentials. Setting up your own jenkins server to build the Hadoop versions and flag problems would be a great contribution here. Also: help with the release testing; if someone has a patch for the hadoop-gcs module, review and test that too would be great; stops these patches being neglected. 4. We could do with some more scale tests of the object stores, to test creating many thousands of small files, etc. Contributions welcome 5. We could do with a lot more downstream testing of things like hive & spark IO on object stores, especially via ORC and Parquet. Helping to write those tests would stop regressions in the stack, and help tune Hadoop for your FS. 6. Finally: don't be afraid to get involved with the rest of the codebase. It can only get better.",existence
1478,"Re: Google Cloud Storage connector into Hadoop Haohui & Chris, Sounds great, thank you very much! We'll cut a JIRA once we get everything lined up. Best, James ",not-ak
1479,"Re: Google Cloud Storage connector into Hadoop Hi James, This sounds great! Thank you for considering contributing the code. Just seconding what Haohui said, there is existing precedent for alternative implementations of the Hadoop FileSystem in our codebase. We currently have similar plugins for S3 [1], Azure [2] and OpenStack Swift [3]. Additionally, we have a suite of FileSystem contract tests [4]. These tests are designed to help developers of alternative file systems assess how closely they match the semantics expected by Hadoop ecosystem components. Many Hadoop users are accustomed to using HDFS instead of these alternative file systems, so none of the alternatives are on the default Hadoop classpath immediately after deployment. Instead, the code for each one is in a separate module under the ""hadoop-tools"" directory in the source tree. Users who need to use the alternative file systems take extra steps post-deployment to add them to the classpath where necessary. This achieves the dependency isolation needed. For example, users who never use the Azure plugin won't accidentally pick up a transitive dependency on the Azure SDK jar. I recommend taking a quick glance through the existing modules for S3, Azure and OpenStack. We'll likely ask that a new FileSystem implementation follow the same patterns if feasible for consistency. This would include things like using the contract tests, having a provision to execute tests both offline/mocked and live/integrated with the real service and providing a documentation page that explains configuration for end users. For now, please feel free to file a HADOOP JIRA with your proposal. We can work out the details of all of this in discussion on that JIRA. Something else to follow up on will be licensing concerns. I see the project already uses the Apache license, but it appears to be an existing body of code initially developed at Google. That might require a Software Grant Agreement [5]. Again, this is something that can be hashed out in discussion on the JIRA after you create it. [1] http://hadoop.apache.org/docs/r2.7.1/hadoop-aws/tools/hadoop-aws/index.html [2] http://hadoop.apache.org/docs/r2.7.1/hadoop-azure/index.html [3] http://hadoop.apache.org/docs/r2.7.1/hadoop-openstack/index.html [4] http://hadoop.apache.org/docs/r2.7.1/hadoop-project-dist/hadoop-common/file system/testing.html [5] http://www.apache.org/licenses/ --Chris Nauroth On 12/7/15, 3:10 PM, ""Haohui Mai"" wrote:",existence
1480,"Re: Google Cloud Storage connector into Hadoop Hi, Thanks for reaching out. It would be great to see this in the Hadoop ecosystem. In Hadoop we have AWS S3 support. IMO they address similar use cases thus I think that it should be relatively straightforward to adopt the code. The only catch in my head right now is to properly isolate dependency. Not only the code needs to be put into a separate module, but many Hadoop applications also depend on different versions of Guava. I think it might be a problem that needs some attentions at the very beginning. Please feel free to reach out if you have any other questions. Regards, Haohui ",not-ak
1481,"Google Cloud Storage connector into Hadoop Hello, We're from a team within Google Cloud Platform focused on OSS and data technologies, especially Hadoop (and Spark.) Before we cut a JIRA for something we�d like to do, we wanted to reach out to this list to ask a two quick questions, describe our proposed action, and check for any major objections. Proposed action: We have a Hadoop connector[1] (more info[2]) for Google Cloud Storage (GCS) which we have been building and maintaining for some time. After we clean up our code and tests to conform (to these[3] and other requirements) we would like to contribute it to Hadoop. We have many customers using the connector in high-throughput production Hadoop clusters; we�d like to make it easier and faster to use Hadoop and GCS. Timeline: Presently, we are working on the beta of Google Cloud Dataproc[4] which limits our time a bit, so we�re targeting late Q1 2016 for creating a JIRA issue and adapting our connector code as needed. Our (quick) questions: * Do we need to take any (non-coding) action for this beyond submitting a JIRA when we are ready? * Are there any up-front concerns or questions which we can (or will need to) address? Thank you! James Malone On behalf of the Google Big Data OSS Engineering Team Links: [1] - https://github.com/GoogleCloudPlatform/bigdata-interop/tree/master/gcs [2] - https://cloud.google.com/hadoop/google-cloud-storage-connector [3] - https://github.com/GoogleCloudPlatform/bigdata-interop/tree/master/gcs [4] - https://cloud.google.com/dataproc",executive
2269,"Re: Keyspace Keyspace1 doesnot exist On Wed, Apr 7, 2010 at 05:41, shirish wrote There exists a JMX method in StorageServiceMBean that can be used to load the schema from XML for a brand new node. I'm in the process of documenting these things on the wiki: http://wiki.apache.org/cassandra/LiveSchemaUpdates Gary.",existence
2270,"Re: Keyspace Keyspace1 doesnot exist Thanks Jonathan, I am cleaning up the mess :) downloading development release 0.6.0-rc1. ",not-ak
2271,Re: Keyspace Keyspace1 doesnot exist this is because of https://issues.apache.org/jira/browse/CASSANDRA-44. you probably shouldn't be running trunk. ,not-ak
2272,"Re: Keyspace Keyspace1 doesnot exist Hello , and one more thing the startup message at node says : Couldn't detect any schema definitions in local storage. I hope you've got a plan.",not-ak
2273,"Keyspace Keyspace1 doesnot exist Test Cluster false org.apache.cassandra.locator.RackUnawareStrategy 1 org.apache.cassandra.locator.EndPointSnitch org.apache.cassandra.auth.AllowAllAuthenticator <!-- ~ Partitioner: any IPartitioner may be used, including your own as long ~ as it is on the classpath. Out of the box, Cassandra provides ~ org.apache.cassandra.dht.RandomPartitioner, ~ org.apache.cassandra.dht.OrderPreservingPartitioner, and ~ org.apache.cassandra.dht.CollatingOrderPreservingPartitioner. ~ (CollatingOPP colates according to EN,US rules, not naive byte ~ ordering. Use this as an example if you need locale-aware collation.) ~ Range queries require using an order-preservin",not-ak
298,"Re: [DISCUSS] CEP 14: Paxos Improvements Just wanted to mention that I am super eager to see your proposal implemented, Benedict. Thanks for pushing this forward :-) Le mer. 25 ao�t 2021 � 10:29, benedict@apache.org a �crit :",not-ak
299,"Re: [DISCUSS] CEP 14: Paxos Improvements Jeff, Benedict, we�ve taken your thoughts on this on board and will probably plan to repair in between scaling. The point about speculative retry did get me thinking. Many thanks for the tip and the explanation!",not-ak
300,"Re: [DISCUSS] CEP 14: Paxos Improvements I�ll move this to a vote in a day or so, assuming no further discussion. ",not-ak
301,"Re: [DISCUSS] CEP 14: Paxos Improvements I don�t see how Your best chance is with snitch games And those don�t guarantee correctness if a single replica GC pauses and forces a speculative retry --------------------------------------------------------------------- To unsubscribe, e-mail: dev-unsubscribe@cassandra.apache.org For additional commands, e-mail: dev-help@cassandra.apache.org",not-ak
302,Re: [DISCUSS] CEP 14: Paxos Improvements We think we have a way to do this using certain settings in the Java driver. Agree on your other points!,not-ak
303,Re: [DISCUSS] CEP 14: Paxos Improvements This stood out to me: I'm a strong +1 on this. The less clients have to know about their powerful and complex distributed database and still gain the benefits of it the better. ~Josh ,not-ak
304,"Re: [DISCUSS] CEP 14: Paxos Improvements The problem is that today there�s no way to reliably exclude the new DC from serving reads, that I know of? If you can, then yes you would only need to ensure repair were run prior to activating reads from this DC. I think this is unlikely, particularly as we start to consider things like consensus - at least any time soon. Quorums are quite intricately woven into any implementation, and it would be quite hard to fully generalise them. In practice we can probably accommodate any simple vote threshold quorums (those where some electorate each have a vote, and each vote has an equal weight that reaches consensus once a threshold is crossed) and support at least one level of nesting (so that DCs may logically vote as a block based on some quorum within a DC) in any topology without a plugin system, and I suspect this will be more than enough for any system in the foreseeable future. There are some practicalities that probably prohibit us from eliminating user provided CLs, but I would like to see them phased out as far as possible as they are very hard to verify. To support this flexibility more generally I�d prefer to see tables offer potentially multiple consensus schemes with potentially different qualities (that can perhaps even be named by the user) for these cases, such as (for instance) fast-and-inconsistent-reads. This still permits their properties to be vetted by the database while offering flexibility to the user, and for them to declare at the operator level what meeting this concept requires. It also means the database can maintain these properties through any topology change. But we�ll probably have people using legacy CLs for another decade, so we�re going to have to support people querying with those CLs, but we might want to encourage people to disable them on their clusters and migrate to safer setups. ",existence
305,"Re: [DISCUSS] CEP 14: Paxos Improvements Many thanks for this detailed response Benedict. I look forward to seeing the forthcoming proposals in relation to schema change safety when LWTs are in use. We have been following almost the scale-by-one workaround you described - I am grateful for the additional validation. The only divergence is that we have not been advising a repair in between each node addition. My initial testing suggestedit was not required (when the new DC is not serving reads). But if you are aware of issues that arise at scale then I�d love to hear your experience, as we are still in the planning phase for that project. Regarding CLs (off topic) I agree with your points here. I�d add that the geographical location of DCs can be relevant. Perhaps the CL mechanism could be pluggable (in the same way that authn/z both are) so that we can experiment in this area at higher velocity? (I appreciate this is an invasive change.) A colleague and I are considering whether we might be able to look at the EACH_QUORUM idea in the shorter term. We will share more if we have the bandwidth to undertake the work. I also agree that CLs defined for tables is a worthy enhancement, I wonder if it should be a �default CL� which can additionally be overridden by queries? In any event I feel I�ve hijacked your thread enough, but thank you again for the warm welcome and the interesting discussion!",not-ak
306,"Re: [DISCUSS] CEP 14: Paxos Improvements Hello and welcome! So this is a really complicated topic, unfortunately, but the simple answer is that as currently formulated this work won�t address this particular case. The slightly longer answer is that this problem will be a thing of the past soon either way - there�s work incoming to address every possible category of this kind of problem, but it might take a little longer. The full answer is that membership of a keyspace in Cassandra is a mess, and is derived from the intersection of two things: schema and gossip. The electorate verification addresses _gossip_ inconsistencies, that is, inconsistencies about what nodes are perceived to be a member of the ring. Schema generates the issue you are discussing here. In particular the lack of any state machine that transitions from one topology to another when a new schema implies a new topology. This is its own distinct problem, that others I work with plan to file a CEP for in the coming weeks or months. In the meantime, the correct way to do this (painful though it might be) is to add one node at a time. So instead of adding DC2 at RF=3, add DC2 at RF=1 and wait for that to settle, *run repair* and then bump to RF=2, etc. To respond to Mick: we could introduce an EACH_SERIAL which would permit this to be done in one go. This isn�t a super complicated piece of work, and I�d be happy to help review a contribution here. However, in my view we should be reconsidering how quorums are decided more comprehensively. This is very off-topic, but there are other more sensible quorums for multi-region setups (such as quorum-of-quorums), but also there�s a wide range of useful quorums we don�t support, particularly heterogenous ones supporting lower write failure tolerance than read failure tolerance (for instance). Today we support only the most extreme versions of this, and all of our quorums must be mixed manually by clients which is error prone. In my opinion we should be moving towards specifying quorums on a per-table basis for reads and writes, so that clients do not specify their consistency levels. This way the database can configure arbitrary quorums, and also guarantee that these quorums provide the desired consistency. ",existence
307,"Re: [DISCUSS] CEP 14: Paxos Improvements On 2021/08/20 07:07:00, Mick Semb Wever wrote: Apologies, this repeats Miles' question, which I didn't see until now. --------------------------------------------------------------------- To unsubscribe, e-mail: dev-unsubscribe@cassandra.apache.org For additional commands, e-mail: dev-help@cassandra.apache.org",not-ak
308,"Re: [DISCUSS] CEP 14: Paxos Improvements Benedict, possibly off-topic, but are there any plans or thoughts around adding EACH_SERIAL ? A number of users have enquired about this, having to deal with edge cases when changing replication between two DCs, for example when migrating to and decommissioning DCs.",not-ak
309,"Re: [DISCUSS] CEP 14: Paxos Improvements Long time listener, first time caller here - hello! I am very interested in this part ""Better safety among range movements: Electorate verification during range movements provides a stronger assertion of linearizability via assurance of the set of instances voting on a transaction.� I have seen issues in the wild where people want to add/remove DCs. I think that there may be a risk consistency violations due to transactions circumventing the locks held by in-progress transactions. Will electorate verification help in the below scenario? Queries are running at SERIAL, writing at EACH_QUORUM against DC1 at RF=3. DC2 is added, and once all nodes are in UN the schema is adjusted so that DC2�s RF=3. While the new schema propagates, there is a transitional state, in which some potential coordinators have the new schema S2, and others are operating on the old schema S1. In this state, S2 form consensus from 4/6 nodes, while S1 coordinators form consensus from 2/3 nodes. A query issued from an S1 coordinator can form a valid consensus which will circumvent the lock held by an S2 coordinator. I was thinking of proposing an EACH_QUORUM serial CL, but if electorate verification solves the problem then that may be the better solution. Miles",not-ak
310,"Re: [DISCUSS] CEP 14: Paxos Improvements So this is essentially just a reporting mechanism for when an operation encounters state that should be impossible � this will have been left behind by prior operations, so the damage is already done and there�s no reason to throw an exception and fail the current one. I should also make clear this _isn�t_ a guarantee of spotting violations, but it�s quite sensitive and much better than nothing. In a real system the most likely cause of this kind of impossible state would be e.g. mixing SERIAL with LOCAL_SERIAL, which is not safe unless you perform a really intricate dance, but we can distinguish this case from real bugs. :D ",existence
311,"Re: [DISCUSS] CEP 14: Paxos Improvements I'm curious about this: ""We will introduce mechanisms to spot and log linearizability violations for the user to file as bug reports"" Why not throw an exception? Maybe it's just I don't quite see how this will be detected. I think this is very interesting though. Also, way to sell the next discussion Benedict :D Patrick ",not-ak
312,"Re: [DISCUSS] CEP 14: Paxos Improvements Hi Jeremy, That�s a great question, and the answer is that we shouldn�t compare the two as they aren�t in conflict. The goal of this work is only to improve the existing Paxos implementation � the characteristics are identical besides being faster, so this is a simple and safe upgrade route for users in the short to medium term. Watch this space for a follow up discussion very soon about what we can do to modernise transactions in Cassandra more generally, and what this might mean for how we perform consensus. A comparative discussion of EPaxos and other related work is very well suited to that topic, in my opinion. ",existence
313,"Re: [DISCUSS] CEP 14: Paxos Improvements It sounds like a great improvement! Just for those who had followed the development of ePaxos* that Blake and others worked on but was never committed, it would be nice to briefly compare the two. https://issues.apache.org/jira/browse/CASSANDRA-6246",not-ak
314,"Re: [DISCUSS] CEP 14: Paxos Improvements Benedict, thank you for sharing this CEP! Adding some notes on why I support this proposal: - Reducing common-case round trips from 4x to 2x on writes and 2x to 1x on reads is a huge improvement. This latency reduction may be sufficient to allow many users of Cassandra who operate in a single datacenter, availability zone, or region to migrate to a multi-region topology. - The Cluster Simulation work described in CEP-10 provides a toolchain for probabilistically-exhaustive validation and simulation of transactional correctness, allowing assertion of linearizability in the presence of adversarial thread scheduling and message ordering over an unbounded number of simulated clusters and transactions. - Some use cases may see a superlinear increase in LWT performance due to a reduction in contention afforded by fewer message round-trips. E.g., halving latency shortens the interval during which competing transactions may conflict, reducing contention and improving throughput beyond a level that would be afforded by the latency reduction alone. - Better safety among range movements: Electorate verification during range movements provides a stronger assertion of linearizability via assurance of the set of instances voting on a transaction. � Scott ________________________________________ From: benedict@apache.org Sent: Wednesday, August 18, 2021 2:31 PM To: dev@cassandra.apache.org Subject: [DISCUSS] CEP 14: Paxos Improvements RE: https://cwiki.apache.org/confluence/display/CASSANDRA/CEP-14%3A+Paxos+Improvements I�m proposing this CEP for approval by the project. The goal is to both improve the performance of LWTs and to ensure their correctness across a range of scenario like range movements. This work builds upon the Simulator CEP that has been recently adopted, and patches will follow in the coming weeks. If you have any concerns or questions please raise them here for discussion. --------------------------------------------------------------------- To unsubscribe, e-mail: dev-unsubscribe@cassandra.apache.org For additional commands, e-mail: dev-help@cassandra.apache.org",existence
315,"[DISCUSS] CEP 14: Paxos Improvements RE: https://cwiki.apache.org/confluence/display/CASSANDRA/CEP-14%3A+Paxos+Improvements I�m proposing this CEP for approval by the project. The goal is to both improve the performance of LWTs and to ensure their correctness across a range of scenario like range movements. This work builds upon the Simulator CEP that has been recently adopted, and patches will follow in the coming weeks. If you have any concerns or questions please raise them here for discussion.",not-ak
2411,"Re: HBase Design Ideas, Part I Hi, sorry for the delay in responding... I didn't got this. How you want to associate than one key - value pair ( let's name it cell) to a row key? As mentioned I see a object ""rowKey - columnName - value"" or one rowKey - columnKey-Value[] Hmm, I'm not sure if I like the idea of having size based separated files of columns. I don't think there are many use cases where people will store lets say locales and video files associated to the same url row key. In such a case it makes more sense to have separated tables. From my point of view the best way would be to have a kind of column seek mechanism, what will require a other kind of sequence writer and reader. As far I remember the google system has all columns of a row in one tablet. What you think about to beeing able have one row in different tablets but each tablet has different rows? So not just distribute the rows but also columns. Yes, the later is better from my point of view. That is a good idea. Make sense. May be the local Region Server just request to be spitted and the master handle the split itself. My concern is that just using heart beats to announce regions to the master is not fast enough. Means when region is splitted all rows need to be read only during the process. The master need to know the two new regions before we remove the write lock. Yes, reading files from DFS is too slow, we ran into the same performance problem to often in the several projects. For example reading a lucene index file - as nutch does - from dfs is just useless. But loading a copy to the local hdd is fast enough during startup. In general I don't think disk space is an issue these days, so I have no problem to have data replicated in the dfs and on a local hdd.",existence
2412,"Re: HBase Design Ideas, Part I Hi Stefan, Thanks for your mail. Comments below. On 5/15/06, Stefan Groschupf wrote: What about this: don't store explicit ""column"" fields anywhere. Rather, each row is stored as a series of key-value pairs, where the key is the column name. True, if there are a huge number of columns and you are interested in just one, there will be unnecessary processing. This is especially bad if one column is a 2-char string and another column is a video file. So we should actually keep a family of files, segmented by object size. But in the general case, it shouldn't be possible to ""seek to a column"". Instead, you seek to a row and unpack all its key/val (col/cell) pairs. Do you mean that a lock applies to an entire server at once? Or that an HRegionServer is responsible for all locks? (I'd like to do the latter, at least in the short-term.) I'd like to avoid having an HRegion that's hosted by multiple servers, because then it's unclear which HRegionServer should own the lock. I suppose the HRegionServers for a given HRegion could hold an election, but this seems like a lot of work. If there's a row that's really ""hot"" and wanted by a lot of clients, I could imagine starting a series of ""read-only"" HRegionServers that field read requests. That way you avoid having an election for the lock but can still scale capacity if necessary. (I don't think we'll ever have a situation where a flood of writes come in the door. If so, the whole design is a bad idea!) There are two ways that an HRegionServer might offer brand-new service for an HRegion: 1) The HRegion's old HRegionServer died. A new HRegionServer offers the exact same HRegion, loaded from a DFS file. This will have to be initiated by the HBaseMaster, because it is the only node that knows about heartbeats. 2) An HRegion is getting too big, and must be split into two. I imagine that this can be initiated by the local HRegionServer, which then asks the master for various hints (like where there is another lightly-loaded HRegionServer that could take a new Region). My idea was to simply download the data to the node and read any time You mean just keep a local cache of the DFS file? That might be a good idea for a feature we add into DFS as a performance enhancement. My idea was in such a case the HRegionServer may be know the new The old HRegionServer may not know the new location, depending on how the new one was created. (The old one might be dead, too!) But if we can speed things up substantially by forwarding the location, I think that's OK.",existence
2413,"Re: HBase Design Ideas, Part I On 5/14/06, Eric Baldeschwieler wrote: Sorry, maybe the text was confusing. I didn't mean for a client to ever directly read a DFS file. The stored files should only be served by HRegionServers, directly to clients. Clients might have to go through a level of indirection to find the right HRegionServer, but that should only happen once before being cached. I imagine in practice that most of the key-->HRegionServer mapping will end up being cached in memory. As I read you design, it sounds like you might be doing a lot of Checking for the existence of a key should require at most one sort. To check for the presence of a key, you need to locate the relevant HRegionServer, then test to see if the key is stored there. The suggestion is to keep most data in read-only files where the start and end keys for a page are stored in an external map. True, you need a seek to test for the existence of a key, but there's no way to avoid that unless all keys are stored in memory. Items are stored in-order, so linear scans will be very quick. You never edit one of these structures in place. Edits are kept in memory and periodically logged to disk. Every so often, we generate a brand-new read-only structure by merging the logs and the existing read-only structure. Writes are fast, being logged to memory and lazily to disk. A read lookup takes at most one disk seek. A scan is very efficient, requiring no unnecessary seeks. Read operations may become a little complicated, as we have to integrate the read-only structure, the log files, and the memory buffer. However, since all of these extra operations will be in-memory, there should be no problem performance-wise. (One thing to worry about is the edits that have been logged to disk already. We should probably compact often enough so that edits can always fit in memory comfortably.) On May 14, 2006, at 3:00 PM, Michael Cafarella wrote:",existence
2414,"Re: HBase Design Ideas, Part I May be we can define protocols and interfaces first and based on that people can implement. Stefan",not-ak
2415,"Re: HBase Design Ideas, Part I I see the possibility as described in the talk to get key regions form the master, than ask the next box for a key region etc. So you can distribute the key region table over a set of boxes. In case the client cache that the load on master shouldn't be that hard. Alternative I see a chance of request an update with a given key and get a kind of forward message returned until the client find the region server that hosts the data for a given row key. However since the client needs to start at the master, this would be a lot of load. A combination of both could be interesting. I agree there should be only one 'memory backed together' write cache that needs to be consulted before you search in the last checkpoint file. In any case we can write also one log to make sure we lose no data when a box crash. ... just my 2 cents. Stefan",existence
2416,"Re: HBase Design Ideas, Part I Hi, sounds pretty much similar to what I was thinking about, just that I had used different terms and you description is much more elegant than my hand written notes. Some comments below. I was playing around with row and run in to several problems using the hadoop io package. (SequenceReader writer) Optimal would be if a cell is a writable but having rowkey and cell key and value for each sell blows up disk usage. Alternative we can have a row writable so we only one rowkey , n column key and n values. In case a row has many column this scales very bad. For example my row key is a url and my column keys are user ids and the value are number of clicks. if I want to get the number of clicks for a given url and user, I need to load the values for all other user as well. :( I already posted a mail about this issue. What we may be need is a Writer that can seek first for row key and than for column keys. In general I agree with sparse structure. My idea was to have the lock on the HRegionServer level, my ideas was that the client itself take care about replication, means write the value to n servers that have the same replicatins of HRegions. Would the node send out a message to request a split or does the master decide based on heart beat messages? My idea was to simply download the data to the node and read any time locally, but write into the dfs, since in my case write access can be slower but I needer very fast read access. My idea was in such a case the HRegionServer may be know the new location at least until the master is informed. So getting a forward message could be faster than get an error and try ask for the target again. Sounds great! Looking forward to see that working. Stefan",existence
2417,"Re: HBase Design Ideas, Part I Seems like you are exporting a lot of complexity to the clients by having them find the table chunks via DFS read. Lots of data motion and sync / cache issues there. When not just ask the master for the block/server of a key? Or you could distribute this work over your HRegionServers if you don't want to stress the master. All this could be kept fresh in RAM there (segmented if you get huge). [but this adds complexity] As I read you design, it sounds like you might be doing a lot of seeks to find a record (do you need to scan all the logs to see if a key is present?). Best to outline the performance you want and then look at the ram / disk trade-offs. IE you can store everything in BTRees, but then you will thrash you disks. Or you can store everything linearly and store all your unmerged entries in RAM. This would have different costs/benefits... On May 14, 2006, at 3:00 PM, Michael Cafarella wrote:",existence
2418,"HBase Design Ideas, Part I Hi everyone, I've written up a design that I've been working on for a little bit, for a project I'll call ""HBase"". The idea is for Hadoop to implement something similar in spirit to BigTable. That is, a distributed data store that places a greater emphasis on scalability than on SQL compatibility or traditional transactional correctness. BigTable is neither completely described anywhere, nor is it necessarily exactly what we want. So I'm not trying to clone BigTable, but I am going to draw on it a lot. My personal view is that BigTable is a great ""physical layer"" but not yet a great database system. A major thing it lacks is a good query language. Another, freely admitted by the Google people, is any kind of inter-row locking. I'm not going to try to solve all these problems, but I would like HBase to be extendible enough that it's easy to add new query languages or primitives. In this mail, I'll describe a system that's pretty similar to BigTable. I'll send a second one that describes what we might want to change or add. Please let me know what you think! Thanks, --Mike -------------------------------------------------------------------------------- I. Table semantics An HBase consists of one or more HTables. An HTable is a list of rows, sorted alphabetically by ""row name"". An HTable also has a series of ""columns."" A row may or may not contain a value for a column. The HTable representation is sparse, so if a row does not contain a value for a given column, there is no storage overhead. (Thus, there's not really a ""schema"" to an HTable. Every operation, even adding a column, is considered a row-centric operation.) The ""current version"" of a row is always available, timestamped with its last modification date. The system may also store previous versions of a row, according to how the HTable is configured. Updates to a single row are always atomic and can affect one or more columns. II. System layout HTables are partitionable into contiguous row regions called HRegions. All machines in a pool run an HRegionServer. A given HRegion is served to clients by a single HRegionServer. A single HRegionServer may be responsible for many HRegions. The HRegions for a single HTable will be scattered across arbitrary HRegionServers. When a client wants to add/delete/update a row value, it must locate the relevant HRegionServer. It then contacts the HRegionServer and communicates the updates. There may be other steps, mainly lock-oriented ones. But locating the relevant HRegionServers is a bare minimum. The HBase system can repartition an HTable at any time. For example, many repeated inserts at a single location may cause a single HRegion to grow very large. The HBase would then try to split that into multiple HRegions. Those HRegions may be served by the same HRegionServer as the original or may be served by a different one. Each HRegionServer sends a regular heartbeat to an HBaseMaster machine. If the heartbeat for an HRegionServer fails, then the HBaseMaster is responsible for reassigning its HRegions to other available HRegionServers. All HRegions are stored within DFS, so the HRegion is always available, even in the face of machine failures. The HRegionServers and DFS DataNodes run on the same set of machines. We would like for an HRegionServer to always serve data stored locally, but that is not guaranteed when using DFS. We can encourage it by: 1) In the event of an insert-motivated HRegion move, the new HRegionServer should always create a new DFS file for the new HRegion. The DFS rules of thumb will allocate the chunks locally for the HRegionServer. 2) In the even of a machine failure, we cannot do anything similar to above. Instead, the HBaseMaster can ask DFS for hints as to where the relevant file blocks are stored. If possible, it will allocate the new HRegions to servers that physically contain the HRegion. 3) If necessary, we could add an API to DFS that demands block replication to a given node. I'd like to avoid this if possible. The mapping from row to HRegion (and hence, to HRegionServer) is itself stored in a special HTable. The HBaseMaster is the only client allowed to write to this HTable. This special HTable may itself be split into several HRegions. However, we only allow a hard-coded number of split-levels. The top level of this hierarchy must be easily-stored on a single machine. That top-level table is always served by the HBaseMaster itself. III. Client behavior Let's think about what happens when a client wants to add a row. 1) The client must compute what HRegion is responsible for the key it wants to insert into the HTable. It must navigate the row->HRegion mapping, which is stored in an HTable. So the client first contacts the HBaseMaster for the top-level table contents. It then steps downward through the table set, until it finds the mapping for the target row. 2) The client contacts the HRegionServer responsible for the target row, and asks to insert. If the HRegionServer is no longer responsible for the relevant HRegion, it returns a failure message and tells the client to go back to step 1 to find the new correct HRegionServer. If the HRegionServer is the right place to go, it accepts the new row from the client. The HRegionServer guarantees that the insert is atomic; it will not intermingle the insert with a competing insert for the same row key. When the row is stored, the HRegionServer includes version and timestamp information. 3) That's it! IV The HRegionServer Maintaining the data for a single HRegion is slightly complicated. It's especially weird given the write-once semantics of DFS. There are three important moving parts: 1) HBackedStore is a file-backed store for rows and their values. It is never edited in place. It has B-Tree-like lookups for finding a row quickly. HBackedStore is actually a series of on-disk stores, each store being tuned for a certain object size. Thus, all the ""small"" (in bytes) values for a row live within the same file, all the medium ones live in a separate file, etc. There is only one HBackedStore for any single HRegion. 2) HUpdateLog is a log of updates to the HBackedStore. It is backed by an on-disk file. When making reads from the HBackedStore, it may be necessary to consult the HUpdateLog to see if any more-recent updates have been made. There may be a series of HUpdateLogs for a single HRegion. 3) HUpdateBuf is an in-memory version of HUpdateLog. It, too, needs to be consulted whenever performing a read. There is only one HUpdateBuf for a single HRegion. Any incoming edit is first made directly to the HUpdateBuf. Changes made to the HUpdateBuf are volatile until flushed to an HUpdateLog. The rate of flushes is an admin-configurable parameter. Periodically, the HBackedStore and the series of current HUpdateLogs are merged to form a new HBackedStore. At that point, the old HUpdateLog objects can be destroyed. During this compaction process, edits are made to the HUpdateBuf.",property
79,"Re: [DISCUSS] CEP-19: Trie memtable implementation Let us continue the configuration discussion in the CEP-11 JIRA (https://issues.apache.org/jira/browse/CASSANDRA-17034).Any further comments on the alternate memtable? Are we ready for a vote?Regards,Branimir",not-ak
80,"Re: [DISCUSS] CEP-19: Trie memtable implementation TBH, I don't have an opinion on the configuration. I just want to say that if at the end we decide the configuration in the YAML should override the table schema, I would like to recommend that we specifying a list of whitelisted (or blacklisted) ""templates"" in the YAML file, and the template chosen by the table schema is used if it's enabled, otherwise fallback to a default template, which could be the first element in the whitelist if that's used, or a separate configuration entry if a blacklist is used. The list should be optional in the YAML, and an empty list or the absent of it means everything is enabled. Advantage of this: 1. it doesn't require the operator to configure this, as an empty or absent list by default enables all templates and should work fine in most cases. 2. it allows the operator to whitelist / blacklist any template if ever needed (e.g. due to a bug), and also allow them to choose a fallback option. 3. the table schema has priority as long as the chosen template is not explicitly disabled by the YAML. 4. it allows the operator to selectively disable some templates without forcing all tables to use the same template specified by the YAML. ",not-ak
81,"Re: [DISCUSS] CEP-19: Trie memtable implementation Why not have some default templates that can be specified by the schema without touching the yaml, but overridden in the yaml as necessary? ",not-ak
82,"Re: [DISCUSS] CEP-19: Trie memtable implementation If I understand this correctly, you prefer _not_ to have an option to give the configuration explicitly in the schema. I.e. force the configurations (""templates"" in current terms) to be specified in the yaml, and only allow tables to specify which one to use among them?This does sound at least as good to me, and I'll happily change the API.Regards,Branimir",existence
83,"Re: [DISCUSS] CEP-19: Trie memtable implementation My quick reading of the code suggests that schema will override the operator's default preference in the YAML. In the event of a bug in the new implementation, there could be situation where the operator might need to override this via the YAML.On Feb 8, 2022, at 12:29 PM, Jeremiah D Jordan <jeremiah.jordan@gmail.com> wrote:I don�t really see most users touching the default implementation. I would expect the main reason someone would change would be1. They run into some bug that is only in one of the implementations.2. They have persistent memory and so want to use https://issues.apache.org/jira/browse/CASSANDRA-13981Given that I doubt most people will touch it, I think it is good to give advanced operators the ability to have more control over switching to things that have new performance characteristics. So I like the idea that the proposed configuration approach which allows someone to change to a new implementation one node at a time and only for specific tables.On Feb 8, 2022, at 2:21 PM, Dinesh Joshi <djoshi@apache.org> wrote:Thank you for sharing the perf test results.Going back to the schema vs yaml configuration. I am concerned users may pick the wrong implementation for their use-case. Is there any chance for us to automatically pick a MemTable implementation based on heuristics? Do we foresee users ever picking the existing SkipList implementation over the Trie Given the performance tests, it seems the Trie implementation is the clear winner.To be clear, I am not suggesting we remove the existing implementation. I am for maintaining a pluggable API for various components.DineshOn Feb 7, 2022, at 8:39 AM, Branimir Lambov <blambov@apache.org> wrote:Added some performance results to the ticket: https://issues.apache.org/jira/browse/CASSANDRA-17240Regards,Branimir",not-ak
84,"Re: [DISCUSS] CEP-19: Trie memtable implementation I don�t really see most users touching the default implementation. I would expect the main reason someone would change would be1. They run into some bug that is only in one of the implementations.2. They have persistent memory and so want to use https://issues.apache.org/jira/browse/CASSANDRA-13981Given that I doubt most people will touch it, I think it is good to give advanced operators the ability to have more control over switching to things that have new performance characteristics. So I like the idea that the proposed configuration approach which allows someone to change to a new implementation one node at a time and only for specific tables.On Feb 8, 2022, at 2:21 PM, Dinesh Joshi <djoshi@apache.org> wrote:Thank you for sharing the perf test results.Going back to the schema vs yaml configuration. I am concerned users may pick the wrong implementation for their use-case. Is there any chance for us to automatically pick a MemTable implementation based on heuristics? Do we foresee users ever picking the existing SkipList implementation over the Trie Given the performance tests, it seems the Trie implementation is the clear winner.To be clear, I am not suggesting we remove the existing implementation. I am for maintaining a pluggable API for various components.DineshOn Feb 7, 2022, at 8:39 AM, Branimir Lambov <blambov@apache.org> wrote:Added some performance results to the ticket: https://issues.apache.org/jira/browse/CASSANDRA-17240Regards,Branimir",not-ak
85,"Re: [DISCUSS] CEP-19: Trie memtable implementation FWIW, I think the proposed approach to configuration is fine. I think selecting a choice for the user should be done simply and deterministically. We should probably default to Trie based memtables for users with a fresh config file, and we can consider changing the default in a later release for those with an old config file that does not specify an implementation. ",not-ak
86,"Re: [DISCUSS] CEP-19: Trie memtable implementation Thank you for sharing the perf test results.Going back to the schema vs yaml configuration. I am concerned users may pick the wrong implementation for their use-case. Is there any chance for us to automatically pick a MemTable implementation based on heuristics? Do we foresee users ever picking the existing SkipList implementation over the Trie Given the performance tests, it seems the Trie implementation is the clear winner.To be clear, I am not suggesting we remove the existing implementation. I am for maintaining a pluggable API for various components.DineshOn Feb 7, 2022, at 8:39 AM, Branimir Lambov <blambov@apache.org> wrote:Added some performance results to the ticket: https://issues.apache.org/jira/browse/CASSANDRA-17240Regards,Branimir",not-ak
87,"Re: [DISCUSS] CEP-19: Trie memtable implementation Branimir, thank you for sharing these results. The numbers are exciting - particularly the UCS test in which compaction keeps up, and your note mentioning 30% larger L0 flushes due to the more compact memory representation.Great work.� ScottOn Feb 7, 2022, at 8:39 AM, Branimir Lambov <blambov@apache.org> wrote:?Added some performance results to the ticket: https://issues.apache.org/jira/browse/CASSANDRA-17240Regards,Branimir",not-ak
89,"Re: [DISCUSS] CEP-19: Trie memtable implementation Added some performance results to the ticket:�https://issues.apache.org/jira/browse/CASSANDRA-17240Regards,Branimir",not-ak
91,"Re: [DISCUSS] CEP-19: Trie memtable implementation This is excellent. Thanks for opening up this CEP. It would be great to get some stats around GC allocation rate / memory pressure, read & write latencies, etc. compared to existing implementation.DineshOn Jan 18, 2022, at 2:13 AM, Branimir Lambov <blambov@apache.org> wrote:The memtable pluggability API (CEP-11) is per-table to enable memtable selection that suits specific workflows. It also makes full sense to permit per-node configuration, both to be able to modify the configuration to suit heterogeneous deployments better, as well as to test changes for improvements such as this one.Recognizing this, the patch comes with a modification to the API that defines memtable templates in cassandra.yaml (i.e. per node) and allows the schema to select a template (in addition to being able to specify the full memtable configuration). One could use this e.g. by adding:memtable_templates: trie: class: TrieMemtable shards: 16 skiplist: class: SkipListMemtablememtable: template: skiplist(which defines two templates and specifies the default memtable implementation to use) to cassandra.yaml and specifying WITH memtable = {'template' : 'trie'} in the table schema.I intend to commit this modification with the memtable API (CASSANDRA-17034/CEP-11).Performance comparisons will be published soon.Regards,Branimir",not-ak
112,"Re: [DISCUSS] CEP-19: Trie memtable implementation The memtable pluggability API (CEP-11) is per-table to enable memtable selection that�suits specific workflows. It also makes full sense to permit per-node configuration, both to be able to modify the configuration to suit heterogeneous deployments better, as well as to test changes for improvements such as this one.Recognizing this, the patch comes with a modification to the API that defines memtable templates in cassandra.yaml (i.e. per node) and allows the schema to select a template (in addition to being able to specify the full memtable configuration). One could use this e.g. by adding:memtable_templates: trie: class: TrieMemtable shards: 16 skiplist: class: SkipListMemtablememtable: template: skiplist(which defines two templates and specifies the default memtable implementation to use) to cassandra.yaml and specifying��WITH memtable = {'template' : 'trie'}�in the table schema.I intend to commit this modification with the memtable API (CASSANDRA-17034/CEP-11).Performance comparisons will be published soon.Regards,Branimir",existence
114,"Re: [DISCUSS] CEP-19: Trie memtable implementation Sounds like a great additionCan you share some of the details around gc and latency improvements you�ve observed with the list? Any specific reason the confirmation is through schema vs yaml? Presumably it�s so a user can test per table, but this changes every host in a cluster, so the impact of a bug/regression is much higher. On Jan 10, 2022, at 1:30 AM, Branimir Lambov <blambov@apache.org> wrote:?We would like to contribute our TrieMemtable to Cassandra. https://cwiki.apache.org/confluence/display/CASSANDRA/CEP-19%3A+Trie+memtable+implementationThis is a new memtable solution aimed to replace the legacy implementation, developed with the following objectives:- lowering the on-heap complexity and the ability to store memtable indexing structures off-heap,- leveraging byte order and a trie structure to lower the memory footprint and improve mutation and lookup performance.The new memtable relies on CASSANDRA-6936 to translate to and from byte-ordered representations of types, and CASSANDRA-17034 / CEP-11 to plug into Cassandra. The memtable is built on multiple shards of custom in-memory single-writer multiple-reader tries, whose implementation uses a combination of state-of-the-art and novel features for greater efficiency.The CEP's JIRA ticket (https://issues.apache.org/jira/browse/CASSANDRA-17240) contains the initial version of the implementation. In its current form it achieves much better garbage collection latency, significantly bigger data sizes between flushes for the same memory allocation, as well as drastically increased write throughput, and we expect the memory and garbage collection improvements to go much further with upcoming improvements to the solution.I am interested in hearing your thoughts on the proposal.Regards,Branimir",not-ak
119,"[DISCUSS] CEP-19: Trie memtable implementation We would like to contribute�our TrieMemtable to Cassandra.�https://cwiki.apache.org/confluence/display/CASSANDRA/CEP-19%3A+Trie+memtable+implementationThis is a new memtable solution aimed to replace the legacy implementation, developed with the following objectives:- lowering the on-heap complexity and the ability to store memtable indexing structures off-heap,- leveraging byte order and a trie structure to lower the memory footprint and improve mutation and lookup performance.The new memtable relies on CASSANDRA-6936 to translate to and from byte-ordered representations of types, and CASSANDRA-17034 / CEP-11 to plug into Cassandra. The memtable is built on multiple shards of custom in-memory single-writer multiple-reader tries, whose implementation uses a combination of state-of-the-art and novel features for greater efficiency.The CEP's JIRA ticket (https://issues.apache.org/jira/browse/CASSANDRA-17240) contains the initial version of the implementation. In its current form it achieves much better garbage collection latency, significantly bigger data sizes between flushes for the same memory allocation, as well as drastically increased write throughput, and we expect the memory and garbage collection improvements to go much further with upcoming improvements to the solution.I am interested in hearing your thoughts on the proposal.Regards,Branimir",property
168,"Re: [DISCUSSION] Next release roadmap Hi, FYI I am planning to put together all we discussed under sstable encryption thread into a kind-of CEP to distil everything said. I hope I'll put it together in the foreseeable future before taking a longer break till February. I am not sure if that is enough time to implement it if we eventually vote on that (which is rather hypothetical at this point) but I would appreciate having something solid to elaborate on. Regards ",not-ak
169,"Re: [DISCUSSION] Next release roadmap Sure :-) I will make a separate section. Le mar. 14 d�c. 2021 � 17:30, C. Scott Andreas a �crit :",not-ak
170,"Re: [DISCUSSION] Next release roadmap Thanks Benjamin!I see that the Roadmap doc on Confluence contains several features that are large in scope but do not have a published CEP or discussion on the mailing list.Because users will treat the roadmap doc as indicative of the project�s direction and intent, can these items be moved to a section indicating that there is interest or that they are potential features pending proposal and discussion?I don't think it's a good idea to list features that haven't been discussed on a user-visible roadmap page, but wouldn't object to the idea of them being in a separate section.� ScottOn Dec 13, 2021, at 6:42 AM, Benjamin Lerer <blerer@apache.org> wrote:I finally wrote down the roadmap on the wiki, and updated it to reflect thecurrent situation (https://cwiki.apache.org/confluence/display/CASSANDRA/Roadmap)Sorry for the delay.Le lun. 24 mai 2021 � 19:44, Ekaterina Dimitrova <e.dimitrova@gmail.com> a�crit :Thanks Paulo!The patch is available on github. It depends only on our availability andpriorities. I see Benedict mentioned on the ticket that probably 90% of thepatch covers already the idea of his proposal. I will be happy to finishthe work or if I am not available, when the time for it comes to handoverit to someone else.I can�t find the related ticket now but one of the jvm prerequisites weneeded is solved - to be able to load custom types.",executive
172,"Re: [DISCUSSION] Next release roadmap I finally wrote down the roadmap on the wiki, and updated it to reflect the current situation ( https://cwiki.apache.org/confluence/display/CASSANDRA/Roadmap) Sorry for the delay. Le lun. 24 mai 2021 � 19:44, Ekaterina Dimitrova a �crit :",not-ak
426,"Re: [DISCUSSION] Next release roadmap Thanks Paulo! The patch is available on github. It depends only on our availability and priorities. I see Benedict mentioned on the ticket that probably 90% of the patch covers already the idea of his proposal. I will be happy to finish the work or if I am not available, when the time for it comes to handover it to someone else. I can�t find the related ticket now but one of the jvm prerequisites we needed is solved - to be able to load custom types. ",not-ak
429,"Re: [DISCUSSION] Next release roadmap Thanks Paulo. That one definitely fell through the cracks. I have been pretty busy lately but as soon as I have a bit of time I will create a roadmap page to summarize everything that was proposed so far. Including Making SSLContext creation pluggable proposed by Maulin and the JUnit 5 migration proposal from Aleksei. Le mer. 19 mai 2021 � 01:48, Paulo Motta a �crit :",not-ak
430,"Re: [DISCUSSION] Next release roadmap I would love to see Ekaterina's work from CASSANDRA-15234 to standardize configuration be resumed in the next releases. Thought it would be worth mentioning since we had quite a productive discussion before putting it on hold to focus on 4.0, so it would be great to have that conversation resumed. Em seg., 26 de abr. de 2021 �s 14:16, Benedict Elliott Smith < benedict@apache.org> escreveu:",not-ak
431,"Re: [DISCUSSION] Next release roadmap I think my earlier response vanished into the moderator queue. Just a few comments: 1) The Paxos latency (and correctness) improvements I think should land in 4.0.x, as we have introduced a fairly significant regression and this work mostly resolves outstanding issues with LWTs today. 2) If we aim to deliver multi-partition LWTs in 4.x/5.0, we may likely want to pair this with work to further reduce latency beyond the above work, as contention will become a more significant problem. Should I be involved in delivering multi-partition LWTs I will also be aiming to deliver even lower latencies for the release they land in. 3) To support all of the above work, I also aim to deliver a Simulator facility for deterministically executing cluster workloads under adversarial scheduling (i.e. that intercepts all message and thread events and evaluates them sequentially, in pseudorandom order), alongside linearizability verification built upon this. This work will include (or have as a prerequisite) significant clean-ups to internal functionality like executors, use of futures and other concurrency primitives, and mocking out of time and the filesystem. ?On 23/04/2021, 14:46, ""Benjamin Lerer"" wrote: Hi everybody, Thanks for all the responses. I went through the emails and aggregated the proposals to give us an idea on where we stand at this point. I only included the improvements in the list and left on the side the bug fixes. Regarding bug fixes, I wonder if we should not have discussions every month to discuss what are the important issues that should be fixed in priority. I feel that we sometimes tend to forget old issues even if they are more important than some new ones. Do not hesitate to tell me if I missed something or misinterpreted some proposal. *Query side improvements:* * Storage Attached Index or SAI. The CEP can be found at https://cwiki.apache.org/confluence/display/CASSANDRA/CEP-7%3A+Storage+Attached+Index * Add support for OR predicates in the CQL where clause * Allow to aggregate by time intervals (CASSANDRA-11871) and allow UDFs in GROUP BY clause * Ability to read the TTL and WRITE TIME of an element in a collection (CASSANDRA-8877) * Multi-Partition LWTs * Materialized views hardening: Addressing the different Materialized Views issues (see CASSANDRA-15921 and [1] for some of the work involved) *Security improvements:* * SSTables encryption (CASSANDRA-9633) * Add support for Dynamic Data Masking (CEP pending) * Allow the creation of roles that have the ability to assign arbitrary privileges, or scoped privileges without also granting those roles access to database objects. * Filter rows from system and system_schema based on users permissions (CASSANDRA-15871) *Performance improvements:* * Trie-based index format (CEP pending) * Trie-based memtables (CEP pending) * Paxos improvements: Paxos / LWT implementation that would enable the database to serve serial writes with two round-trips and serial reads with one round-trip in the uncontended case *Safety/Usability improvements:* * Guardrails. The CEP can be found at https://cwiki.apache.org/confluence/display/CASSANDRA/%28DRAFT%29+-+CEP-3%3A+Guardrails * Add ability to track state in repair (CASSANDRA-15399) * Repair coordinator improvements (CASSANDRA-15399) * Make incremental backup configurable per keyspace and table (CASSANDRA-15402) * Add ability to blacklist a CQL partition so all requests are ignored (CASSANDRA-12106) * Add default and required keyspace replication options (CASSANDRA-14557) * Transactional Cluster Metadata: Use of transactions to propagate cluster metadata * Downgrade-ability: Ability to downgrade to downgrade in the event that a serious issue has been identified *Pluggability improvements:* * Pluggable schema manager (CEP pending) * Pluggable filesystem (CEP pending) * Pluggable authenticator for CQLSH (CASSANDRA-16456). A CEP draft can be found at https://docs.google.com/document/d/1_G-OZCAEmDyuQuAN2wQUYUtZBEJpMkHWnkYELLhqvKc/edit * Memtable API (CEP pending). The goal being to allow improvements such as CASSANDRA-13981 to be easily plugged into Cassandra *Memtable pluggable implementation:* * Enable Cassandra for Persistent Memory (CASSANDRA-13981) *Other tools:* * CQL compatibility test suite (CEP pending) Le jeu. 22 avr. 2021 � 16:11, Benjamin Lerer a �crit : --------------------------------------------------------------------- To unsubscribe, e-mail: dev-unsubscribe@cassandra.apache.org For additional commands, e-mail: dev-help@cassandra.apache.org",property
432,"Re: [DISCUSSION] Next release roadmap Hi Benjamin, Currently C* uses JUnit4 which seems to be obsolete. I think it is reasonable to migrate to JUnit5. I've created CASSANDRA-16630 ticket for that. If it is a good fit for the next release, I'd volunteer to get it done. I'd be glad to hear your thoughts and concerns. Thanks, Aleksei. On 2021/04/08 15:21:18, Benjamin Lerer wrote: year.> contributions> and> join the>",executive
433,"Re: [DISCUSSION] Next release roadmap Hi everybody, Thanks for all the responses. I went through the emails and aggregated the proposals to give us an idea on where we stand at this point. I only included the improvements in the list and left on the side the bug fixes. Regarding bug fixes, I wonder if we should not have discussions every month to discuss what are the important issues that should be fixed in priority. I feel that we sometimes tend to forget old issues even if they are more important than some new ones. Do not hesitate to tell me if I missed something or misinterpreted some proposal. *Query side improvements:* * Storage Attached Index or SAI. The CEP can be found at https://cwiki.apache.org/confluence/display/CASSANDRA/CEP-7%3A+Storage+Attached+Index * Add support for OR predicates in the CQL where clause * Allow to aggregate by time intervals (CASSANDRA-11871) and allow UDFs in GROUP BY clause * Ability to read the TTL and WRITE TIME of an element in a collection (CASSANDRA-8877) * Multi-Partition LWTs * Materialized views hardening: Addressing the different Materialized Views issues (see CASSANDRA-15921 and [1] for some of the work involved) *Security improvements:* * SSTables encryption (CASSANDRA-9633) * Add support for Dynamic Data Masking (CEP pending) * Allow the creation of roles that have the ability to assign arbitrary privileges, or scoped privileges without also granting those roles access to database objects. * Filter rows from system and system_schema based on users permissions (CASSANDRA-15871) *Performance improvements:* * Trie-based index format (CEP pending) * Trie-based memtables (CEP pending) * Paxos improvements: Paxos / LWT implementation that would enable the database to serve serial writes with two round-trips and serial reads with one round-trip in the uncontended case *Safety/Usability improvements:* * Guardrails. The CEP can be found at https://cwiki.apache.org/confluence/display/CASSANDRA/%28DRAFT%29+-+CEP-3%3A+Guardrails * Add ability to track state in repair (CASSANDRA-15399) * Repair coordinator improvements (CASSANDRA-15399) * Make incremental backup configurable per keyspace and table (CASSANDRA-15402) * Add ability to blacklist a CQL partition so all requests are ignored (CASSANDRA-12106) * Add default and required keyspace replication options (CASSANDRA-14557) * Transactional Cluster Metadata: Use of transactions to propagate cluster metadata * Downgrade-ability: Ability to downgrade to downgrade in the event that a serious issue has been identified *Pluggability improvements:* * Pluggable schema manager (CEP pending) * Pluggable filesystem (CEP pending) * Pluggable authenticator for CQLSH (CASSANDRA-16456). A CEP draft can be found at https://docs.google.com/document/d/1_G-OZCAEmDyuQuAN2wQUYUtZBEJpMkHWnkYELLhqvKc/edit * Memtable API (CEP pending). The goal being to allow improvements such as CASSANDRA-13981 to be easily plugged into Cassandra *Memtable pluggable implementation:* * Enable Cassandra for Persistent Memory (CASSANDRA-13981) *Other tools:* * CQL compatibility test suite (CEP pending) Le jeu. 22 avr. 2021 � 16:11, Benjamin Lerer a �crit :",not-ak
434,"Re: [DISCUSSION] Next release roadmap I am +100 on this. Bringing Cassandra to such a state was a huge effort and keeping it that way will help us to ensure the quality of the releases. Le jeu. 15 avr. 2021 � 17:30, Scott Andreas a �crit :",not-ak
435,"Re: [DISCUSSION] Next release roadmap Thanks for starting this discussion, Benjamin! I share others� enthusiasm on this thread for improvements to secondary indexes, trie-based partition indexes, guardrails, and encryption at rest. Here are some other post-4.0 areas for investment that have been on my mind: ?C Transactional Cluster Metadata Migrating from optimistic modification and propagation of cluster metadata via gossip to a transactional implementation opens a lot of possibilities. Token movements and instance replacements get safer and faster. Schema changes can be made atomic, enabling users to execute DDL rapidly without waiting for convergence. Operations like expansions and shrinks become easier to automate with less care and feeding. ?C Paxos improvements During discussion on C-12126, Benedict expressed interest in post-4.0 improvements that can be made to Cassandra�s Paxos / LWT implementation that would enable the database to serve serial writes with two round-trips and serial reads with one round-trip in the uncontended case. For many cross-WAN serial use cases, this may halve the latency of CAS queries. ?C Multi-Partition LWTs LWT is a great primitive, but modeling applications with the constraint of single-key CAS can be a game of Twister. Extending the paxos improvements discussed above to enable multi-partition CAS would enable users of Apache Cassandra to perform serial operations across partition boundaries. ?C Downgrade-ability I also see �downgradeability� as important to future new release adoption. Taking file format changes as an example, it�s currently not possible to downgrade in the event that a serious issue has been identified ?C unless you�re able to host-replace yourself out after upgrading one replica, or revert to a pre-upgrade snapshot and accept data loss. It would be excellent if it were possible for v.next to continue writing the previous SSTable/commitlog/hint/etc. format until a switch is flipped to opt into new file formats. Apache HDFS takes a similar approach, enabling downgrade until NameNode metadata is finalized [1]. This would be an excellent capability to have in Apache Cassandra, and dramatically lower the stakes for new release adoption. On pluggability / disaggregation: I agree that these are important themes. We�ll want to bring a lot of care and attention to this work. Disaggregation can open a lot of possibilities - with the drawback of future changes being restricted to the defined interface and an inability to optimize across interface boundaries. We can probably hit a sweet spot, though. Toolchains to validate implementations of pluggable components will become very important. It would be bad for the project�s users if bundled implementations were of uneven quality or supported subsets of functionality. Converging on a common validation toolchain for pluggable subsystems can help us ensure that quality while minimizing the effort required to test new implementations. Finally, I think it's important we work to maintain trunk in a shippable state. This might look like major changes and new features hiding behind feature flags that enable users to selectively enable them as development and validation proceeds, with new code executed regardless of the flag held to a higher standard. Cheers, ?C Scott [1] https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsRollingUpgrade.html ________________________________________ From: guo Maxwell Sent: Wednesday, April 14, 2021 10:25 PM To: dev@cassandra.apache.org Subject: Re: [DISCUSSION] Next release roadmap +1 Brandon Williams ?2021?4?15??? ??4:48??? -- you are the apple of my eye ! --------------------------------------------------------------------- To unsubscribe, e-mail: dev-unsubscribe@cassandra.apache.org For additional commands, e-mail: dev-help@cassandra.apache.org",property
436,Re: [DISCUSSION] Next release roadmap +1 Brandon Williams ?2021?4?15??? ??4:48??? -- you are the apple of my eye !,not-ak
437,"Re: [DISCUSSION] Next release roadmap Agreed. Everyone just please keep in mind this thread is for roadmap contributions you plan to make, not contributions you would like to see. ",not-ak
438,"Re: [DISCUSSION] Next release roadmap Agree with Stefan 100% on this. We need to move towards pluggability. Our users are asking for it, it makes sense architecturally, and people are doing it anyway. ...",property
441,"Re: [DISCUSSION] Next release roadmap Hi, for me definitely https://issues.apache.org/jira/browse/CASSANDRA-9633 I am surprised nobody mentioned this in the previous answers, there is ~50 people waiting for it to happen and multiple people working on it seriously and wanting that feature to be there for so so long. We will come up with a more detailed list of things but this just came to my mind instantly as I read this thread. Regards ",not-ak
442,"Re: [DISCUSSION] Next release roadmap I plan to work on the following 1. CASSANDRA-12106 Blacklisting bad partitions - Rework patch and solicit for feedback/review and have it committed 2. CASSANDRA-14557 Default and required keyspace RF - Patch available; solicit for feedback/review and have it committed 3. CASSANDRA-15433 Pending ranges are not recalculated on keyspace creation - patch available; work on jvm dtests, solicit for feedback/review, have it committed. 4. CASSANDRA-8877 Querying TTL and writetime for collections 5. CASSANDRA-15472 Read failure due to exception from metrics-core dependency ",not-ak
443,Re: [DISCUSSION] Next release roadmap besides do we need a table level backup and restore solution for cassandra ? https://issues.apache.org/jira/browse/CASSANDRA-15402,not-ak
444,"Re: [DISCUSSION] Next release roadmap There are numerous things I'd like to contribute to on the next roadmap. I really think that pluggable storage is a great goal and can expand Cassandra's options for performance and scalability, so I plan on helping to work on that. I also plan to work on extending CQLSH so that it offers plugin support (particularly for security plugins). See https://issues.apache.org/jira/browse/CASSANDRA-16456. One idea I wanted to raise here is concerning testing. With all the many managed or tweaked Cassandra solutions available (such as DataStax Astra, Amazon Keyspaces, ScyllaDB, etc.), I would love to work on a suite of protocol tests that are isolated to testing CQL compatibility. Basically, a test tool that focuses on the CQL grammar (the kind of testing the pact framework does for example, https://docs.pact.io/getting_started/how_pact_works/). This would help test the CQL compatibility of any offering, help improve their support, and would help us be crisp about what is part of CQL and what is a different kind of addition. Assuming there is some interest in this, I plan on writing a CEP to cover the idea. Thanks! Brian Sent with ProtonMail Secure Email. ??????? Original Message ??????? On Thursday, April 8, 2021 12:55 PM, David Capwell wrote: --------------------------------------------------------------------- To unsubscribe, e-mail: dev-unsubscribe@cassandra.apache.org For additional commands, e-mail: dev-help@cassandra.apache.org",property
445,"Re: [DISCUSSION] Next release roadmap Yes, it does. Thanks for pointing it out. :-) Le ven. 9 avr. 2021 � 04:21, guo Maxwell a �crit :",not-ak
446,Re: [DISCUSSION] Next release roadmap �Filter rows from system and system_schema based on users permissions� I think the issue match this improvement. https://issues.apache.org/jira/browse/CASSANDRA-15871 David Capwell ?2021?4?9??? ??3:56??? -- you are the apple of my eye !,not-ak
447,"Re: [DISCUSSION] Next release roadmap Here are two things I descoped from 4.0 and plan to pick up after 4.0 release https://issues.apache.org/jira/browse/CASSANDRA-15566 - Repair coordinator can hang under some cases. Aka repair has many cases where it can become unresponsive and not reliant; so work to improve it. https://issues.apache.org/jira/browse/CASSANDRA-15399 - Add ability to track state in repair. Rather than rely on logs to see what repair is doing, add APIs to expose what�s going on with repair, and what repair has done.",existence
448,"Re: [DISCUSSION] Next release roadmap On our side, the list of improvements we plan to deliver for the next release are: Query side improvements: * Storage Attached Index or SAI. The CEP can be found at https://cwiki.apache.org/confluence/display/CASSANDRA/CEP-7%3A+Storage+Attached+Index * Add support for OR predicates in the CQL where clause * Allow to aggregate by time intervals (CASSANDRA-11871) and allow UDFs in GROUP BY clause * Materialized views hardening: Addressing the different Materialized Views issues (see CASSANDRA-15921 and [1] for some of the work involved) Security improvements: * Add support for Dynamic Data Masking (CEP pending) * Allow the creation of roles that have the ability to assign arbitrary privileges, or scoped privileges without also granting those roles access to database objects. * Filter rows from system and system_schema based on users permissions Performance improvements: * Trie-based index format (CEP pending) * Trie-based memtables (CEP pending) Safety/Usability improvements: * Guardrails. The CEP can be found at https://cwiki.apache.org/confluence/display/CASSANDRA/%28DRAFT%29+-+CEP-3%3A+Guardrails Pluggability improvements: * Pluggable schema manager (CEP pending) * Pluggable filesystem (CEP pending) * Memtable API (CEP pending). The goal being to allow improvements such as CASSANDRA-13981 to be easily plugged into Cassandra Feedbacks are welcome :-). [1] https://lists.apache.org/thread.html/r908b5397dd803132822cabe5ba0755861d97bb5d8603a523591d55c9%40%3Cdev.cassandra.apache.org%3E Le jeu. 8 avr. 2021 � 17:21, Benjamin Lerer a �crit :",existence
449,"[DISCUSSION] Next release roadmap Hi Everybody, Please speak up and tell us what you plan to contribute in the next year. The goal of this discussion is to allow people to present the contributions that they have planned for the next Cassandra release. That discussion has several benefits: - It will give a greater visibility on who is planning to contribute and what their contributions would be. Allowing other contributors to join the efforts or ask for questions if they wish to. - It will also us to synchronize our efforts when some features impact the same part of the code - For users, it will provide an idea of what to expect from the next release Thanks in advance for all your inputs.",executive
1766,Re: Patch review process ,executive
1767,"Re: Patch review process On 11 February 2015 at 21:11:25, Chris Douglas (cdouglas@apache.org) wrote: +1; ChrisN's formulation is exactly right. The patch manager can't force (or shame) anyone into caring about your issue. One of the benefits of RTC is that parts of the code with a single maintainer are exposed. If you can't find collaborators, either (a) this isn't the right community for that module or (b) the project needs to acknowledge and address the ""bus factor"" [1] for that code. By observing and directing review, the patch manager accumulates context most contributors don't have. At the same time, if only 1 person is looking at a part of the codebase & submitting patches, they have inherently recused themselves from reviewing on their own patches. Ideally you want >1 committer tracking a topic. That's someone with competence in the area too, obviously; a barrier to participation in the corner areas. Does anyone want to work with INFRA to test Crucible? It looks like Ambari started exploring it last year [2]. From David's response, it sounds like they'd be willing to work with a project to experiment, but most requests have been for Gerrit. -C [1] http://en.wikipedia.org/wiki/Bus_factor [2] https://issues.apache.org/jira/browse/INFRA-8430 started with https://issues.apache.org/jira/browse/INFRA-9152 , though I'm not sure the diff between fisheye and cruicible here; they seem blurred ",not-ak
1768,"Re: Patch review process +1; ChrisN's formulation is exactly right. The patch manager can't force (or shame) anyone into caring about your issue. One of the benefits of RTC is that parts of the code with a single maintainer are exposed. If you can't find collaborators, either (a) this isn't the right community for that module or (b) the project needs to acknowledge and address the ""bus factor"" [1] for that code. By observing and directing review, the patch manager accumulates context most contributors don't have. Does anyone want to work with INFRA to test Crucible? It looks like Ambari started exploring it last year [2]. From David's response, it sounds like they'd be willing to work with a project to experiment, but most requests have been for Gerrit. -C [1] http://en.wikipedia.org/wiki/Bus_factor [2] https://issues.apache.org/jira/browse/INFRA-8430 ",executive
1769,"Re: Patch review process I don�t anticipate a patch manager introducing a new bottleneck. As originally described by Chris D, the role of the patch manager is not to review and commit all patches in an assigned area. Instead, the responsibility is queue management: following up on dormant jiras to make sure progress is made. This might involve the patch manager doing the review and commit, but it also might mean contacting someone else for review, closing it if it�s a duplicate, or making a won�t-fix decision. It�s the kind of activity that Allen and Steve have done a lot lately. I see the patch manager role as addressing the fact that the community itself has grown large and complex. As others have mentioned, it�s not always clear to a new contributor who to ask for a code review. A patch manager would be familiar enough with the community to help steer their patches in the right direction. I suppose we don�t need to formalize this too much. If anyone feels capable of doing this kind of queue management in a certain area of expertise, please dive in. Congratulations, you are now a patch manager! I�m sure everyone would appreciate it. Chris Nauroth Hortonworks http://hortonworks.com/ On 2/10/15, 9:31 AM, ""Tsuyoshi Ozawa"" wrote:",executive
1770,"Re: Patch review process +1 for trying Crucible. We should try whether it's integrated well and it can solve the problem of ""splitting discussion"". If Crucible solves it, it would be great. About the patch manager, I concern that it can delay reviews if the patch size is too small and the amount of work of patch manager get more and more. About ""long-lived old patches"", how about making them open automatically when specific periods passes? It can also be a ping to ML and save the time to check old patches. the unit tests, which slows down patch iterations. One solution is running tests in parallel (and even distributed). Previous distributed experiments have done a full unit test run in a couple minutes, but it'd be a fair amount of work to actually make this production ready. Automating this will save reviewer time. I'm very interested in working this. If the distributed tests environment can be prepared, it can accelerate the development of Hadoop. I've heard that swift community started to maintain code. http://docs.openstack.org/developer/sahara/userdoc/hadoop-swift.html If we make the components production ready, we need to setup S3 or Swift stubs in test environment. Is this feasible? BTW, Agile board looks helpful for us to know the status of our projects at a glance. Mesos is using it. https://issues.apache.org/jira/secure/RapidBoard.jspa?rapidView=1 Thanks, - Tsuyoshi ",executive
1771,"Re: Patch review process On 9 February 2015 at 21:18:52, Colin P. McCabe (cmccabe@apache.org) wrote: What happened with the Crucible experiment? Did we get a chance to try that out? That would be a great way to speed up patch reviews, and one that is well-integrated with JIRA. I am -1 on Gerrit unless we can find a way to mirror the comments to JIRA. I think splitting the discussion is a far worse thing that letting a few minor patches languish for a while (even assuming that gerrit would solve this, which seems unclear to me). The health of the community is most important. I think it is normal and healthy to post on hdfs-dev, email developers, or hold a meeting to try to promote your patch and/or idea. Some of the discussion here seems to be assuming that Hadoop is a machine for turning patch available JIRAs into commits. It's not. It's a community, and sometimes it is necessary to email people or talk to them to get them to help with your JIRA. I know your heart is in the right place, but the JIRA examples given here are not that persuasive. Both of them are things that we would not encounter on a real cluster (nobody uses Hadoop with ipv6, nobody uses Hadoop without setting up DNS). Got some bad news there. The real world is messy, and the way Hadoop tends to fail right now leaves java stack traces that tend to leave people assuming its Hadoop side. Messy networks are extra commonplace amongst people learning to use Hadoop themselves, future community members, and when you are bringing up VMs. In production, well, talk to your colleagues in support and say ""how often do you field network-related problems?"", followed by ""do you think Hadoop could do more to help here?"" But, if we find a specific set of issues that the community has ignored (such as good error messages in bad networking setups, configuration issues, etc.), then we could create an umbrella JIRA and make a sustained effort to get it done. Seems like a good strategy. I've just created https://issues.apache.org/jira/browse/HADOOP-11571, ""get S3a production ready"". It shipped in Hadoop 2.6; now it's out in the wild the bug reports are starting to come back in. Mostly scale related; some failure handling, some improvements to work behind proxies and with non-AWS endpoints. 1. To date all the s3a code has come from none committers; the original codebase 2. Most of the ongoing dev from is Thomas Demoor at amplidata, 3. There's been some support via AWS (HADOOP-10714), 4. There's been a couple of patches from Ted Yu after hbase backups keeled over from too many threads One thing that is notable about the s3a (or any of the object store filesystems) is that Jenkins does not run the tests. Anyone proposing to +1 a patch based on a Jenkins run (see HADOOP-11488) is going to get a -1 from me; it takes 30-60 minutes for a test run. You get a bill of about 50c/month for participating this project To date I've been the sole committer running the tests, reviewing the code and with a vague idea of what's being going on. That's because (a) I care about object stores after my experience with getting swift:// in, and (b) I'm not recommending that anyone use it in production until its been field-tested more. Who is going to assist me review and test these patches? Perhaps we could also do things like batching findbugs fixes into fewer JIRAs, as has been suggested before. A detail. Findbugs is not the problem",not-ak
1780,"Re: Patch review process What happened with the Crucible experiment? Did we get a chance to try that out? That would be a great way to speed up patch reviews, and one that is well-integrated with JIRA. I am -1 on Gerrit unless we can find a way to mirror the comments to JIRA. I think splitting the discussion is a far worse thing that letting a few minor patches languish for a while (even assuming that gerrit would solve this, which seems unclear to me). The health of the community is most important. I think it is normal and healthy to post on hdfs-dev, email developers, or hold a meeting to try to promote your patch and/or idea. Some of the discussion here seems to be assuming that Hadoop is a machine for turning patch available JIRAs into commits. It's not. It's a community, and sometimes it is necessary to email people or talk to them to get them to help with your JIRA. I know your heart is in the right place, but the JIRA examples given here are not that persuasive. Both of them are things that we would not encounter on a real cluster (nobody uses Hadoop with ipv6, nobody uses Hadoop without setting up DNS). But, if we find a specific set of issues that the community has ignored (such as good error messages in bad networking setups, configuration issues, etc.), then we could create an umbrella JIRA and make a sustained effort to get it done. Perhaps we could also do things like batching findbugs fixes into fewer JIRAs, as has been suggested before. best, Colin ",executive
1781,"Re: Patch review process On 8 February 2015 at 09:55:42, Karthik Kambatla (kasha@cloudera.com) wrote: ",not-ak
1782,Re: Patch review process ,executive
1783,"Re: Patch review process On 7 February 2015 at 02:14:39, Colin P. McCabe (cmccabe@apache.org) wrote: I think it's healthy to have lots of JIRAs that are ""patch available."" It means that there is a lot of interest in the project and people want to contribute. It would be unhealthy if JIRAs that really needed to get in were not getting in. But beyond a few horror stories, that usually doesn't seem to happen. I believe it is easier for you or I to assert that than it is for someone to submit a patch which really matters to them, only to find it languishes ignored, because it doesn't appear to matter to anyone who has the rights to get it into the code. I agree that we should make an effort to review things that come from new contributors. I always set aside some time each week to look through the new JIRAs on the list and review ones that I feel like I can do. I think the ""patch manager"" for a patch should be the person who submitted it. As Chris suggested, if nobody is reviewing, email people who reviewed earlier and ask why. Or email the list and ask if this is the right approach, and bring attention to the issue. Is the fact that you have keep asking people to look at your patch a good one? Its certainly a sign that the submitter feels it matters, but it also shows there's no active queue management, I suspect it also tends to be easier to pull off if you are already known in the community. I know a certain AW will now note that it helps to share employers with other committers, but we also tend to review and +1 code work by people you already know and are reasonably good at working with. (i.e you don't fear their code, trust them to care about issues like compatibility, testing, etc). Certainly I appreciate Alan's +1s for my languishing patches. If you aren't known, if you have just one patch which appears to only surface in your env, risk of neglect. example: https://issues.apache.org/jira/browse/HADOOP-3426 ""Datanode does not start up if the local machines DNS isn't working right and dfs.datanode.dns.interface==default"" my home lan, my broken /etc/resolv.conf, my patch. And until in Hadoop: my private branch needed to work. And now its in, I'm happy with that specific problem being addressed. Except, there's one nearby about failing better in an IPv6 world, that's been around for a while and nobody has looked at https://issues.apache.org/jira/browse/HADOOP-3619 It's little ones like that that I think can fall by the wayside (I'm looking at it now). Here's someone pushing the boundaries: running without IPv6 disabled -and instead of us picking up the early lessons, they are being ignored unless/until they become issues in the runup to a release. And, we are trying to be a community here, which means encouraging more contributions. Those of us working full time on it should be able to allocate some time, even if only weekends outside the release phase, to catching up with the work queue. There's an article here that makes this point �that OSS projects should be inclusive, not exclusive, which means encouraging a more diverse set of contributors. http://www.curiousefficiency.org/posts/2015/01/abuse-is-not-ok.html We can't do that if we restrict our reviews to work by known people, The other issue I find with the ""harass people until they commit it"" strategy is that it scales badly. Not just from the # of people submitting patches, but from the #of patches. If I have a small 4 line patch, is it worth the effort of chasing people round to get it in, or should I save my effort for the more transformational patches? Furthermore, as a recipient of such emails, after I while I get more ruthless about ignoring them. Though I think I'll look at a few today, including one that colleague of Colin's has been asking for (HADOOP-11293), as I feel sorry for anyone attempting a minor-but-widereaching bit of code cleanup. I do like the idea of cleaning up old JIRAs that no longer apply or that have been abandoned. And perhaps picking up on a few issues that we have forgotten about. +1 But it is part of release management in my mind. The release manager decides that we need to get features and bugfixes X, Y, and Z in release Q, and then pushes on the JIRAs and committers responsible for making this happen. Since JIRAs implement features and bugfixes they naturally fall under release management. This is how several companies that I've worked at have done it internally... At release time it's too late to do things that are important yet whose roll-out is considered a threat to the code. If you were to look at the history of any JIRA related to updating Jetty you can see this: we know the problems, but don't want to go there, especially near a release time. And, given the stress induced by the ""great protobuf upgrade of 2013"", I agree. Except now its not release time, nobody has gone near Jetty again. Anyway, I'm going to review some patches this weekend. Please DO NOT email suggestions to me, as that will only re-inforce the ""email-priority-scheduler"" algorithm I have just argued against. I will pick some minor ones from people with little or no contribution history, or ones that I care about but have forgotten to review. -Steve",executive
1784,"Re: Patch review process I think it's healthy to have lots of JIRAs that are ""patch available."" It means that there is a lot of interest in the project and people want to contribute. It would be unhealthy if JIRAs that really needed to get in were not getting in. But beyond a few horror stories, that usually doesn't seem to happen. I agree that we should make an effort to review things that come from new contributors. I always set aside some time each week to look through the new JIRAs on the list and review ones that I feel like I can do. I think the ""patch manager"" for a patch should be the person who submitted it. As Chris suggested, if nobody is reviewing, email people who reviewed earlier and ask why. Or email the list and ask if this is the right approach, and bring attention to the issue. I do like the idea of cleaning up old JIRAs that no longer apply or that have been abandoned. And perhaps picking up on a few issues that we have forgotten about. But it is part of release management in my mind. The release manager decides that we need to get features and bugfixes X, Y, and Z in release Q, and then pushes on the JIRAs and committers responsible for making this happen. Since JIRAs implement features and bugfixes they naturally fall under release management. This is how several companies that I've worked at have done it internally... cheers, Colin ",executive
1785,"Re: Patch review process I'm thinking it's unhealthy to have over 1000 JIRAs patch available. Reviewers should be more welcome and should review patches from everywhere to increase developers and future reviewers. I'm not completely sure patch managers will make it healthy, however, changing the process (and this discussion) would help improving our mindsets. @Committers: Let's review more patches! @Developers: You can also review patches you are interested in. Your comments will help committers to review and merge them. (As you can see, the above comments don't have any enforcement.) Regards, Akira ",executive
1786,Re: Patch review process +1 to patch managers per component. ,not-ak
1787,"Re: Patch review process There are many ways to find reviewers. Look at the set of watchers, email people who work on that component (check git if you're unsure who's been there recently), or even email random committers and ask for leads. Privately ask people why they stopped responding to an issue. Even if an issue has a +1 from a coworker or close collaborator, solicit feedback from new committers to set their expectations for the role. Be gracious to reviewers; you're inviting them to volunteer. A ""patch manager"" isn't process, but a role that's available, useful, and appreciated. -C ",not-ak
1788,"Re: Patch review process Is process really the problem? Or, more directly, how does any of this actually increase the pool beyond the (I�m feeling generous today) 10 or so committers (never mind PMC) that actually review patches that come from outside their employers on a regular basis? To put this in perspective, there are over 1000 JIRAs in patch available status across all three projects right now. That�s not even counting the ones that I know I�ve personally removed the PA status on because the patch no longer applies... On Feb 4, 2015, at 12:10 PM, Chris Douglas wrote:",not-ak
1789,"Re: Patch review process Release managers are just committers trying to roll releases; it's not an enduring role. A patch manager is just someone helping to track work and direct reviewers to issues. The job doesn't come with a hat. We could look into a badge and gun if that would help. This doesn't require a lot of hand-wringing or diagnosis. If you're concerned about the queue, then start trying to find reviewers for viable patches. We should also close issues that require too much work to fix, or at least mark them for ""Later"". Not every idea needs to end in a commit, but silence is frustrating for contributors. -C ",executive
1790,"Re: Patch review process The main JIRA dashboard for each project has an Issues tab with useful summary statistics and links to filtered queries, most notably links to unresolved issues grouped by each project sub-component. https://issues.apache.org/jira/browse/HADOOP/?selectedTab=com.atlassian.jir a.jira-projects-plugin:issues-panel https://issues.apache.org/jira/browse/HDFS/?selectedTab=com.atlassian.jira. jira-projects-plugin:issues-panel https://issues.apache.org/jira/browse/MAPREDUCE/?selectedTab=com.atlassian. jira.jira-projects-plugin:issues-panel https://issues.apache.org/jira/browse/YARN/?selectedTab=com.atlassian.jira. jira-projects-plugin:issues-panel I can see that many of these represent a much smaller, more manageable work queue than trying to sift through all patch available, or worse yet, all unresolved. For example, here are the results for Hadoop Common native, HDFS snapshots, MapReduce Job History Server, and YARN Capacity Scheduler. https://issues.apache.org/jira/issues/?jql=project%20%3D%20HADOOP%20AND%20r esolution%20%3D%20Unresolved%20AND%20component%20%3D%20native%20ORDER%20BY% 20priority%20DESC https://issues.apache.org/jira/issues/?jql=project%20%3D%20HDFS%20AND%20res olution%20%3D%20Unresolved%20AND%20component%20%3D%20snapshots%20ORDER%20BY %20priority%20DESC https://issues.apache.org/jira/issues/?jql=project%20%3D%20MAPREDUCE%20AND% 20resolution%20%3D%20Unresolved%20AND%20component%20%3D%20jobhistoryserver% 20ORDER%20BY%20priority%20DESC https://issues.apache.org/jira/issues/?jql=project%20%3D%20YARN%20AND%20res olution%20%3D%20Unresolved%20AND%20component%20%3D%20capacityscheduler%20OR DER%20BY%20priority%20DESC Suppose we ask for committers to act in the Patch Manager role associated with these per-component queries as their work queues. If people are working in an area of expertise, then they'll likely process the queue efficiently. If people want to stretch into an area of code where they are less familiar, then volunteering as Patch Manager could be a way to ramp up. The success of this approach would depend on the quality of our JIRA metadata. We�d need to be diligent about assigning each issue to its correct component. We may also find a need to restructure the component breakdown over time. Right now, it tends to mirror our Java package structure pretty closely, but something like �namenode"" is quite broad as a patch queue. Thoughts? Chris Nauroth Hortonworks http://hortonworks.com/ On 2/4/15, 11:14 AM, ""Steve Loughran"" wrote:",executive
1791,"Re: Patch review process I'm worrying more about the ongoing situation. As a release approaches someone effectively goes full time as the gatekeeper, -for a good release they should be saying ""too late!"" for most features and ""only if it's low risk"" to non-critical bug fixes Which means that non-critical stuff don't get in as a release approaches. This is a good thing for release stability, but not for getting work in. Active patch queue management should be something going on when the releases aren't being made (or even then, just not near the release branch). The problem is it takes time and effort. Time to review the code, test it, maybe even tune it a bit to help. For the big bits of work, if you can get full-time/part time support from committers then you do stand a chance of getting it in. But the effort needed for those project usually means that the engineer in question has been allocated that time by their employer. If its a big project and they don't have that support, I think the patch is going to be in trouble. The new NFS client proposal is an example of that: I can personally see why it'd be nice to have, but I'm not going to go near it. For the little bits of work, they take less continuous time and effort, but someone who understands the area in question does need to go through them, provide feedback and help get them in. I don't think we do enough there. I understand why not: time and effort, but think we miss out in the process. On 4 February 2015 at 18:25:05, Colin P. McCabe (cmccabe@apache.org) wrote: I wonder if this work logically falls under the release manager role. During a release, we generally spend a little bit of time thinking about what new features we added, systems we stabilized, interfaces we changed, etc. etc. This gives us some perspective to look backwards at old JIRAs and either close them as no longer relevant, or target them for the next release (with appropriate encouragement to the people who might have the expertise to make that happen.) best, Colin",executive
1792,"Re: Patch review process I wonder if this work logically falls under the release manager role. During a release, we generally spend a little bit of time thinking about what new features we added, systems we stabilized, interfaces we changed, etc. etc. This gives us some perspective to look backwards at old JIRAs and either close them as no longer relevant, or target them for the next release (with appropriate encouragement to the people who might have the expertise to make that happen.) best, Colin ",executive
1793,"Re: Patch review process +1 on the idea of patch managers. As the patch managers should have good expertise on the specific fields, they are more productive on reviewing the patches and driving the development on the specific fields forward. ~Haohui ",executive
1794,"Re: Patch review process I like the idea of patch managers monitoring specific queues of issues, perhaps implemented as a set of jira filters on different values for the component or label fields. Right now, looking at the whole HADOOP backlog is daunting. Using separate filtered review queues could help each reviewer focus and parallelize the work. Going back to the topic of tooling, I just learned that multiple Apache projects have expressed interest in Gerrit recently. I've never used Gerrit and so can�t speak in favor or against it, but I think consistency across Apache has benefits. Issue INFRA-2205 has the discussion. The issue is closed, but there is recent discussion in the comments. https://issues.apache.org/jira/browse/INFRA-2205 Chris Nauroth Hortonworks http://hortonworks.com/ On 2/2/15, 3:56 AM, ""Chris Douglas"" wrote:",executive
1795,"Re: Patch review process Many projects have unofficial ""patch managers"": http://producingoss.com/en/share-management.html#patch-manager People who go through outstanding issues, ensuring that each has reached a stable state, or at least a willing reviewer. -C ",executive
1796,"Re: Patch review process Given experience of apache reviews, I don't know how much time to spend on it. I'm curious about Gerrit, but again, if JIRA integration is what is sought, Cruicible sounds better. Returning to other issues in the discussion 1. Improving test times would make a big difference; locally as well as on Jira. 2. How can we clear through today's backlog without relying on a future piece of technology from magically fixing it? For clearing the backlog, I don't see any solution other than ""people put in time"". I know its an obligation for committers to do this, but I also know how little time most of us have to do things other than deal with our own tests failing. As a result, things that aren't viewed as critical get neglected. Shell, build, object stores, cruft cleanup, etc, I think people that care about these areas are going to have to get together and sync up. For some of the stuff it may be quite fast �people may not have noticed, but a few of us have brought the build dependencies forward fairly fast recently, with a goal of Hadoop branch-2/trunk being compatible with recent Guava versions and java 8. I've been doing some S3/object store work the last couple of weekends; that's slow as test runs take 30+ minutes against the far end, test runs jenkins doesn't do. If anyone else wants to look at the fs/s3 and fs/swift queue their input is welcome. And of course AW went through the entire backlog of shell stuff & a lot of the not-in-branch-2 features. So where now? What is a strategy to deal with all those things in the queue?",executive
1797,"Re: Patch review process The fact that reviews.apache.org has ~35k users ( https://reviews.apache.org/users/?page=711 ) that mostly appear to be bots gives me zero confidence in using this tool for anything real. On Jan 30, 2015, at 11:11 AM, Gera Shegalov wrote:",executive
1798,"Re: Patch review process Splitting the conversation via reviewboard and JIRA is definitely a problem that we have hit previously [1]. Since reviewboard and probably other tools as well generate emails for each set of comments we could leverage JIRA's functionality [2] to make sure that they are reflected in the JIRA as well. Probably there is some pre or post processing required to make sure that this happens. Of course since crucible delivers it out of the box[3], it should be the first candidate to look at. +1 1. https://issues.apache.org/jira/browse/MAPREDUCE-4974?focusedCommentId=13619455&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13619455 ] 2. https://confluence.atlassian.com/display/Cloud/Creating+Issues+and+Comments+from+Email 3. https://www.atlassian.com/software/crucible/overview/code-quality-jira On Thu Jan 29 2015 at 10:33:11 AM Colin P. McCabe wrote:",executive
22,"[NOTICE] Attaching patches in JIRA issue no longer works Dear Hadoop developers, I've disabled the Precommit-(HADOOP|HDFS|MAPREDUCE|YARN)-Build jobs. If you attach a patch to a JIRA issue, the Jenkins precommit job won't run. Please use GitHub PR for code review. Background: - https://issues.apache.org/jira/browse/HADOOP-17798 - https://lists.apache.org/thread/6g3n4wo3b3tpq2qxyyth3y8m9z4mcj8p Thanks and regards, Akira",executive
5,"Re: [E] [NOTICE] Attaching patches in JIRA issue no longer works Hi Eric, JIRA issues contain useful information in the fields. We are leveraging them in development and release process. the information between two different places. Agreed that it's ideal to have all the information in one place, but the pre commit jobs for JIRA have some limitations ( https://issues.apache.org/jira/browse/HADOOP-17798) and I don't want to maintain the jobs anymore. Yes, but the developers don't seem to look at the JIRA issue or read the discussion thread. That's why I sent the [NOTICE] mail. Really? Most of the Hadoop developers currently use GitHub PR for code review. support/consensus and without a vote thread The background is to reduce my workload for maintaining the precommit jobs and to improve the process. I didn't think we needed a vote. Anyway, the change is a 2-way door decision, I'm okay to revert the change and start a discussion & vote. -Akira ",executive
6,"Re: [E] [NOTICE] Attaching patches in JIRA issue no longer works I think this deserves some attention. More than just the question of JIRA vs GitHub Issues, I'm a little concerned that we completely changed the way we post code changes without a vote thread or even a discussion thread that had a clear outcome. The previous thread ([DISCUSS] Tips for improving productivity, workflow in the Hadoop project?) had many committers giving opinions on the matter, but it never came to conclusion and just sat there with no traffic for months. The way I read the previous thread was that committers were proposing that we clean out stale PRs, not that we turn off JIRA patches/Precommit builds. I'm not necessarily saying that we should go with patches vs GitHub PRs, but I'm concerned that the decision was made without community support/consensus and without a vote thread (not sure if that's necessary for this type of change or not). Eric ",executive
21,"Re: [E] [NOTICE] Attaching patches in JIRA issue no longer works If we're not using patches on JIRA anymore, why are we using JIRA at all? Why don't we just use GitHub Issues? Using JIRA to then redirect to GitHub seems unintuitive and will fracture the information between two different places. Do the conversations happen on JIRA or on a GitHub PR? Having conversations on both is confusing and splitting information. I would rather use JIRA with patches or GitHub Issues with PRs. I think anything in between splits information and makes it hard to find. Eric ",executive
1452,"RE: Chimera as new component in Apache Commons Thanks Benedikt for your support! This is really great help. Makes sense. Sub modules share the same Commons community. This doesn't conflict with the fact that sub modules has its own release cycle and versioning. Yes, keeping a stable API is very important for shared libraries. 3. Apache Commons components usually have a (boring) descriptive name, rather then a fancy one. This is the reason why we renamed Apache Commons Sanselan zu Apache Commons Imaging. People should be able to tell just by looking at the name of a component what that component is about. IMHO Chimera falls into the fancy name category, so maybe we will discuss that name. There is no problem that Chimera be renamed to something like ""crypto"". Thanks, Haifeng",executive
1141,"Re: [DISCUSS] Merging API-based scheduler configuration to trunk/branch-2 Thanks Andrew and Larry for the feedback. I was hoping to start a merge vote early next week, because of the 2.9 deadline. (I suppose meeting this deadline depends on the outcome of this DISCUSS thread.) Appreciate any questions you have on the JIRA. To answer your questions Larry: *Is this feature extending the existing YARM RM REST API?* Yes, this feature adds another endpoint to the YARN RM REST API, for users to send their configuration change requests. *When it isn't enabled what is the API behavior?* When disabled and API is called, nothing happens, it will return HTTP 400 bad request. *Does it implement the trusted proxy pattern for proxies to be able to impersonate users and most importantly to dictate what proxies would be allowed to impersonate an admin for this API - which I assume will be required?* Right now there's a pluggable policy which controls which users can make which configuration changes (see YARN-5949). The default policy is to only allow YARN admins (i.e. users in yarn.admin.acl) to make changes. There's also an implementation of a more relaxed policy which allows admins of queues to make configuration modifications to their own queue. Not sure if this answers your question. Thanks, Jonathan Hung ",existence
1143,"Re: [DISCUSS] Merging API-based scheduler configuration to trunk/branch-2 Hi Jonathan - Thank you for bringing this up for discussion! I would personally like to see a specific security review of features like this - especially ones that allow for remote access to configuration. I'll take a look at the JIRA and see whether I can come up with any concerns or questions and I would urge others to give it a pass from a security perspective as well. In addition, here are a couple questions of the top of my head: Is this feature extending the existing YARM RM REST API? When it isn't enabled what is the API behavior? Does it implement the trusted proxy pattern for proxies to be able to impersonate users and most importantly to dictate what proxies would be allowed to impersonate an admin for this API - which I assume will be required? --larry ",executive
1144,"Re: [DISCUSS] Merging API-based scheduler configuration to trunk/branch-2 Hi Jonathan, I'm okay with putting this into branch-3.0 for GA if it can be merged within the next two weeks. Even though beta1 has slipped by a month, I want to stick to the targeted GA data of Nov 1st as much as possible. Of course, let's not sacrifice quality or stability for speed; if something's not ready, let's defer it to 3.1.0. Subru, have you been able to review this feature from the 2.9.0 perspective? It'd add confidence if you think it's immediately ready for merging to branch-2 for 2.9.0. Thanks, Andrew ",not-ak
1149,"[DISCUSS] Merging API-based scheduler configuration to trunk/branch-2 Hi everyone, Starting this thread to discuss merging API-based scheduler configuration to trunk/branch-2. The feature adds the framework for allowing users to modify scheduler configuration via REST or CLI using a configurable backend (leveldb/zk are currently supported), and adds capacity scheduler support for this. The umbrella JIRA is YARN-5734. All the required work for this feature is done and committed to branch YARN-5734, and a full diff has been generated at YARN-7241. Regarding compatibility, this feature is configurable and turned off by default. The feature has been tested locally on a couple RMs (since it is an RM only change), with queue addition/removal/updates tested on single RM (leveldb) and two RMs (zk). Also we verified the original configuration update mechanism (via refreshQueues) is unaffected when the feature is off/not configured. Our original plan was to merge this to trunk (which is what the YARN-7241 diff is based on), and port to branch-2 before the 2.9 release. @Andrew, what are your thoughts on also merging this to branch-3.0? Thanks! Jonathan Hung",existence
731,"Re: Cassandra 4.0 Dev Work Status Hi Everyone, Josh is traveling this week so he sent me a brief summary and I offered to send it to the mailing list w/ a few updates. There was enough progress in the last week to warrant an update. The 4.0 board can be found at https://issues.apache.org/jira/secure/RapidBoard.jspa?rapidView=355. More details below. - *Progress*: We closed 8 more tickets this week for a rolling total of 26 (up from 18 in the last update) of 122 (up from 115 last week) across 4.0-alpha, 4.0-beta, and 4.0. Closed: https://issues.apache.org/jira/issues/?jql=project%20%3D%20CASSANDRA%20AND%20fixversion%20in%20(4.0%2C%204.0.0%2C%204.0-alpha%2C%204.0-beta)%20AND%20resolved%20%3E%3D%20-4w Total: https://issues.apache.org/jira/issues/?filter=12347782 *LHF / Failing Tests*: 3 of the 6 failing tests now have an assignee. The remaining 3 unassigned tickets can be found at https://issues.apache.org/jira/secure/RapidBoard.jspa?rapidView=355&quickFilter=1660&quickFilter=1658 *Needs Reviewer*: 6 tickets need a reviewer. This is down from 10 last week. They can be found at https://issues.apache.org/jira/secure/RapidBoard.jspa?rapidView=355&quickFilter=1659 *Available to work*: 3 alpha (the remaining test failures), 4 beta, and 18 RC issues are unassigned. They can be found at https://issues.apache.org/jira/secure/RapidBoard.jspa?rapidView=355&view=detail&selectedIssue=CASSANDRA-15308&quickFilter=1661&quickFilter=1658 *Ready to Commit*: 7 tickets are marked ready to commit. They can be found at https://issues.apache.org/jira/browse/CASSANDRA-15461?jql=project%20%3D%20CASSANDRA%20AND%20fixversion%20in%20(4.0%2C%204.0.0%2C%204.0-alpha%2C%204.0-beta)%20AND%20status%20%3D%20%22Ready%20to%20Commit%22%20 *Testing*: On our 4.0 Quality and Test Plan Wiki ( https://cwiki.apache.org/confluence/display/CASSANDRA/4.0+Quality%3A+Components+and+Test+Plans ) we have 5 remaining open Shepherd positions (down from 7 last week). 11 areas do not have a tracking ticket (down from 13 last week). 13 areas remain not started. Thanks everyone for your contributions! Its exciting to see this progress. Jordan ",not-ak
733,"Re: Cassandra 4.0 Dev Work Status Specifically, if anyone's interested, I think we should probably maintain three tags for work landing in 4.0, e.g. 4.0-alpha1, 4.0-alpha, 4.0 This helps track all of the relevant information, the first limited release, the first general release, and the point in the release process it was delivered. ?On 15/01/2020, 13:34, ""Benedict Elliott Smith"" wrote: I think there's always been a distinction in the way we treat alphas/betas versus patch releases, because they have a staged delivery (landing for dev and users in different releases). I don't know we've ever been totally consistent about it across major versions though. I think we can view 4.0-alpha as equivalent to 4.x, except that it has value being maintained after commit, to historically track where things land in the release process. It was discussed somewhere, not ages ago and I can't remember where, that there was value in this. There's probably also value in introducing 4.0-alpha1 etc on top. We should probably decide and document it, as you say, so that we can at least be consistent next major. ?On 15/01/2020, 13:18, ""Joshua McKenzie"" wrote: Historically I believe we used the "".x"" nomenclature to indicate general release we wanted things in (4.x, 3.11.x, 3.6.x, etc), and then upon merge update the FixVersion to reflect which release it actually went in. Is that still a thing, and whether a thing or not, is the current appropriate usage of FixVersion on the project documented somewhere? ",executive
734,"Re: Cassandra 4.0 Dev Work Status I think there's always been a distinction in the way we treat alphas/betas versus patch releases, because they have a staged delivery (landing for dev and users in different releases). I don't know we've ever been totally consistent about it across major versions though. I think we can view 4.0-alpha as equivalent to 4.x, except that it has value being maintained after commit, to historically track where things land in the release process. It was discussed somewhere, not ages ago and I can't remember where, that there was value in this. There's probably also value in introducing 4.0-alpha1 etc on top. We should probably decide and document it, as you say, so that we can at least be consistent next major. ?On 15/01/2020, 13:18, ""Joshua McKenzie"" wrote: Historically I believe we used the "".x"" nomenclature to indicate general release we wanted things in (4.x, 3.11.x, 3.6.x, etc), and then upon merge update the FixVersion to reflect which release it actually went in. Is that still a thing, and whether a thing or not, is the current appropriate usage of FixVersion on the project documented somewhere? ",not-ak
735,"Re: Cassandra 4.0 Dev Work Status Historically I believe we used the "".x"" nomenclature to indicate general release we wanted things in (4.x, 3.11.x, 3.6.x, etc), and then upon merge update the FixVersion to reflect which release it actually went in. Is that still a thing, and whether a thing or not, is the current appropriate usage of FixVersion on the project documented somewhere? ",not-ak
736,"Re: Cassandra 4.0 Dev Work Status Just realized I'd misunderstood Mick's original email, apologies. I'd originally interpreted it as a question of prioritization, but the intent was to ensure that the Fix Version field reflects the release a given change is /included in/, not /originally targeted for/. Apologies for my misunderstanding. Agreed yes; it'd make sense to update recently-committed items that have a future fix version to indicate they were resolved during alpha. I haven't seen fix version refer to specific alpha releases (given that there's just one at the moment), but agree that it would be useful to differentiate between which alpha/beta/RC build a given change lands in. Thanks Mick! � Scott ________________________________________ From: Mick Semb Wever Sent: Tuesday, January 14, 2020 12:44 PM To: dev@cassandra.apache.org Subject: Re: Cassandra 4.0 Dev Work Status Yeah, though there's a nuance here between the ticket milestone when it is open and the version it becomes available in. That is milestones are indicated by the fixVersions field while a ticket is open, and with the "".x"" suffixed versions. And when the ticket gets resolved/closed the fixVersion is then updated to the exact version it becomes available in. But given that we don't actually have those exact alpha1, alpha2, etc versions, maybe i missed a piece of info along the way, and this isn't true for the alpha/beta/RCs ? --------------------------------------------------------------------- To unsubscribe, e-mail: dev-unsubscribe@cassandra.apache.org For additional commands, e-mail: dev-help@cassandra.apache.org --------------------------------------------------------------------- To unsubscribe, e-mail: dev-unsubscribe@cassandra.apache.org For additional commands, e-mail: dev-help@cassandra.apache.org",not-ak
737,"Re: Cassandra 4.0 Dev Work Status Yeah, though there's a nuance here between the ticket milestone when it is open and the version it becomes available in. That is milestones are indicated by the fixVersions field while a ticket is open, and with the "".x"" suffixed versions. And when the ticket gets resolved/closed the fixVersion is then updated to the exact version it becomes available in. But given that we don't actually have those exact alpha1, alpha2, etc versions, maybe i missed a piece of info along the way, and this isn't true for the alpha/beta/RCs ? --------------------------------------------------------------------- To unsubscribe, e-mail: dev-unsubscribe@cassandra.apache.org For additional commands, e-mail: dev-help@cassandra.apache.org",not-ak
738,"Re: Cassandra 4.0 Dev Work Status I think the intent of the milestones is meant to indicate that contributors view completion of those items as exit criteria for alpha / beta / RC; not necessarily that all items will be completed in strict order. In principle I'd interpret work targeting earlier milestones as higher priority, but am generally glad to see any contribution that helps us close items in any pre-release milestone. :-) ________________________________________ From: Mick Semb Wever Sent: Tuesday, January 14, 2020 10:27 AM To: dev@cassandra.apache.org Subject: Re: Cassandra 4.0 Dev Work Status shouldn't we only have issues closed in 4.0-alpha, given we are not yet at 4.0-beta and 4.0 ? --------------------------------------------------------------------- To unsubscribe, e-mail: dev-unsubscribe@cassandra.apache.org For additional commands, e-mail: dev-help@cassandra.apache.org --------------------------------------------------------------------- To unsubscribe, e-mail: dev-unsubscribe@cassandra.apache.org For additional commands, e-mail: dev-help@cassandra.apache.org",not-ak
739,"Re: Cassandra 4.0 Dev Work Status shouldn't we only have issues closed in 4.0-alpha, given we are not yet at 4.0-beta and 4.0 ? --------------------------------------------------------------------- To unsubscribe, e-mail: dev-unsubscribe@cassandra.apache.org For additional commands, e-mail: dev-help@cassandra.apache.org",not-ak
740,Re: Cassandra 4.0 Dev Work Status Apparently the formatting on this got straight borked. I may try sending subsequent emails from my personal gmail instead of my @apache address to see if that keeps the rich-text formatting. Sorry for the ugliness. ;) ,not-ak
741,"Cassandra 4.0 Dev Work Status Hello and welcome to our kickoff email about the 4.0 release work status. Structure and contents are fluid; if you'd like to see, or not see, something, please reply and let me know as my goal is purely to help meet the needs of our dev community here. My initial thinking is to send this out weekly or biweekly depending on the volume of change; if things are relatively unchanged by this time next week, I may go twice a month. I put together a board of recent or open 4.0 scope (anything closed within past 4 weeks should show up). My intent is to use this purely as a visualization tool and not advocate for any constraining work in progress, time in col tracking, or other kanban-esque things. I find it useful to have a single place to poke and prod at the state of a release and see where things might need some attention. Some observations that stand out (I'll drop ticket details at bottom of email for convenience): - *Progress: *We've closed out 18 issues in the past 4 weeks of a total of 115 tickets across 4.0-alpha, 4.0-beta, and 4.0. - *LHF: *We have 5 failing tests on our Alpha Release with no assignee on them (*good Low Hanging Fruit for anyone that wants to get involved in the project*) - *Needs Review:* We have 3 beta tickets and 7 release tickets that are Patch Available but do not have a reviewer - *Available to Work:* There are 6 alpha tickets, 5 beta tickets, and 14 RC tickets that do not have an assignee at this time. I'm excluding patch available or in review w/out assignee w/the assumption that they're in flight so probably just need to have assignee fixed on them (I'll take a look in a bit) - *Testing: *On our 4.0 Quality and test plan wiki article , we have the following open opportunities (all data as per wiki, will follow up w/Scott to confirm accuracy): - 13 of 17 areas for testing are not yet started - 8 of 17 areas do not yet have a Shepherd - 13 of the 17 areas do not yet have JIRA tickets associated with them I'd personally like to see the information from the wiki translated into a JIRA epic w/tickets for each area of testing and validation so we can track status in one place and avoid information atrophy and staleness; given the volume of information already in this current email, I'll defer that discussion to another thread. And lastly, I am intentionally avoiding any conversations about scope of tickets for release in this email (4.0 vs. 4.x, etc). Given the friction last week on the topic, I'd like to start out just by providing insight and visibility to people and, assuming there's interest, I'm happy to facilitate discussions around scope separately (on JIRA or dev list, etc). *Below is an embedded list of tickets with states in case you want to more easily peruse them or pick up work from here w/out going to the board above:* 4.0 Test Failures with no Assignee Link CASSANDRA-15307 Fix flakey test_remote_query - cql_test.TestCQLSlowQuery test 4.0-alpha Link CASSANDRA-15306 Investigate why we are allocating 8MiB chunks and reaching the maximum BufferPool size 4.0-beta Link CASSANDRA-15311 Fix flakey test_13595 - consistency_test.TestConsistency 4.0-alpha Link CASSANDRA-15315 Fix failing test - test_rolling_upgrade_with_internode_ssl - upgrade_tests.upgrade_through_versions_test.TestProtoV4Upgrade_AllVersions_RandomPartitioner_EndsAt_Trunk_HEAD 4.0-alpha Link CASSANDRA-15314 Fix failing test - test_rolling_upgrade_with_internode_ssl - upgrade_tests.upgrade_through_versions_test.TestProtoV4Upgrade_AllVersions_EndsAt_Trunk_HEAD 4.0-alpha Link CASSANDRA-15313 Fix flaky - ChecksummingTransformerTest - org.apache.cassandra.transport.frame.checksum.ChecksummingTransformerTest 4.0-alpha Link CASSANDRA-15308 Fix flakey testAcquireReleaseOutbound - org.apache.cassandra.net.ConnectionTest 4.0-alpha Patch Available Needing Reviewer(s) Link CASSANDRA-14740 BlockingReadRepair does not maintain monotonicity during range movements Link CASSANDRA-15305 Fix multi DC nodetool status output Link CASSANDRA-15462 Purgable tombstones can cause false positives in repaired data tracking Link CASSANDRA-15461 Legacy counter shards can cause false positives in repaired data tracking Link CASSANDRA-14842 SSL connection problems when upgrading to 4.0 when upgrading from 3.0.x Link CASSANDRA-15300 4.0 rpmbuild spec file is missing auditlogviewer and fqltool Link CASSANDRA-12995 update hppc dependency to 0.7 Link CASSANDRA-15257 Remove joda time from dependencies Link CASSANDRA-14904 SSTableloader doesn't understand listening for CQL connections on multiple ports Link CASSANDRA-14788 Add test coverage workflows to CircleCI config 4.0 with no assignee Link CASSANDRA-14608 Confirm correctness of windows scripts post-9608 Link CASSANDRA-14520 ClosedChannelException handled as FSError Link CASSANDRA-13254 move compaction strategies to dedicated pages and expand on details Link CASSANDRA-15212 CassandraInputStream Bugs Link CASSANDRA-15214 OOMs caught and not rethrown Link CASSANDRA-15307 Fix flakey test_remote_query - cql_test.TestCQLSlowQuery test Link CASSANDRA-15306 Investigate why we are allocating 8MiB chunks and reaching the maximum BufferPool size Link CASSANDRA-15311 Fix flakey test_13595 - consistency_test.TestConsistency Link CASSANDRA-14517 Short read protection can cause partial updates to be read Link CASSANDRA-15315 Fix failing test - test_rolling_upgrade_with_internode_ssl - upgrade_tests.upgrade_through_versions_test.TestProtoV4Upgrade_AllVersions_RandomPartitioner_EndsAt_Trunk_HEAD Link CASSANDRA-15314 Fix failing test - test_rolling_upgrade_with_internode_ssl - upgrade_tests.upgrade_through_versions_test.TestProtoV4Upgrade_AllVersions_EndsAt_Trunk_HEAD Link CASSANDRA-15313 Fix flaky - ChecksummingTransformerTest - org.apache.cassandra.transport.frame.checksum.ChecksummingTransformerTest Link CASSANDRA-14754 Add verification of state machine in StreamSession Link CASSANDRA-14748 Recycler$WeakOrderQueue occupies Heap Link CASSANDRA-14793 Improve system table handling when losing a disk when using JBOD Link CASSANDRA-15308 Fix flakey testAcquireReleaseOutbound - org.apache.cassandra.net.ConnectionTest Link CASSANDRA-14801 calculatePendingRanges no longer safe for multiple adjacent range movements Link CASSANDRA-15406 Add command to show the progress of data streaming and index build Link CASSANDRA-15234 Standardise config and JVM parameters Link CASSANDRA-14697 Transient Replication 4.0 pre-release followup work Link CASSANDRA-14296 Fix eclipse-warnings introduced by 7544 parameter handling Link CASSANDRA-15369 Fake row deletions and range tombstones, causing digest mismatch and sstable growth Link CASSANDRA-15229 BufferPool Regression Link CASSANDRA-14606 Add documentation for java 11 support Thanks everyone for your contributions to this process and for your attention!",executive
242,"Re: Tradeoffs for Cassandra transaction management Hi all I was expecting to stay out of the way while a vote on CEP-15 seemed imminent. But discussing this tradeoffs thread with Jonathan, he encouraged me to say these points in my own words, so here we are. ",not-ak
244,"Re: Tradeoffs for Cassandra transaction management I realise this is not contributing to this discussion, but this email is very difficult to read because it seems like something has happened with formatting. For me it gets displayed as a single paragraph with no line breaks. There seems to be some overlap between the image uploaded to imgur and this email, but some things are only present in the email and not on the image. ",not-ak
247,"Re: Tradeoffs for Cassandra transaction management I'll read more of this in a bit, I want to make sure I fully digest it before commenting on the rest, but this block here deserves a few words: ",not-ak
248,"Tradeoffs for Cassandra transaction management * Hi all,After calling several times for a broader discussion of goals and tradeoffs around transaction management in the CEP-15 thread, I�ve put together a short analysis to kick that off.Here is a table that summarizes the state of the art for distributed transactions that offer serializability, i.e., a superset of what you can get with LWT. (The most interesting option that this eliminates is RAMP.)Since I'm not sure how this will render outside gmail, I've also uploaded it here: https://imgur.com/a/SCZ8jex SpannerCockroachCalvin/FaunaSLOG (see below)Write latencyGlobal Paxos, plus 2pc for multi-partition.For intercontinental replication this is 100+ms. Cloud Spanner does not allow truly global deployments for this reason.Single-region Paxos, plus 2pc. I�m not very clear on how this works but it results in non-strict serializability.I didn�t find actual numbers for CR other than �2ms in a single AZ� which is not a typical scenario.Global Raft. Fauna posts actual numbers of ~70ms in production which I assume corresponds to a multi-region deployment with all regions in the USA. SLOG paper says true global Calvin is 200+ms.Single-region Paxos (common case) with fallback to multi-region Paxos.Under 10ms.Scalability bottlenecksLocks held during cross-region replicationSame as SpannerOLLP approach required when PKs are not known in advance (mostly for indexed queries) -- results in retries under contentionSame as CalvinRead latency at serial consistencyTimestamp from Paxos leader (may be cross-region), then read from local replica.Same as Spanner, I thinkSame as writesSame as writesMaximum serializability flavorStrictUn-strictStrictStrictSupport for other isolation levels?SnapshotNoSnapshot (in Fauna)Paper mentions dropping from strict-serializable to only serializable. Probably could also support Snapshot like Fauna.Interactive transaction support (req�d for SQL)YesYesNoNoPotential for grafting onto C*NightmareNightmareReasonable, Calvin is relatively simple and the storage assumptions it makes are minimalI haven�t thought about this enough. SLOG may require versioned storage, e.g. see this comment .(I have not included Accord here because it�s not sufficiently clear to me how to create a full transaction manager from the Accord protocol, so I can�t analyze many of the properties such a system would have. The most obvious solution would be �Calvin but with Accord instead of Raft�, but since Accord already does some Calvin-like things that seems like it would result in some suboptimal redundancy.)After putting the above together it seems to me that the two main areas of tradeoff are, 1. Is it worth giving up local latencies to get full global consistency? Most LWT use cases use LOCAL_SERIAL. While all of the above have more efficient designs than LWT, it�s still true that global serialization will require 100+ms in the general case due to physical transmission latency. So a design that allows local serialization with EC between regions, or a design (like SLOG) that automatically infers a �home� region that can do local consensus in the common case without giving up global serializability, is desirable.2. Is it worth giving up the possibility of SQL support, to get the benefits of deterministic transaction design? To be clear, these benefits include very significant ones around simplicity of design, higher write throughput, and (in SLOG) lower read and write latencies.I�ll doubleclick on #2 because it was asserted in the CEP-15 thread that Accord could support SQL by applying known techniques on top. This is mistaken. Deterministic systems like Calvin or SLOG or Accord can support queries where the rows affected are not known in advance using a technique that Abadi calls OLLP (Optimistic Lock Location Prediction), but this does not help when the transaction logic is not known in advance.Here is Daniel Abadi�s explanation of OLLP from �An Overview of Deterministic Database Systems :�In practice, deterministic database systems that use ordered locking do not wait until runtime for transactions to determine their access-sets. Instead, they use a technique called OLLP where if a transaction does not know its access-sets in advance, it is not inserted into the input log. Instead, it is run in a trial mode that does not write to the database state, but determines what it would have read or written to if it was actually being processed. It is then annotated with the access-sets determined during the trial run, and submitted to the input log for actual processing. In the actual run, every replica processes the transaction deterministically, acquiring locks for the transaction based on the estimate from the trial run. In some cases, database state may have changed in a way that the access sets estimates are now incorrect. Since a transaction cannot read or write data for which it does not have a lock, it must abort as soon as it realizes that it acquired the wrong set of locks. But since the transaction is being processed deterministically at this point, every replica will independently come to the same conclusion that the wrong set of locks were acquired, and will all independently decide to abort the transaction. The transaction then gets resubmitted to the input log with the new access-set estimates annotated.Clearly this does not work if the server-visible logic changes between runs. For instance, consider this simple interactive transaction:cursor.execute(""BEGIN TRANSACTION"")count = cursor.execute(""SELECT count FROM inventory WHERE id = 1"").result[0]if count > 0: cursor.execute(""UPDATE inventory SET count = count - 1 WHERE id = 1"")cursor.execute(""COMMIT TRANSACTION"")The first problem is that it�s far from clear how to do a �trial run� of a transaction that the server only knows pieces of at a time. But even worse, the server only knows that it got either a SELECT, or a SELECT followed by an UPDATE. It doesn�t know anything about the logic that would drive a change in those statements. So if the value read changes between trial run and execution, there is no possibility of transparently retrying, you�re just screwed and have to report failure.So Abadi concludes,[A]ll recent [deterministic database] implementations have limited or no support for interactive transactions, thereby preventing their use in many existing deployments. If the advantages of deterministic database systems will be realized in the coming years, one of two things must occur: either database users must accept a stored procedure interface to the system [instead of client-side SQL], or additional research must be performed in order to enable improved support for interactive transactions.TLDR:We need to decide if we want to give users local transaction latencies, either with an approach inspired by SLOG or with tuneable serializability like LWT (trading away global consistency). I think the answer here is clearly Yes, we have abundant evidence from LWT that people care a great deal about latency, and specifically that they are willing to live with cross-datacenter eventual consistency to get low local latencies.We also need to decide if we eventually want to support full SQL. I think this one is less clear, there are strong arguments both ways.P.S. SLOG deserves more attention. Here are links to the paper , Abadi�s writeup , and Murat Demirbas�s reading group compares SLOG to something called Ocean Vista that I�ve never heard of but which reminds me of Accord .* -- Jonathan Ellis co-founder, http://www.datastax.com @spyced",executive
2258,"Re: Distributed Counters Use Cases Ryan, Thanks for the insight. FWIW, SimpleGeo's use cases are very similar do the 2nd use case Ryan mentioned. We want to do rollups by time, geography, and facet of a customer's record. The most important benefit Cassandra brings for us is the ability to handle large number of rows (very detailed rollups). Secondary is the ability to increment at high volume (the increment buffering that Ryan has mentioned seems highly valuable). Dirty Burritos, Inc. <# burritos sold> in by , , and Mission Total: 1,726 Meat Chicken: 765 Beef: 620 Chorizo: 173 Veggie: 168 SOMA Total: 1,526 Meat Chicken: 665 Beef: 520 Chorizo: 173 Veggie: 168 Marina Total: 1,326 Meat Chicken: 565 Beef: 420 Chorizo: 173 Veggie: 168 We would roll up by many different time periods (minutes, hours, days), geographic boundaries (neighborhod, zip, city, state), metrics (# burritos sold, order total, delivery time), and properties (meat, male/female, order size). With a smart schema, I think we can store and update this data in real-time and make it reasonably query-able, and it will be much simpler and easier than batch processing. This kind of reporting isn't novel or special, but the cost to produce this data become extremely low when you don't have to futz with Hadoop, batch processing, broken jobs, etc. We have looked at a few ways to store each increment in a new column, and possibly have some kind of high-level compaction that comes through and cleans it up, but it just become unwieldy at the app level. We plan on messing with #1072 in the very new future, as well as offering to beta test the increment buffering Ryan has mentioned. -Ben Standefer ",existence
2259,"Distributed Counters Use Cases In the spirit of making sure we have clear communication about our work, I'd like to outline the use cases Twitter has for distributed counters. I expect that many of you using Cassandra currently or in the future will have similar use cases. The first use case is pretty simple: high scale counters. Our Tweet button [1] is powered by #1072 counters. We could every mention of every url that comes through a public tweet. As you would expect, there are a lot of urls and a lot of traffic to this widget (its on many high traffic sites, though it is highly cached). The second is a bit more complex: time series data. We have built infrastructure that can process logs (in real time from scribe) or other events and convert them into a series of keys to increment, buffer the data for 1 minute and increment those keys. For logs, each aggregator would do its on increment (so per thing you're tracking you get an increment for each aggregator), but for events it'll be one increment per event. We plan to open source all of this soon. We're hoping to soon start replacing our ganglia clusters with this. For the ganglia use-case we end up with a large number or increments for every read. For monitoring data, even a reasonably sized fleet with a moderate number of metrics can generate a huge amount of data. Imagine you have 500 machines (not how many we have) and measure 300 (a reasonable estimate based on our experience) metrics per machine. Suppose you want to measure these things every minute and roll the values up every hour, day, month and for all time. Suppose also that you were tracking sum, count, min, max, and sum of squares (so that you can do standard deviation). You also want to track these metrics across groups like web hosts, databases, datacenters, etc. These basic assumptions would mean this kind of traffic: (500 + 100 ) * 300 * 5 * 4 3,600,000 increments/minute (machines groups) metrics time granularities aggregates Read traffic, being employee-only would be negligible compared to this. One other use case is that for many of the metrics we track, we want to track the usage across several facets. For example [2] to build our local trends feature, you could store a time series of terms per city. In this case supercolumns would be a natural fit because the set of facets is unknown and open: Imagine a CF that has data like this: city0 => hour0 => { term1 => 2, term2 => 1000, term3 => 1}, hour1 => { term5 => 2, term2 => 10} city1 => hour0 => { term12 => 3, term0 => 500, term3 => 1}, hour1 => { term5 => 2, term2 => 10} Of course, there are some other ways to model this data� you could collapse the subcolumn names into the column names and re-do how you slice (you have to slice anyway). You have to have fixed width terms then, though: city0 => { hour0 + term1 => 2, hour0 + term2 => 1000, hour0 + term3 => 1}, hour1 => { hour1 + term5 => 2, hour1 + term2 => 10} city1 => { hour0 + term12 => 3, hour0 + term0 => 500, hour0 + term3 => 1}, hour1 => { hour1 + term5 => 2, hour1 + term2 => 10} This is doable, but could be rough. The other option is to have a separate row for each facet (with a compound key of [city, term]), and build a custom comparator that only looks at the first part for generating the token, they we have to do range slices to get all the facets. Again, doable, but not pretty. -ryan 1. http://twitter.com/goodies/tweetbutton 2. this is not how we actually do this, but it would be a reasonable approach.",executive
615,Re: DataStax Driver Donation to Apache Cassandra Project CEP seems reasonable enough. I'll talk to Alex and Olivier. ,not-ak
616,"Re: DataStax Driver Donation to Apache Cassandra Project Can we take it to a CEP now? Even if the decision is to take one driver as a guinea pig and learn as we go, there's some questions that need to be thrashed out in advance (somewhere better than this thread), e.g. the incubator ip clearance steps, and other questions to tackle along the way: versions and supported branches, committers and maintainers, artifact and package names, CI, jira, ML, coordination to server, etc; so a CEP can be the document to land it all.",not-ak
617,"Re: DataStax Driver Donation to Apache Cassandra Project I don't see any reason not to bring in other drivers to the project. We can start with the Java driver. I think Nate might be aware of the specifics of the process. Dinesh --------------------------------------------------------------------- To unsubscribe, e-mail: dev-unsubscribe@cassandra.apache.org For additional commands, e-mail: dev-help@cassandra.apache.org",not-ak
618,"Re: DataStax Driver Donation to Apache Cassandra Project My understanding is that there's comparable traffic on python, java, and node drivers in terms of usage out in the Cassandra ecosystem. Shall we get started w/the java process and incubation on the donation (CLA's, vetting contributions, etc) with plans to follow up with python and then node? What are next steps here? Anyone knowledgeable on thread? ",not-ak
683,Re: DataStax Driver Donation to Apache Cassandra Project This approach makes complete sense to me: let's sort out how to accept the Java Driver (I guess? most widely used and reference impl) and then we can iterate from there.,not-ak
684,"Re: DataStax Driver Donation to Apache Cassandra Project I agree keeping the source separate is a good idea to start. If we find some benefit later in merging the two trees, it's easy enough to do so, it's more of a pain to split things apart. The build system used plays a big part as well - ant is definitely not doing us any favors here. ",not-ak
685,Re: DataStax Driver Donation to Apache Cassandra Project ,not-ak
688,"Re: DataStax Driver Donation to Apache Cassandra Project You're confidently responding to something I wasn't trying to say. :) I may not have communicated clearly. I was attempting to enumerate: 1. New feature development will likely require coordination between server and drivers (i.e. driver changes are required to support new features in server) 2. Future roadmap for the core server and drivers will likely overlap (see #1) 3. CEP's for 1 and 2, assuming one accepts the assertion that features require driver changes, mean CEP's will have components of both 4. Independent architectural or API changes in the drivers will likely impact the server, and thus also require coordination. Especially with drivers being nested and used extensively in cqlsh, tests, etc. I was not speaking to the day to day maintenance of the projects but rather the larger feature-level, roadmap, architectural planning of them. I would not expect day to day maintenance to intersect with the governance of the projects on a regular basis. ",executive
689,"Re: DataStax Driver Donation to Apache Cassandra Project I want to clarify that my plea here is just that we acknowledge that once we adopt drivers (especially if all of them), the ""project"" becomes quite big. All sane big projects have a minimum of organization, so let's make sure we have enough organization to make sure we don't make our future lives harder than it needs to. And there is a clear and natural separation between the server and (each) drivers, so that's an obvious point of organization/separation. Again, at a ""high"" level, I'm in favor of the Cassandra project being both server and drivers (not saying it's not debatable). So a single _user_ ML make sense, as well as a single web site, document and CEP process (I do see CEP as being somewhat high-ish level). My concern is more for the day-to-day maintenance work. Here, I think there is gonna be 3 types of people: 1. some will _primarily_ focus on (a) driver development. 2. some will _primarily_ focus on server development. 3. some may have interested in both, but won't be able to focus too much on either (because again, the sum is too big, and in a way too unrelated). And I actually expect 1 and 2 to preponderantly drive the day-to-day maintenance. So I'd like to keep things easy for those population (but obviously, with the goal of not hinder collaboration and consistency overall). Concretely, my initial thinking (but haven't think some of those through a lot) are: - as said above, user list, web site, documentation and CEP would be global. - new specific JIRA projects for drivers, and JIRA notifications going to separate 'commits' mailing lists. To me, that one point is a no-brainer, I don't see why we wouldn't do that, and I'll fight for that one. - dev mailing lists: I'm conflicted. I see a few ""dev"" discussion gaining from being common, but I think most won't be (common). My gut reaction was to suggest separate lists but I'm warming up to the idea of experimenting with one and splitting later if it's unmanageable. - source repository: I think I don't have a super strong opinion so far. I'm not a fan of abusing mono-repo, and I think it would be overall cleaner to have separate repo with separate history. But I reckon there is pros to mono-repo as well so this might boil down to a personal preference. - committers and PMC members pool: I believe that if we keep the organization of a single project in the Apache sense (which again, is debatable but I'm in favor at this point), then that imply a single pool of committers/PMC members. Which is fine by me, outside of the fact that it imo makes it even more urgent to have the PMC conclude some ongoing and never concluded discussions (around more objective criteria for committers/PMC members nominations). - other: there is actually a bunch of other things we'll need to discuss in that scenario. For instance, DataStax drivers currently have their independent release cycles and versioning.Especially if we go the mono-repo route, then it would make sense to move towards releasing everything together as Stephen mentions Tinkerpop is doing, but that in turn may require a non trivial amount of build-tools setup. Lastly, and to Stephen's previous email, it might be more manageable to accept one drivers first and figure all the details/issues/questions that are bound to arise before accepting more. It's worth discussing at least. there I'll address, because it's an important point. If we're talking day to day maintenance, so the bulk of the work really, then I feel rather confident saying that you are wrong, that the vast majority of the work is mostly unrelated. Which is important, because that's really why I said that no-one can effectively focus on both sides. You can only focus on one and only dabble in the other(s), because the overlap is not that big. -- Sylvain ",executive
690,"Re: DataStax Driver Donation to Apache Cassandra Project Thanks, Stephen, this is really helpful! ",not-ak
691,"Re: DataStax Driver Donation to Apache Cassandra Project Every Apache project is different, so it's quite possible that the experience I have in this area doesn't apply much here, but I'll offer some words on the matter in the event that some of it is helpful. For many years even prior to joining Apache, TinkerPop was quite against bringing in driver-style sub-projects. Our main concern was one that I think was voiced here in this thread in some fashion, where core developers would have to be knowledgeable of the incoming body of work and maintain that going forward. For core contributors who were primarily Java developers it was difficult to think that we'd suddenly be responsible for reviews/VOTEs on Python code, for example. It was with a bit of trepidation that we eventually decided it a good idea and opened the project to them. For our purposes we brought all such projects directly into our core repository as the thinking was that we wanted to keep all aspects of the project unified (testing, release, etc) to ensure that for a particular release tag you could be sure that everything worked together. We initially started with just Python and developed that as our model for how new drivers would arrive (there were already other disparate projects out there in other languages). We wanted a model that ensured a reasonably high bar for acceptance and created a rough set of minimum criteria we wanted to have for adding a new driver to our release lines. The core of that criteria was a common language agnostic test suite that needed to pass for us to consider it ""ready"" in any sense and the project needed to build, test and release using Maven (which is our build tool for the project). The former ensured that we had a reasonable level of common tested functionality among drivers and the latter ensured an easy and consistent way to manage build/release practices (which fed nicely into our Docker infrastructure for both full builds and for giving non-JVM developers a nice way to develop drivers against the latest code without having to be Java experts). Once we established this approach with Python, we successfully brought in .NET and Javascript. I think there were a number of nice upsides to deciding to bring in drivers in the first place and then in the model for acceptance that we chose: + We saw a greater diversity of folks contributing in general as the ecosystem opened up beyond just the JVM. + We saw that the general community coalesced around the ""official"" drivers, contributing as one to them, rather than going off and creating one-off projects. I'm not really aware of any third-party drivers right now for the languages we support, but if you look at something like Go, there are three or more choices. I suppose Go would be our next target for official inclusion. + Release day was pretty simple despite the complexity of the environment with that mixed ecosystem because of our unified build model using Maven and there wasn't a lot of disparate tooling exposed to the release manager directly. + I can't say that we really saw problems with core project developers (who mostly new Java) having to review python/c#/javascript. For the most part, the contribution quality was high and we managed and became more knowledgeable as we went. + As we released drivers and core together, we no longer had situations where some third-party driver lagged behind some feature in core - if you wanted to use the latest core functionality you just used the latest release of core and driver and you could be assured they worked together and we felt confident saying so. Doing it over again, I think I would still consider going single repo for this situation but I think I might not place the requirement that the projects build with Maven. I think Maven has turned-off some contributors from those language ecosystems who don't know the JVM. They would have been much more comfortable just working more directly with the tool systems that they were familiar with. Of course, to get rid of local maven builds completely we would have to build a ""latest"" Docker images so that folks didn't need to do that themselves like they do now (also with Maven). Aside from TinkerPop experiences I will offer that, while I'm not completely sure, I think that for a contribution like this one where the bulk of the code has been developed outside of the ASF, the DS drivers would need to go through an IP Clearance process: https://incubator.apache.org/ip-clearance/ ",executive
692,"Re: DataStax Driver Donation to Apache Cassandra Project Separate JIRA is enough enough, separate dev list.. maybe. I don't see much purpose in trying to organize into a hierarchy, what problem are you actually solving here? It sounds like you don't trust folks who work on the driver to not commit random code to Cassandra, is that the case? If that's not a concern, I don't know what we gain by a hierarchy other than complexity. Every committer doesn't have to work on every part of the project, nor be aware of the daily activity. ",not-ak
693,"Re: DataStax Driver Donation to Apache Cassandra Project +1, this is essentially my position, and I agree with the baseline requirements for a merged project. I'm not trying to rule anything out, just wondering what the optimal division is. I think from the user point of view we can hopefully achieve the same appearance with or without the same project governance. The goal should absolutely be to have ""official"" drivers, and close association. We can link them directly in the Cassandra site either way. The question is only how the projects are best structured. It seems to me that drivers benefit from an umbrella structure for their governance and for discussing their commonalities and direction, but also need their own distinct lists and Jira. So we'd be talking about going from a flat hierarchy to perhaps a three-tier structure, something like: PMC / \ Drivers Cassandra / | \ \ Driver1 Dvr.2 Dvr.3 ... Sidecar? Since drivers are functionally very different to the database server and its accoutrements, there will likely be very different kinds of discussions, with completely different release schedules - hopefully mostly around programmatic API UX, client-side performance, etc. It feels to me intuitively like there is benefit in keeping distinct the projects with different focuses and technical problems, so that discussions more easily can happen simultaneously at the design and decision-making levels. This might not only help avoid fragmentation of the decision-making in this community, but also help unify decision-making across the drivers. By having a decision-making body whose purview is only drivers, we might better emphasise collaboration between those drivers, since that is the body's only function. I'm not staking this out as a strongly held prior conviction, just that I see these problems and think we have to consider this carefully upfront, as I don't think this kind of decision is easy to revisit. ?On 27/04/2020, 10:51, ""Sylvain Lebresne"" wrote: Fwiw, I agree with the concerns raised by Benedict, and think we should carefully think about how this is handled. Which isn't not a rejection of the donation in any way. Drivers are not small projects, and the majority of their day to day maintenance is unrelated to the server (and the reverse is true). From the user point of view, I think it would be fabulous that Cassandra appears like one project with a server and some official drivers, with one coherent website and documentation for all. I'm all for striving for that. Behind the scenes however, I feel tings should be setup so that some amount of separation remains between server and whichever drivers are donated and accepted, or I'm fairly sure things would get messy very quickly[1]). In my mind that means *at a minimum*: - separate JIRA projects. - dedicated _dev_ (and commits) mailing lists. But it's also worth thinking whether a single pool of committers/PMC members is desirable. Tbc, I'm not sure what is the best way to achieve this within the constraint of the Apache fundation, and maybe I'm just stating the obvious here. [1] fwiw, I say this as someone that at some points in time was simultaneously somewhat actively involved in both Cassandra and the DataStax Java driver. -- Sylvain ",executive
694,"Re: DataStax Driver Donation to Apache Cassandra Project To step out of the weeds a bit - other than the Zookeeper / Curator example, does anyone know of any other apache projects that have either subprojects or complementary sideprojects they're interdependent upon in their ecosystems? I'd like to reach out to some other pmc's for advice and feedback on this topic since there's no sense in reinventing the wheel if other projects have wisdom to share on this. ",not-ak
695,"Re: DataStax Driver Donation to Apache Cassandra Project re: ML noise, how hard would it be to filter out JIRA updates w/component ""Drivers""? Or from JIRA queries? For governance, I see it cutting both ways. If we have two separate projects and ML's for drivers and C*, how do we keep a coherent view of new features and roadmap stuff? Do we have CEP's for both projects and tie them together? Do we drive changes in the driver feature ecosystem via CEP's in C*? In the Venn diagram of overlap vs. non between the two projects, I see there being more overlap than not. ",not-ak
696,"Re: DataStax Driver Donation to Apache Cassandra Project +1 Can you say more about what ""getting messy very quickly"" means here? If we're thinking through how this would be setup, initially we had the same Jira project for sidecar but now there is a separate one to track sidecar specific jiras. At the moment we do not have a separate mailing list. I think Cassandra dev mailing list's volume is low enough to keep using the same ML. There is an added value that it gives visibility and developers don't need to go between multiple mailing lists. --------------------------------------------------------------------- To unsubscribe, e-mail: dev-unsubscribe@cassandra.apache.org For additional commands, e-mail: dev-help@cassandra.apache.org",executive
697,"Re: DataStax Driver Donation to Apache Cassandra Project Fwiw, I agree with the concerns raised by Benedict, and think we should carefully think about how this is handled. Which isn't not a rejection of the donation in any way. Drivers are not small projects, and the majority of their day to day maintenance is unrelated to the server (and the reverse is true). appears like one project with a server and some official drivers, with one coherent website and documentation for all. I'm all for striving for that. Behind the scenes however, I feel tings should be setup so that some amount of separation remains between server and whichever drivers are donated and accepted, or I'm fairly sure things would get messy very quickly[1]). In my mind that means *at a minimum*: - separate JIRA projects. - dedicated _dev_ (and commits) mailing lists. But it's also worth thinking whether a single pool of committers/PMC members is desirable. Tbc, I'm not sure what is the best way to achieve this within the constraint of the Apache fundation, and maybe I'm just stating the obvious here. [1] fwiw, I say this as someone that at some points in time was simultaneously somewhat actively involved in both Cassandra and the DataStax Java driver. -- Sylvain ",executive
698,"Re: DataStax Driver Donation to Apache Cassandra Project Currently there are 36 servers, all Ubuntu. What can't be tested with docker (ie mac and windows) would need additional servers donated. Maybe start gathering and writing up the PROs and CONs for each approach in a separate doc. --------------------------------------------------------------------- To unsubscribe, e-mail: dev-unsubscribe@cassandra.apache.org For additional commands, e-mail: dev-help@cassandra.apache.org",not-ak
699,"Re: DataStax Driver Donation to Apache Cassandra Project Thanks for the early input here. 4.x is our actively developed branch. It was a major release with some breaking changes: https://www.datastax.com/blog/2019/03/introducing-java-driver-4 That will probably work. I asked partially because the driver CI can have a fairly extensive matrix of platforms, runtimes, and server versions. I'm not sure how much excess capacity the current Jenkins pool has. How should we proceed deciding sub-project vs. incubator question discussed here? Adam ",not-ak
700,"Re: DataStax Driver Donation to Apache Cassandra Project Benedict, Your concerns are valid and its great to think through issues that might occur in the future. I personally have never thought that the driver should be treated as a separate entity because as a user, Cassandra cannot be used _without_ a driver. Drivers are the public interface and are tightly coupled with the server. I personally feel that we should take the donation as part of the Cassandra project and if we see issues we try to resolve them at that point. Thanks, Dinesh --------------------------------------------------------------------- To unsubscribe, e-mail: dev-unsubscribe@cassandra.apache.org For additional commands, e-mail: dev-help@cassandra.apache.org",existence
702,"Re: DataStax Driver Donation to Apache Cassandra Project Do you have some examples of issues? So, to explain my thinking: I believe there is value in most contributors being able to know and understand a majority of what the project undertakes. Many people track a wide variety of activity on the project, and whether they express an opinion they probably form one and will involve themselves if they consider it important to do so. I worry that importing several distinct and only loosely related projects to the same governance and communication structures has a strong potential to undermine that capability, as people begin to assume that activity and decision-making is unrelated to them - and if that happens I think something important is lost. The sidecar challenges this already but seems hopefully manageable: it is a logical extension of Cassandra, existing primarily to plug gaps in Cassandra's own functionality, and features may migrate to Cassandra over time. It is likely to have releases closely tied to Cassandra itself. Other subprojects are so far exclusively for consumption by the Cassandra project itself, and are all naturally coupled. Drivers however are inherently arms-length endeavours: we publish a protocol specification, and driver maintainers implement it. They are otherwise fairly independent, and while a dialogue is helpful it does not need to be controlled by a single entity. Many drivers will continue to be controlled by others, as they have been until now. We're of course able to ensure there's a strong overlap of governance, which I think would be very helpful, and something Curator and Zookeeper seem not to have managed. Looking at the Curator website, it also seems to pitch itself as a relatively opinionated product, and much more than a driver. I hope the recipe for conflict in our case is much more limited given the functional scope of a driver - and anyway better avoided with more integrated, but still distinct governance. That's not to say I don't see some value in the project controlling the driver directly, I just worry about the above. ?On 22/04/2020, 21:25, ""Nate McCall"" wrote: ",executive
703,"Re: DataStax Driver Donation to Apache Cassandra Project It would probably be a good idea to get some outside guidance on what other projects have seen because like what Nate said, this isn't the first time. https://felix.apache.org/documentation/subprojects.html https://cocoon.apache.org/subprojects/ Commons has components: http://commons.apache.org/components.html Hadoop, as mentioned, has modules. Patrick ",not-ak
704,Re: DataStax Driver Donation to Apache Cassandra Project ,executive
705,"Re: DataStax Driver Donation to Apache Cassandra Project I welcome the donation, and hope we are able to accept all of the drivers. This is really great news IMO. I do however wonder if the project may be accumulating too many sub-projects? I wonder if it's time to think about splitting, and perhaps incubating a project for the drivers? ?On 22/04/2020, 18:20, ""Dinesh Joshi"" wrote: Hi Adam, Great to hear from you! I personally welcome the driver donation. My views are inline below. Thanks, Dinesh Java and Python at least. No opinions here. What are the major differences here? Could you please elaborate. I generally think people who have built the code base should become committers to avoid disruption and allow continuity. I am not completely sure but we may need to rename some packages but it would be really great if we could avoid breakages due to naming changes. ASF Jenkins/CircleCI works? Do the drivers have specific needs beyond this? sub-projects like cassandra-diff, sidecar, etc. This way drivers continue to evolve separately. --------------------------------------------------------------------- To unsubscribe, e-mail: dev-unsubscribe@cassandra.apache.org For additional commands, e-mail: dev-help@cassandra.apache.org --------------------------------------------------------------------- To unsubscribe, e-mail: dev-unsubscribe@cassandra.apache.org For additional commands, e-mail: dev-help@cassandra.apache.org",not-ak
706,"Re: DataStax Driver Donation to Apache Cassandra Project Hi Adam, Great to hear from you! I personally welcome the driver donation. My views are inline below. Thanks, Dinesh Java and Python at least. No opinions here. What are the major differences here? Could you please elaborate. I generally think people who have built the code base should become committers to avoid disruption and allow continuity. I am not completely sure but we may need to rename some packages but it would be really great if we could avoid breakages due to naming changes. ASF Jenkins/CircleCI works? Do the drivers have specific needs beyond this? sub-projects like cassandra-diff, sidecar, etc. This way drivers continue to evolve separately. --------------------------------------------------------------------- To unsubscribe, e-mail: dev-unsubscribe@cassandra.apache.org For additional commands, e-mail: dev-help@cassandra.apache.org",not-ak
707,"DataStax Driver Donation to Apache Cassandra Project The developers who maintain the DataStax drivers would like to start a conversation about donating these drivers to the Apache Cassandra project. Since we're actively working on the C* 4.0 support and integration in the drivers right now, we don't plan on executing on this until after C* 4.0 releases in order to avoid delaying the release. In the meantime we wanted to open the discussion so that we can all determine what we think best suits the project going forward. There are a number of details we would like to discuss as a project community. Naming a few to get the discussion going: - Is there interest from the project community to take ownership of the (currently) DataStax drivers? - Which drivers should be taken into project stewardship? -- The project currently bundles Java and Python; there are five others: C#, Node.js, C++, PHP and Ruby - Which major branch of the Java driver should be chosen for development? -- Server currently uses Java driver 3.x but the latest is 4.x - Who will be the committers that maintain these drivers? Should we nominate new committers (contributors on the current drivers code-bases) so they can keep maintaining them with minimal disruption to the project as a whole? - What should the new artifacts be named in package indices (coordinates and artifact names)? - How will we run CI for these contributions? - Do we do in-tree? Sub-projects? There will surely be even more to figure out as we go. We look forward to discussing this with everyone. Kind regards, The DS Drivers Team",executive
2024,"Re: Omega vs. YARN Tim, Answers inline below On 4/19/13 1:42 PM, ""Tim St Clair"" wrote: YARN-397 is kind of a roll up JIRA for some of the scheduler API enhancements. But there are also YARN-314, YARN-56, YARN-110, and YARN-238. But this does not include the ones that I am most interested in which is gang scheduling. I just haven't filed a JIRA for that yet. There is also preemption as an option in YARN-397, although not strictly part of the scheduling request API, but I believe includes informing the AM that resources are going to be taken back if it does not release some of them. Yes, those become more difficult in a distributed environment, but I don't think they are overwhelmingly difficult. These are hard problems to solve for any scheduler. This is because we are trying to come up with heuristics for a problem that is practically impossible to solve. I am not a mathematician but I believe that optimally scheduling resources is an NP-Hard problem. What is more we don't know what the resource utilization is going to be up front, despite the users' resource request/hint, so it is an NP-Hard problem once we have solved the halting problem. This is where priority and preemption come in as ways to try to offload some of the complexity on to the user, and then also to fix mistakes that the heuristic made while scheduling. Moving this to a distributed environment you can solve this in a number of way. The paper talks about optimistic scheduling vs pessimistic scheduling. With optimistic scheduling each scheduler acts kind of like it is the only one there is, and then cleans things up afterwards if there is a collision. In pessimistic scheduling it works hard to avoid all collisions most likely through locking. The paper also talked about auditing the schedulers after the fact to detect if any of them are doing something that does not fit with the policy instead of trying to enforce it. If we want to go with enforcement you could have specific schedulers with priority over other schedulers. So that by convention lower priority schedulers could not preempt higher priority ones, but then the resource utilization, in theory, would go down. On fragmentation I don't think any of the hadoop schedulers right now try to do anything about fragmentation, except pretend it does not exits. In fact we have seen a very rare live lock situation where the MR AM thinks there is enough headroom to schedule a map task so it does not bother to shoot a reducer, but because the headroom is fragmented between various machines the map task will never actually be scheduled. I agree that it may come fast. I just don't know if the mix of applications that Google has will actually come to Hadoop. I can see a lot of batch processing applications begin run on top of YARN, because even though YARN is generic it makes a lot of batch processing assumptions. Because of this I just don't know about other types of processing. It is a bit of a chicken/egg problem. I am in the process of doing a basic port of storm to run on top of YARN. Because the resource scheduling/isolation is not that great on YARN (Mesos too for that matter) we request entire nodes from YARN and bring up a predefined number of machines instead of letting the cluster grow and shrink on demand, because we need to be sure we can get the resources when we need them. Honestly it is a lot simpler to do what we are doing through OpenStack or some other VM management system than through YARN. Even looking at tools like Impala or Hbase, it would be very difficult with there current architecture to think about using YARN for scheduling/deployment. For example when security is enabled HDFS sets limits on how long a delegation token is good for. Once 2 weeks, configurable, are up your HDFS delegation token is done and no new containers will be abel to be launched because the distributed cache will no longer be able to download your jars. I just see a lot of difficulty in using YARN for long running processes, and it being a lot simpler to use something else like OpenStack for that. Now with that said, if we could some how have a distributed scheduler with both Hadoop and OpenStack sharing the same large cluster. That would be awesome. But again I have to convince my management that is the right way to go, it will save us X million dollars a year, and I have to convince myself that it is worth spending my time on that instead of the other fun stuff I have been doing. :)",executive
2025,"Re: Omega vs. YARN Robert, Thank you for your response. � I've placed some questions and comments inline below. Cheers, Tim ----- Original Message ----- If there are JIRA(s) which outline the limitations I would be interested in knowing more. I think the biggest open questions I have with a distributed approach, are; priority, preemption policies, and fragmentation. Something tells me it may come fast, if/when the YARN application space expands.",not-ak
2026,"Re: Omega vs. YARN Tim, They are very interesting points. From a scalability point I don't think we have really run into those situations yet but they are coming. YARN currently has some very ""simplistic"" scheduling for the RM. All of the complexity comes out in the AM. There have been a number of JIRA to make requests more complex, to help support more ""picky"" applications like the paper says. These would make YARN shift a bit more from a two-level scheduler towards a Monolithic one, and thereby reducing some of the scalability of the system, but making it support more complex scheduling patterns. The largest YARN cluster I know of right now is about 4000 nodes. On it we are hitting some bottlenecks with the current scheduler. We have looked at some ways to speed it up with more conventional approaches like allowing the scheduler to me multithreaded. We expect to be able to easily support 4000-6000 nodes through YARN with a few optimizations. Going to tens of thousands of nodes would require some more significant changes. As far as utilization is concerned the presented architecture does provide some very interesting points, but all of that can be addressed with a Monolithic scheduler so long as we don't have to scale very large. It also would probably require a complete redesign of YARN and the MR AM, which is not a small undertaking. There is also the question of trusted code. In a shared state system where all of the various schedulers are peers how would we enforce resource constraints? Each of the schedulers would have to enforce them themselves, and as such would have to be trusted code. This makes adding in new application types on the fly difficult. I suppose we could do a hybrid approach, where the RM is a single type of scheduler among many. It would provide the same API that currently exists for YARN applications, but MR applications could have one or more ""JobTracker"" like schedulers that share state with the RM, and what other ""schedulers"" there are out. That would be something fun to try out, but sadly I really don't have time to even get started thinking about a proof of concept on something like that. At least that is until we hit a significant business use case that would drive it over the architecture we already have. For example needing 10s of thousands of nodes in a cluster, or a huge shift in different types of jobs on to YARN so that we are doing a lot more than just MR on the same cluster. --Bobby On 4/19/13 9:47 AM, ""Tim St Clair"" wrote:",executive
2027,"Omega vs. YARN I recently read Googles Omega paper, and wondering if any of the YARN developers were planning to address some of the items considered as key points. � http://eurosys2013.tudos.org/wp-content/uploads/2013/paper/Schwarzkopf.pdf Cheers, Tim",not-ak
1807,"Re: a friendly suggestion for developers when uploading patches Did some research on changing the default order of attachments. It is not a configuration or INFRA issue. Turned out to be a controversial topic in the Jira itself, which was explicitly rejected by the developers. With many users unsatisfied. https://jira.atlassian.com/browse/JRA-28290 I thought it should be a simple thing to fix... Oh well. Revision numbers is the way to go then for now. Thanks, --Konst ",not-ak
1808,"Re: a friendly suggestion for developers when uploading patches I'm all for changing the default sort order, but it doesn't address the point that Steve and I brought up about local downloads. If you want to push on the INFRA JIRA though, please feel free. I'm +1 for that. Best, Andrew ",not-ak
1809,"Re: a friendly suggestion for developers when uploading patches Guys, I agree that revision numbers are useful if you need to reference a particular attachment. As well as with all your other arguments. My general point is that the infrastructure we use should be convenient for the users to do such simple things automatically. Rather than us introducing rules to overcome certain shortcomings of the tool. I think if the Attachments list was 1. ordered by date rather than by name, and 2. enumerated, like subtasks are then it would have solved the issue discussed here. I did communicate changing the default ordering for attachments with INFRA some time ago. Don't remember if I created a jira. Should we open one now? Thanks, --Konst ",executive
1810,"Re: a friendly suggestion for developers when uploading patches a couple more benefits 1. when you post a patch you can add a comment like ""patch 003 killed NPE in auth"", and the comment history then integrations with the revisions. You can also do this in your private git repository, so correlate commits there with patch versions. 2. they list in creation order in a directory. #2 matters for me as when I create patches I stick them in a dir specific to that JIRA; I can work out what the highest number is and increment it by one for creating a new one...yet retain the whole patch history locally. I also download external patches to review & apply to an incoming/ dir; numbering helps me manage that & to verify that I really am applying the relevant patch. Doesn't mean we should change the order though. I don't think that is something you can do on a per-project basis, so take it to infrastructure@ On 14 December 2014 at 01:33, Yongjun Zhang wrote: -- CONFIDENTIALITY NOTICE NOTICE: This message is intended for the use of the individual or entity to which it is addressed and may contain information that is confidential, privileged and exempt from disclosure under applicable law. If the reader of this message is not the intended recipient, you are hereby notified that any printing, copying, dissemination, distribution, disclosure or forwarding of this communication is strictly prohibited. If you have received this communication in error, please contact the sender immediately and delete it from your system. Thank You.",executive
1811,"Re: a friendly suggestion for developers when uploading patches Hi Konst, Thanks for the good suggestion, certainly that would help. Here are the advantages to include revision number in the patch name: - we would have the same ordering by name or by date - it would be easier to refer to individual patch, say, when we need to refer to multiple patches when making a comment (e.g,, ""comparing revX with revY, here are the pros and cons ...""). - when we create a new rev patch file before submitting, if we use the same name as previous one, it would overwrite the previous one - when we download patch files to the same directory, depending on the order of downloading, the patches would possibly not appear in the order that they were submitted. Best regards, --Yongjun ",executive
2361,"Re: secondary index support in Cassandra The compaction optimization that Prashant mentioned is likely to solve many of the problems that Jun brings up. We were thinking of tackling this problem ... I've opened a ticket in JIRA (https://issues.apache.org/jira/browse/CASSANDRA-16) Avinash, Prashant -- If you guys are already working on it, feel free to assign it to yourself. Otherwise we'll sketch out a plan and send it out, if the community agrees on the idea, we can start hacking away. Sandeep ",not-ak
2362,Re: secondary index support in Cassandra That would depend on the app. What you are describing is serializability? Which was never one of the design goals. Locking business will not help over here. You could write to a replica and read from another to which the write has not yet propagated and you will see the same issues. Locking will help in a single machine but when you go across machines. Client app should be able to handle this and this was the motivation. No strict guarantees Avinash ,not-ak
2363,"Re: secondary index support in Cassandra Some comments inlined below. Jun IBM Almaden Research Center K55/B1, 650 Harry Road, San Jose, CA 95120-6099 junrao@almaden.ibm.com Avinash Lakshman wrote on 03/24/2009 10:08:45 PM: some changes the maintaining However, Then, but be means at This problem doesn't show up in Cassandra today because there is no method that can read columns from different CFs in a row. If there were such a method, it would be hard to enforce that a reader always sees a complete update (updating multiple CFs) without some sort of row locks. not However, scaling A large group may not fit in memory, but should fit in a commodity disk. The compaction optimization Prashant mentioned will definitely make our current approach more feasible. However, in general, I am a bit concerned about putting too much stuff within a row. A row is a unit that has finite capacity and a user shouldn't expect to put an infinite number of columns within a row. I actually like the current assumption in Cassandra that a row has to fit in memory since it simplifies the implementation. On the other hand, a table can have arbitrary capacity (one just need to provision enough nodes in the cluster) and it can have as many rows as you want. many with we its (CF). column function The starting Cassandra able could locking compaction. same and I CF files is in columns in why do uses a entity same In and stored automatically the index in hear if are but to",existence
2364,Re: secondary index support in Cassandra Comments inline. ,existence
2365,Re: secondary index support in Cassandra Prashant had many other points out there whereby you don't need your second approach. I guess that is what I was referring to. Avinash ,not-ak
2366,"Re: secondary index support in Cassandra Prashant, I forgot about another point you mentioned. In the new approach, carving out a chunk of data by hash (needed for node removal/addition) may not be efficient. In the worse case, we have to make a full scan of the data. It is possible to make it more efficient by following the strategy that you guys implemented when using the random hash function: prefixing each index key with the hash value. On the other hand, I am wondering if we really need to worry about the performance on adding/removing nodes. These are infrequent events and are also non-blocking. Jun IBM Almaden Research Center K55/B1, 650 Harry Road, San Jose, CA 95120-6099 junrao@almaden.ibm.com Prashant Malik <pmalik@gmail.com> Prashant Malik <pmalik@gmail.com> 03/24/2009 11:34 AM Please respond to cassandra-dev@incubator.apache.org To cassandra-dev@incubator.apache.org cc Subject Re: secondary index support in Cassandra Some questions Iline ",not-ak
2367,Re: secondary index support in Cassandra I think Prashant brought up some very good points. The response would be very helpful to understand the best way to do this. Avinash ,not-ak
2368,"Re: secondary index support in Cassandra Prashant, Thanks for the comments. They are quite useful. Let me try to address some of the points that you made. 1. It is true that in our current implementation, we can glue the changes on both the data and the index in one batch_update() call. This way, the data and the index will be maintained synchronously. However, maintaining the index on the server is likely more efficient since there is less communication overhead. You seem to agree with this. 2. Cassandra currently doesn't acquire row-lock for row accesses. However, the implication is that a reader may see partial updates of a row. For example, suppose that a writer updates two columns in different CFs. Then, it is possible for a concurrent reader to see the update on one column, but not the other one. For some applications, row-level consistency could be important. It's probably for this reason, in HBase, a region server acquires a row lock for every read and write. 3. For our current application, the size of all entities in a group is not too large and likely fits within the capacity of a single node. However, for other applications, being able to scale a group to more than a node could be useful. Storing a group within a single row will prevent scaling out the group. Jun IBM Almaden Research Center K55/B1, 650 Harry Road, San Jose, CA 95120-6099 junrao@almaden.ibm.com Prashant Malik wrote on 03/24/2009 11:34:51 AM: common want group to implement a name so column if to leave entity to for Today, Also, data easier one where to a the in (rowkey):attribute1:attribute2:rowkey) entities example, the better removal me.",existence
2369,Re: secondary index support in Cassandra ,not-ak
2370,Re: secondary index support in Cassandra ,not-ak
2371,"Re: secondary index support in Cassandra Jonathan, Thanks for the comments. I agree with your first point. It will be useful to plug in a user-defined index analyzer. The analyzer takes a row with the indexed columns and can extract whatever index keys that it likes. This way, an application can choose what to index for different data types. As for queries vs. low-level api, we can make both available to the application developer. In general, what can be done in a single query may have to be translated to multiple low-level api calls. Some apps may prefer the former for efficiency. Jun IBM Almaden Research Center K55/B1, 650 Harry Road, San Jose, CA 95120-6099 junrao@almaden.ibm.com Jonathan Ellis <jbellis@gmail.com> Jonathan Ellis <jbellis@gmail.com> 03/24/2009 10:48 AM Please respond to cassandra-dev@incubator.apache.org To cassandra-dev@incubator.apache.org cc Subject Re: secondary index support in Cassandra This adds a lot of complexity but I definitely see people wanting easy indexing out of the box. So +1 in principle. A few high-level comments: First, for maximum flexibility, you probably want to allow indexes to be defined in code. That is, you'd define something like <ColumnFamily name=""foo""> <Index generator=""com.ibm.cassandra.indexGenerator""/> </ColumnFamily> and allow index generators to be loaded at runtime. Nobody else is going to need the specific case of hash(rowkey):attribute1:attribute2:rowkey so abstract that out and make it pluggable for whatever weird-ass requirements people have. Second, I'm not a fan of queries by parsing strings. The whole rdbms world has been moving _away_ from SQL and towards OO interfaces for the last 10 years. I like the thrift API for this reason. (It is a little clunky in Java, but _everything_ is a little clunky in Java. Much better in Python/Ruby/etc.) Finally, as an implementation detail, Cassandra already does too much in-memory when writing and merging sstables. Don't make it worse. :) -Jonathan P.S. the partitioner abstraction layer in CASSANDRA-3 will allow you to do the per-node grouping you want without weird contortions. ",existence
2372,Re: secondary index support in Cassandra Some questions Iline ,existence
2373,"Re: secondary index support in Cassandra This adds a lot of complexity but I definitely see people wanting easy indexing out of the box. So +1 in principle. A few high-level comments: First, for maximum flexibility, you probably want to allow indexes to be defined in code. That is, you'd define something like and allow index generators to be loaded at runtime. Nobody else is going to need the specific case of hash(rowkey):attribute1:attribute2:rowkey so abstract that out and make it pluggable for whatever weird-ass requirements people have. Second, I'm not a fan of queries by parsing strings. The whole rdbms world has been moving _away_ from SQL and towards OO interfaces for the last 10 years. I like the thrift API for this reason. (It is a little clunky in Java, but _everything_ is a little clunky in Java. Much better in Python/Ruby/etc.) Finally, as an implementation detail, Cassandra already does too much in-memory when writing and merging sstables. Don't make it worse. :) -Jonathan P.S. the partitioner abstraction layer in CASSANDRA-3 will allow you to do the per-node grouping you want without weird contortions. ",executive
2374,"secondary index support in Cassandra We have an application that has groups and entities. A group has many entities and an entity has a bunch of (attribute, value) pairs. A common access pattern is to select some number of entities within a group with attribute X equals to x and ordered by attribute Y. For efficiency, we want to build a secondary index for each group and collocate a group and its secondary index on the same node. Our current approach is to map a group to a row in Cassandra and each entity to a column in a column family (CF). Within the same row, we use a separate CF (ordered by name) to implement a secondary index, say on attribute X and Y. In this family, each column name has the form of X:x:Y:y:entityID. We extended the get_slice() function so that it can get a slice of columns starting from a given column. The extended function uses the column-level index to locate the starting column quickly. (We'd be happy to contribute this extension back to Cassandra if people find this useful). Using the extended get_slice(), we were able to access the entities through the simulated secondary index. We see a couple of problems with the current approach. First, our application has to maintain the index. This is inefficient and could leave the index inconsistent when failure occurs. Second, mapping each entity to a column may not be a good idea. Often, there is some sort of locking for each row access. Putting many entities per row limits concurrency. Today, in Cassandra, a full row is deserialized into memory during compaction. This limits the number of entities that can be put in a single row. Also, intuitively, an entity is more naturally represented as a row with attributes stored as columns. To address the above problems, we are thinking of the following new implementation. Each entity is mapped to a row in Cassandra and uses a two-part key (groupID, entityID). We use the groupID to hash an entity to a node. This way, all entities for a group will be collocated in the same node. We then define a special CF to serve as the secondary index. In the definition, we specify what entity attributes need to be indexed and in what order. Within a node, this special CF will index all rows stored locally. Every time we insert a new entity, the server automatically extracts the index key based on the index definition (for example, the index key can be of the form ""hash(rowkey):attribute1:attribute2:rowkey) and add the index entry to the special CF. We can then access the entities using an extended version of the query language in Cassandra. For example, if we issue the following query and there is an index defined by (attributeX, attributeY), the query can be evaluated using the index in the special CF. (Note that AppEngine supports this flavor of queries.) select attributeZ from ROWS(HASH = hash(groupID)) where attributeX=""x"" order by attributeY desc limit 50 We are in the middle of prototyping this approach. We'd like to hear if other people are interested in this too or if people think there are better alternatives. Jun IBM Almaden Research Center K55/B1, 650 Harry Road, San Jose, CA 95120-6099 junrao@almaden.ibm.com",existence
1003,Re: Cassandra Needs to Grow Up by Version Five! ,not-ak
1005,"Re: Cassandra Needs to Grow Up by Version Five! Cassandra, hard to use? I disagree completely. With that said, there are definitely deficiencies in certain parts of the documentation, but nothing that is a show stopper. We�ve been using Cassandra since the sub 1.0 days and have had nothing but great things to say about it. With that said, its an open source project; you get from it what you�re willing to put in. If you just expect something that installs, asks a couple of questions and you�re off to the races, Cassandra might not be for you. If you�re willing to put in the time to understand how Cassandra works, and how it fits into your use case, and if it is the right fit for your use case, you�ll be more than happy, I bet. If there are things that are lacking, that you can�t find a work around for, submit a PR! That�s the beauty of open source projects. ",not-ak
1006,"Re: Cassandra Needs to Grow Up by Version Five! Cassandra, hard to use? I disagree completely. With that said, there are definitely deficiencies in certain parts of the documentation, but nothing that is a show stopper. We�ve been using Cassandra since the sub 1.0 days and have had nothing but great things to say about it. With that said, its an open source project; you get from it what you�re willing to put in. If you just expect something that installs, asks a couple of questions and you�re off to the races, Cassandra might not be for you. If you�re willing to put in the time to understand how Cassandra works, and how it fits into your use case, and if it is the right fit for your use case, you�ll be more than happy, I bet. If there are things that are lacking, that you can�t find a work around for, submit a PR! That�s the beauty of open source projects. Regards, Eric ",not-ak
1007,"Re: Cassandra Needs to Grow Up by Version Five! On Wed, Feb 21, 2018 at 7:54 PM, Durity, Sean R <SEAN_R_DURITY@homedepot.com Oh, don't get me started on documentation, especially the DataStax one. I come from Postgres. In comparison, Cassandra documentation is mostly non-existent (and this is just a way to avoid listing other uncomfortable epithets). Not sure if I would be able to submit patches to improve that, however, since most of the time it would require me to already know the answer to my questions when the doc is incomplete. The move from DataStax to Apache.org for docs is actually good, IMO, since the docs were maintained very poorly and there was no real leverage to influence that. Cheers, -- Alex",not-ak
1008,"Re: Cassandra Needs to Grow Up by Version Five! Please do send them! There was a *lot* of really hard great work by a lot of people over the past year to significantly improve the documentation in tree. http://cassandra.apache.org/doc/latest/ https://github.com/apache/cassandra/tree/trunk/doc I still didn't see a reply from you re: my request for your jira information so i'm unable to follow what issues you're referring to as you haven't linked to any in your emails either. If you still see holes in the new and improved documentation above, _please_ do create tickets to track that so we can improve that asap! a fresh set of eyes on areas not covered is obviously welcomed; especially those with overlap with the links you're referring to in your email obviously. best, kjellman On Feb 21, 2018, at 4:13 PM, Kenneth Brotman > wrote: Jeff, I already addressed everything you said. Boy! Would I like to bring up the out of date articles on the web that trip people up and the lousy documentation on the Apache website but I can�t because a lot of folks don�t know me or why I�m saying these things. I will be making another post that I hope clarifies what�s going on with me. After that I will either be a freakishly valuable asset to this community or I will be a freakishly valuable asset to another community. You sure have a funny way of reigning in people that are used to helping out. You sure misjudged me. Wow. Kenneth Brotman From: Jeff Jirsa [mailto:jjirsa@gmail.com] Sent: Wednesday, February 21, 2018 3:12 PM To: cassandra Cc: Cassandra DEV Subject: Re: Cassandra Needs to Grow Up by Version Five! ",not-ak
1010,"Re: Cassandra Needs to Grow Up by Version Five! Instead of saying ""Make X better"" you can quantify ""Here's how we can make X better"" in a jira and the conversation will continue with interested parties (opening jiras are free!). Being combative and insulting project on mailing list may help vent some frustrations but it is counter productive and makes people defensive. People are not averse to usability, quite the opposite actually. People do tend to be averse to conversations opened up with ""cassandra is an idiot"" with no clear definition of how to make it better or what a better solution would look like though. Note however that saying ""make backups better"" or ""look at marketing literature for these guys"" is hard for an engineer or architect to break into actionable item. Coming up with cool ideas on how to do something will more likely hook a developer into working on it then trying to shame the community with a sales pitch from another DB's sales guy. Chris --------------------------------------------------------------------- To unsubscribe, e-mail: dev-unsubscribe@cassandra.apache.org For additional commands, e-mail: dev-help@cassandra.apache.org",not-ak
1011,"Re: Cassandra Needs to Grow Up by Version Five! Hi all, I'd like to deescalate a bit here. Since this is an Apache and an OSS project, contributions come in many forms: code, speaking/advocacy, documentation, support, project management, and so on. None of these things come for free. Ken, I appreciate you bring up these usability topics; they are certainly valid concerns. You've mentioned you are working on posting of some sort that I think will amount to an enumerated list of the topics/issues you feel need addressing. Some may be simple changes, some may be more invasive, some we can consider implementing, some not. I look forward to a positive discussion. I think what would be best would be for you to complete that list and work with the community, in a *positive and constructive manner*, towards getting it done. That is certainly contributing, and contributing in a big way: project management. Working with the community is going to be the most beneficial path for everyone. Ken, if you feel like you'd like some help getting such an initiative going, and contributing substantively to it (not necessarily in terms of code) please feel free to reach out to me directly (jasedbrown@gmail.com). Hoping this leads somewhere positive, that benefits everyone, -Jason ",not-ak
1012,Re: Cassandra Needs to Grow Up by Version Five! ,not-ak
1013,Re: Cassandra Needs to Grow Up by Version Five! The only progress from this point is what Jon said: enumerate and detail your issues in jira tickets. ,not-ak
1015,"Re: Cassandra Needs to Grow Up by Version Five! I would second Jon in the arguments he made. Contributing outside work is draining and really requires a lot of commitment. If someone requires features around usability etc, just pay for it, period. ",not-ak
1016,"Re: Cassandra Needs to Grow Up by Version Five! kenneth: could you please send your jira information? i'm unable to even find an account on http://issues.apache.org with your name despite multiple attempts. thanks! best, kjellman",not-ak
1018,"Re: Cassandra Needs to Grow Up by Version Five! Ken, Maybe it�s not clear how open source projects work, so let me try to explain. There�s a bunch of us who either get paid by someone or volunteer on our free time. The folks that get paid, (yay!) usually take direction on what the priorities are, and work on projects that directly affect our jobs. That means that someone needs to care enough about the features you want to work on them, if you�re not going to do it yourself. Now as others have said already, please put your list of demands in JIRA, if someone is interested, they will work on it. You may need to contribute a little more than you�ve done already, be prepared to get involved if you actually want to to see something get done. Perhaps learning a little more about Cassandra�s internals and the people involved will reveal some of the design decisions and priorities of the project. Third, you seem to be a little obsessed with market share. While market share is fun to talk about, *most* of us that are working on and contributing to Cassandra do so because it does actually solve a problem we have, and solves it reasonably well. If some magic open source DB appears out of no where and does everything you want Cassandra to, and is bug free, keeps your data consistent, automatically does backups, comes with really nice cert management, ad hoc querying, amazing materialized views that are perfect, no caveats to secondary indexes, and somehow still gives you linear scalability without any mental overhead whatsoever then sure, people might start using it. And that�s actually OK, because if that happens we�ll all be incredibly pumped out of our minds because we won�t have to work as hard. If on the slim chance that doesn�t manifest, those of us that use Cassandra and are part of the community will keep working on the things we care about, iterating, and improving things. Maybe someone will even take a look at your JIRA issues. Further filling the mailing list with your grievances will likely not help you progress towards your goal of a Cassandra that�s easier to use, so I encourage you to try to be a little more productive and try to help rather than just complain, which is not constructive. I did a quick search for your name on the mailing list, and I�ve seen very little from you, so to everyone�s who�s been around for a while and trying to help you it looks like you�re just some random dude asking for people to work for free on the things you�re asking for, without offering anything back in return. Jon --------------------------------------------------------------------- To unsubscribe, e-mail: dev-unsubscribe@cassandra.apache.org For additional commands, e-mail: dev-help@cassandra.apache.org",not-ak
1019,"Re: Cassandra Needs to Grow Up by Version Five! So before buying any marketing claims from Microsoft or whoever, maybe should you try to use it extensively ? And talking about backup, have a look at DynamoDB: http://i68.tinypic.com/n1b6yr.jpg or can't make it easy for end-user (without involving an unwieldy Hadoop machinery: https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DynamoDBPipeline.html), what Cassandra offers in term of back-up restore is more than satisfactory ",executive
1021,"Re: Cassandra Needs to Grow Up by Version Five! It is instructive to listen to the concerns of new and existing users in order to improve a product like Cassandra, but I think the school yard taunt model isn�t the most effective. In my experience with open and closed source databases, there are always things that could be improved. Many have a historical base in how the product evolved over time. A newcomer sees those as rough edges right away. In other cases, the database creators have often widened their scope to try and solve every data problem. This creates the complexity of too many configuration options, etc. Even the best RDBMS (Informix!) battled these kinds of issues. Cassandra, though, introduced another angle of difficulty. In trying to relate to RDBMS users (pun intended), it often borrowed terminology to make it seem familiar. But they don�t work the same way or even solve the same problems. The classic example is secondary indexes. For RDBMS, they are very useful; for Cassandra, they are anathema (except for very narrow cases). However, I think the shots at Cassandra are generally unfair. When I started working with it, the DataStax documentation was some of the best documentation I had seen on any project, especially an open source one. (If anything the cooling off between Apache Cassandra and DataStax may be the most serious misstep so far�) The more I learned about how Cassandra worked, the more I marveled at the clever combination of intricate solutions (gossip, merkle trees, compaction strategies, etc.) to solve specific data problems. This is a great product! It has given me lots of sleep-filled nights over the last 4+ years. My customers love it, once I explain what it should be used for (and what it shouldn�t). I applaud the contributors, whether coders or users. Thank you! Finally, a note on backup. Backing up a distributed system is tough, but restores are even more complex (if you want no down-time, no extra disk space, point-in-time recovery, etc). If you want to investigate why it is a tough problem for Cassandra, go look at RecoverX from Datos IO. They have solved many of the problems, but it isn�t an easy task. You could ask people to try and recreate all that, or just point them to a working solution. If backup and recovery is required (and I would argue it isn�t always required), it is probably worth paying for. Sean Durity From: Josh McKenzie [mailto:jmckenzie@apache.org] Sent: Wednesday, February 21, 2018 11:28 AM To: dev@cassandra.apache.org Cc: User Subject: [EXTERNAL] Re: Cassandra Needs to Grow Up by Version Five! There's a disheartening amount of ""here's where Cassandra is bad, and here's what it needs to do for me for free"" happening in this thread. This is open-source software. Everyone is *strongly encouraged* to submit a patch to move the needle on *any* of these things being complained about in this thread. For the Apache Way to work, people need to step up and meaningfully contribute to a project to scratch their own itch instead of just waiting for a random corporation-subsidized engineer to happen to have interests that align with them and contribute that to the project. Beating a dead horse for things everyone on the project knows are serious pain points is not productive. ",not-ak
1022,"Re: Cassandra Needs to Grow Up by Version Five! There's a disheartening amount of ""here's where Cassandra is bad, and here's what it needs to do for me for free"" happening in this thread. This is open-source software. Everyone is *strongly encouraged* to submit a patch to move the needle on *any* of these things being complained about in this thread. For the Apache Way to work, people need to step up and meaningfully contribute to a project to scratch their own itch instead of just waiting for a random corporation-subsidized engineer to happen to have interests that align with them and contribute that to the project. Beating a dead horse for things everyone on the project knows are serious pain points is not productive. ",not-ak
1023,Re: Cassandra Needs to Grow Up by Version Five! ,not-ak
1025,Re: Cassandra Needs to Grow Up by Version Five! html,not-ak
1026,"Re: Cassandra Needs to Grow Up by Version Five! the things you are asking for are unfortunately not tiny effort. as you don�t seem to have the time to contribute code the best way you personally create change would be (again) to file individual jiras for each enhancement or feature request. highlight key ones you filed via the mailing list that you�d personally like to see prioritized - and advocate to have resources allocated towards implementing and ultimately get those scheduled for a release over other ones. best, kjellman --------------------------------------------------------------------- To unsubscribe, e-mail: dev-unsubscribe@cassandra.apache.org For additional commands, e-mail: dev-help@cassandra.apache.org",executive
1029,"Re: Cassandra Needs to Grow Up by Version Five! Comments inline There�s probably 2-3 reasons why here: 1) Historically the pmc has tried to keep the scope of the project very narrow. It�s a database. We don�t ship drivers. We don�t ship developer tools. We don�t ship fancy UIs. We ship a database. I think for the most part the narrow vision has been for the best, but maybe it�s time to reconsider some of the scope. Postgres will autovacuum to prevent wraparound (hopefully), but everyone I know running Postgres uses flexible-freeze in cron - sometimes it�s ok to let the database have its opinions and let third party tools fill in the gaps. 2) Cassandra is, by definition, a database for large scale problems. Most of the companies working on/with it tend to be big companies. Big companies often have pre-existing automation that solved the stuff you consider fundamental tasks, so there�s probably nobody actively working on the solved problems that you may consider missing features - for many people they�re already solved. 3) It�s not nearly as basic as you think it is. Datastax seemingly had a multi-person team on opscenter, and while it was better than anything else around last time I used it (before it stopped supporting the OSS version), it left a lot to be desired. It�s probably 2-3 engineers working for a month to have any sort of meaningful, reliable, mostly trivial cluster-managing UI, and I can think of about 10 JIRAs I�d rather see that time be spent on first. And for everything you think is obvious, there�s a 50% chance someone else will have already solved differently, and your obvious new solution will be seen as an inconvenient assumption and complexity they won�t appreciate. Open source projects get to walk a fine line of trying to be useful without making too many assumptions, being �too� opinionated, or overstepping bounds. We may be too conservative, but it�s very easy to go too far in the opposite direction. And that�s why nobody�s done it - we all have bigger problems we�re being paid to solve, and nobody�s felt it necessary. Because it�s not necessary, it�s nice, but not required. I don�t see this ever happening. Your config management already pushes files around your infrastructure, Cassandra doesn�t need to do it. The only time you should be doing this is when you�re wiping nodes from failed bootstrap, and that stopped being required in 2.2. There�s a good argument to be made that something like Reaper should be shipped with Cassandra. There�s another good argument that most tools like this end up needing some sort of leader election for scheduling and that goes against a lot of the fundamental assumptions in Cassandra (all nodes are equal, etc) - solving that problem is probably at least part of why you haven�t seen them built into the db. �Leader election is easy� you�ll say, and I�ll laugh and tell you about users I know who have DCs go offline for weeks at a time. Stefan (in particular) has done a fair amount of work on this, but I�d bet 90% of users don�t use ssl and genuinely don�t care. Na. Stability and testing should be a big theme in the next major release. Let�s keep some perspective. Most of us came to Cassandra from rdbms worlds where we were building solutions out of a bunch of master/slave MySQL / Postgres type databases. I started using Cassandra 0.6 when I needed to store something like 400gb/day in 200whatever on spinning disks when 100gb felt like a �big� database, and the thought of writing runbooks and automation to automatically pick the most up to date slave as the new master, promote it, repoint the other slave to the new master, then reformat the old master and add it as a new slave without downtime and without potentially deleting the company�s whole dataset sounded awful. Cassandra solved that problem, at the cost of maintaining a few yaml (then xml) files. Yes there are rough edges - they get slightly less rough on each new release. Can we do better? Sure, use your engineering time and send some patches. But the basic stuff is the nuts and bolts of the database: I care way more about streaming and compaction than I�ll ever care about installation. The committers are working their ass off on all sorts of hard problems. Some of those are probably even related to Cassandra. If you have idea, open a JIRA. If you have time, send a patch. Or review a patch. But don�t expect a bunch of people to set down work on optimizing the database to work on packaging and installation, because there�s no ROI in it for 99% of the existing committers: we�re working on the database to solve problems, and installation isn�t one of those problems.",not-ak
1030,"Re: Cassandra Needs to Grow Up by Version Five! hi ken, sorry you don�t like the database. some thoughts: 1) please file actionable jiras for places you feel need to be improved in the database... this is the best way to make and encourage the change you�re looking for. it seems you have quite a few ideas from your post that could be broken down into individual actionable jiras. 2) please don�t cross post between mailing lists. 3) pull requests are always welcomed! best, kjellman --------------------------------------------------------------------- To unsubscribe, e-mail: dev-unsubscribe@cassandra.apache.org For additional commands, e-mail: dev-help@cassandra.apache.org",not-ak
1031,"Cassandra Needs to Grow Up by Version Five! Cassandra feels like an unfinished program to me. The problem is not that it's open source or cutting edge. It's an open source cutting edge program that lacks some of its basic functionality. We are all stuck addressing fundamental mechanical tasks for Cassandra because the basic code that would do that part has not been contributed yet. Ease of use issues need to be given much more attention. For an administrator, the ease of use of Cassandra is very poor. Furthermore, currently Cassandra is an idiot. We have to do everything for Cassandra. Contrast that with the fact that we are in the dawn of artificial intelligence. Software exists to automate tasks for humans, not mechanize humans to administer tasks for a database. I'm an engineering type. My job is to apply science and technology to solve real world problems. And that's where I need an organization's I.T. talent to focus; not in crank starting an unfinished database. For example, I should be able to go to any node, replace the Cassandra.yaml file and have a prompt on the display ask me if I want to update all the yaml files across the cluster. I shouldn't have to manually modify yaml files on each node or have to create a script for some third party automation tool to do it. I should not have to turn off service, clear directories, restart service in coordination with the other nodes. It's already a computer system. It can do those things on its own. How about read repair. First there is something wrong with the name. Maybe it should be called Consistency Repair. An administrator shouldn't have to do anything. It should be a behavior of Cassandra that is programmed in. It should consider the GC setting of each node, calculate how often it has to run repair, when it should run it so all the nodes aren't trying at the same time and when other circumstances indicate it should also run it. Certificate management should be automated. Cluster wide management should be a big theme in any next major release. What is a major release? How many major releases could a program have before all the coding for basic stuff like installation, configuration and maintenance is included! Finish the basic coding of Cassandra, make it easy to use for administrators, make is smart, add cluster wide management. Keep Cassandra competitive or it will soon be the old Model T we all remember fondly. I ask the Committee to compile a list of all such items, make a plan, and commit to including the completed and tested code as part of major release 5.0. I further ask that release 4.0 not be delayed and then there be an unusually short skip to version 5.0. Kenneth Brotman",not-ak
1803,"[GitHub] cassandra pull request: opinion on refactoring ListenableFuture to... Github user yulin2 closed the pull request at: https://github.com/apache/cassandra/pull/50 --- If your project is set up for it, you can reply to this email and have your reply appear on GitHub as well. If your project does not have this feature enabled and wishes so, or if the feature is enabled but not working, please contact infrastructure at infrastructure@apache.org or file a JIRA ticket with INFRA. ---",not-ak
1804,"[GitHub] cassandra pull request: opinion on refactoring ListenableFuture to... Github user MarkReddy commented on the pull request: https://github.com/apache/cassandra/pull/50#issuecomment-68760981 @yulin2 Pull requests are not used for Apache Cassandra. Please open a JIRA (https://issues.apache.org/jira/browse/CASSANDRA) if you have an improvement, idea or issue to share and close this request. --- If your project is set up for it, you can reply to this email and have your reply appear on GitHub as well. If your project does not have this feature enabled and wishes so, or if the feature is enabled but not working, please contact infrastructure at infrastructure@apache.org or file a JIRA ticket with INFRA. ---",executive
1805,"[GitHub] cassandra pull request: opinion on refactoring ListenableFuture to... GitHub user yulin2 opened a pull request: https://github.com/apache/cassandra/pull/50 opinion on refactoring ListenableFuture to Java 8 CompletableFuture I'm doing research on new concurrent constructs in Java 8. I found `CompletableFuture` in Java 8 has the same functionality as Guava `ListenableFuture`. But `CompletableFuture` is much nicer because it comes together with Lambda expression in Java 8, and it is monadic, which makes the code more readable and cleaner. Also, it provides more ways to compose different tasks. Therefore, using `CompletableFuture` instead of `ListenableFuture` is better for future extension and maintenance of the code. I tried to refactoring one Guava `ListenableFuture` to Java 8 `CompletableFuture` in Cassandra, so you can see the difference in the code. You don't have to merge this pull request. I'm just wondering your opinion on this kind of refactoring (or migrating the code from Java 7 to Java 8). Do you think the refactoring is useful? Do you have any plan to use Java 8? You can merge this pull request into a Git repository by running: $ git pull https://github.com/yulin2/cassandra trunk Alternatively you can review and apply these changes as the patch at: https://github.com/apache/cassandra/pull/50.patch To close this pull request, make a commit to your master/trunk branch with (at least) the following in the commit message: This closes #50 ---- commit 6b68f5479fc642d8342702f195bf05f6ca044d40 Author: Yu Lin Date: 2014-12-31T19:44:03Z refactor one ListenableFuture to Java 8 CompletableFuture ---- --- If your project is set up for it, you can reply to this email and have your reply appear on GitHub as well. If your project does not have this feature enabled and wishes so, or if the feature is enabled but not working, please contact infrastructure at infrastructure@apache.org or file a JIRA ticket with INFRA. ---",existence
1372,"Issue in handling checksum errors in write pipeline Hello We had come across one issue, where write is failed even 7 DN's are available due to network fault at one datanode which is LAST_IN_PIPELINE. It will be similar to HDFS-6937 . Scenario : (DN3 has N/W Fault and Min repl=2). Write pipeline: DN1->DN2->DN3 => DN3 Gives ERROR_CHECKSUM ack. And so DN2 marked as bad DN1->DN4-> DN3 => DN3 Gives ERROR_CHECKSUM ack. And so DN4 is marked as bad .... And so on ( all the times DN3 is LAST_IN_PIPELINE) ... Continued till no more datanodes to construct the pipeline. Thinking we can handle like below: Instead of throwing IOException for ERROR_CHECKSUM ack from downstream, If we can send back the pipeline ack and client side we can replace both DN2 and DN3 with new nodes as we can't decide on which is having network problem. Please give you views the possible fix.. --Brahma Reddy Battula",not-ak
781,"Re: Agenda & More Information about Hadoop Community Meetup @ Palo Alto, June 26 Thanks Wangda. Will this event be recorded? It will be extremely helpful for people who are unable to join to catch up. Thanks Weiwei On Jun 26, 2019, 4:12 AM +0800, Wangda Tan , wrote: A friendly reminder, The meetup will take place tomorrow at 9:00 AM PDT to 4:00 PM PDT. The address is: 395 Page Mill Rd, Palo Alto, CA 94306 We�ll be in the Bigtop conference room on the 1st floor. Go left after coming through the main entrance, and it will be on the right. Zoom: https://cloudera.zoom.us/j/606607666 Please let me know if you have any questions. If you haven't RSVP yet, please go ahead and RSVP so we can better prepare food, seat, etc. Thanks, Wangda ",not-ak
782,"Re: Agenda & More Information about Hadoop Community Meetup @ Palo Alto, June 26 A friendly reminder, The meetup will take place tomorrow at 9:00 AM PDT to 4:00 PM PDT. The address is: 395 Page Mill Rd, Palo Alto, CA 94306 We�ll be in the Bigtop conference room on the 1st floor. Go left after coming through the main entrance, and it will be on the right. Zoom: https://cloudera.zoom.us/j/606607666 Please let me know if you have any questions. If you haven't RSVP yet, please go ahead and RSVP so we can better prepare food, seat, etc. Thanks, Wangda ",not-ak
783,"Re: Agenda & More Information about Hadoop Community Meetup @ Palo Alto, June 26 It�s great?I'm really looking forward to this Meetup --------------------------------------------------------------------- To unsubscribe, e-mail: common-dev-unsubscribe@hadoop.apache.org For additional commands, e-mail: common-dev-help@hadoop.apache.org",not-ak
784,"Agenda & More Information about Hadoop Community Meetup @ Palo Alto, June 26 Hi All, I want to let you know that we have confirmed most of the agenda for Hadoop Community Meetup. It will be a whole day event. Agenda & Dial-In info because see below, *please RSVP at https://www.meetup.com/Hadoop-Contributors/events/262055924/ * Huge thanks to Daniel Templeton, Wei-Chiu Chuang, Christina Vu for helping with organizing and logistics. *Please help to promote meetup information on Twitter, LinkedIn, etc. Appreciated! * Best, Wangda *AM:9:00: Arrival and check-in--------------------------9:30 - 10:15:-------------Talk: Hadoop storage in cloud-native environmentsAbstract: Hadoop is a mature storage system but designed years before the cloud-native movement. Kubernetes and other cloud-native tools are emerging solutions for containerized environments but sometimes they require different approaches.In this presentation we would like to share our experiences to run Apache Hadoop Ozone in Kubernetes and the connection point to other cloud-native ecosystem elements. We will compare the benefits and drawbacks to use Kubernetes and Hadoop storage together and show our current achievements and future plans.Speaker: Marton Elek (Cloudera)10:20 - 11:00:--------------Talk: Selective Wire Encryption In HDFSAbstract: Wire data encryption is a key component of the Hadoop Distributed File System (HDFS). However, such encryption enforcement comes in as an all-or-nothing feature. In our use case at LinkedIn, we would like to selectively expose fast unencrypted access to fully managed internal clients, which can be trusted, while only expose encrypted access to clients outside of the trusted circle with higher security risks. That way we minimize performance overhead for trusted internal clients while still securing data from potential outside threats. Our design extends HDFS NameNode to run on multiple ports, connecting to different NameNode ports would end up with different levels of encryption protection. This protection then gets enforced for both NameNode RPC and the subsequent data transfers to/from DataNode. This approach comes with minimum operational and performance overhead.Speaker: Konstantin Shvachko (LinkedIn), Chen Liang (LinkedIn)11:10 - 11:55:-------------Talk: YuniKorn: Next Generation Scheduling for YARN and K8sAbstract: We will talk about our open source work - YuniKorn scheduler project (Y for YARN, K for K8s, uni- for Unified) brings long-wanted features such as hierarchical queues, fairness between users/jobs/queues, preemption to Kubernetes; and it brings service scheduling enhancements to YARN. Any improvements to this scheduler can benefit both Kubernetes and YARN community.Speaker: Wangda Tan (Cloudera)PM:12:00 - 12:55 Lunch Break (Provided by Cloudera)------------------------------------------------1:00 - 1:25-----------Talk: Yarn Efficiency at UberAbstract: We will present the work done at Uber to improve YARN cluster utilization and job SOA with elastic resource management, low compute workload on passive datacenter, preemption, larger container, etc. We will also go through YARN upgrade in order to adopt new features and talk about the challenges.Speaker: Aihua Xu (Uber), Prashant Golash (Uber)1:30 - 2:10 One more talk---------------------------------2:20 - 4:00-----------BoF sessions & Breakout Sessions & Group discussions: Talk about items like JDK 11 support, next releases (2.10.0, 3.3.0, etc.), Hadoop on Cloud, etc.4:00: Reception provided by Cloudera.==============================================Join Zoom Meetinghttps://cloudera.zoom.us/j/116816195 *",not-ak
2,Re: Performance Engineering Track at ApacheCon NA? Hi Dinesh Thanks for volunteering to help us review the submissions for the Performance Engineering track. One thing we are currently asking of the track reviewers is that they are not planning to make a submission to the track they are reviewing. Will that be OK for you? If so then please let me know so I can contact you about getting setup. Thanks Sharan On 2022/04/06 17:21:52 Dinesh Joshi wrote:,not-ak
3,Re: Performance Engineering Track at ApacheCon NA? That�s great to hear. I would also be available to help review submissions.,not-ak
4,Re: Performance Engineering Track at ApacheCon NA? Hi Paulo We have great news - the Performance Engineering track has been accepted so we will be looking to encourage and promote CFP submissions for it. We are also looking for reviewers to help us rate the submissions---if you are still interested in doing that. ;-) Thanks Sharan On 2022/03/16 15:36:04 Sharan Foga wrote:,not-ak
35,Re: Performance Engineering Track at ApacheCon NA? Hi Paulo Thanks for the feedback. If we do get the track accepted then we will definitely be needing help reviewing the submissions - so may take you up on your offer :-) Thanks Sharan On 2022/03/14 16:32:23 Paulo Motta wrote:,not-ak
46,"Re: Performance Engineering Track at ApacheCon NA? This Apachecon track sounds fun! I hope someone from the Cassandra community steps up to help on this track.I would be happy to help on reviews but not organize the event per se as I will likely not attend the event.Em sex., 11 de mar. de 2022 �s 09:26, sharanf <sharan@apache.org> escreveu:Hi All The call for tracks for ApacheCon NA is open. There is a suggestion to try and run a Performance Engineering track at ApacheCon this year. At the end of the message I have included some details including a definition�of what we mean by it and some reasoning about why it could be good to run. We have a list of projects that have something to do with performance engineering and if you take a look -� you will see that this project is on the list! So what I need is a some feedback as to whether the community thinks that this could be an interesting track topic to run at ApacheCon..and more importantly would the community be willing to submit talks for it or attend ApacheCon to see it. Like I say - this is just an idea at this stage. If the Performance Engineering track does get approval to be included at ApacheCon� - do we have any volunteers willing to help with�managing and promoting the track on behalf of the project? Thanks Sharan ----------------------------- *Performance Engineering*� is the science and practice of engineering software with the required performance and scalability characteristics. Many Apache projects focus on solving hard Big Data performance and scalability challenges, while others provide tools for performance engineering - but there are few projects that don�t care about some aspect of software performance. This track will enable Apache projects members to share their experiences of performance engineering best practices, tools, techniques, and results, from their own communities, with the benefits of cross-fertilization between projects. Performance Engineering in the wider open source community is pervasive and includes methods and tools (including automation and agile approaches) for performance: architecting and design, benchmarking, monitoring, tracing, analysis, prediction, modeling and simulation, testing and reporting, regression testing, and source code analysis and instrumentation techniques. Performance Engineering also has wider applicability to DevOps, the operation of cloud platforms by managed service providers (hence some overlap with SRE - Site Reliability Engineering), and customer application performance and tuning.� This track would therefore be applicable to the wider open source community. *SUPPORTING DETAILS* *Google Searches* Google �Open source performance engineering� has 4,180,000,000 results Google �site:apache.org<http://apache.org>� performance� has 147,000 results *Apache Projects *which may have some interest in, or focus on, performance (just the top results): JMeter, Cassandra, Storm, Spark, Samza, Pulsar, Kafka, Log4J, SystemML, Drill, HTTP Server, Cayenne, ActiveMQ, Impala, Geode, Flink, Ignite, Impala, Lucene, TVM, Tika, YuniKorn, Solr, Iceberg, Dubbo, Hudi, Accumulo, Xerces, MXNet, Zookeeper *Incubator projects *which may have some interest in, or focus on, performance**(again just top results): Crail, Eagle, Nemo, Skywalking, MXnet, HAWQ, Mnemonic, CarbonData, Drill, ShenYu, Tephra, Sedona *References *(randomly selected to show the range of open-source performance engineering topics available, rather than the quality of articles): � 1. Performance Engineering for Apache Spark and Databricks Runtime � � �ETHZ, Big Data HS19 � � �<https://archive-systems.ethz.ch/sites/default/files/courses/2019-fall/bigdata/Databricks%20ETHZ%20Big%20Data%20HS19.pdf> � 2. Real time insights into LinkedIn's performance using Apache Samza � � �<https://engineering.linkedin.com/samza/real-time-insights-linkedins-performance-using-apache-samza> � 3. A day in the life of an open source performance engineering team � � �<https://opensource.com/article/19/5/life-performance-engineer> � 4. Locating Performance Regression Root Causes in the Field Operations � � �of<https://ieeexplore.ieee.org/document/9629300>Web-based Systems: � � �An Experience Report Published in: IEEE Transactions on Software � � �Engineering (Early Access) � � �<https://ieeexplore.ieee.org/document/9629300> � 5. How to Detect Performance Changes in Software History: Performance � � �Analysis of Software System Versions � � �<https://dl.acm.org/doi/10.1145/3185768.3186404> � 6. Performance-Regression Pitfalls Every Project Should Avoid � � �<https://www.eetimes.eu/performance-regression-pitfalls-every-project-should-avoid/> � 7. How to benchmark your websites with the open source Apache Bench � � �tool � � �<https://www.techrepublic.com/article/how-to-benchmark-your-websites-with-the-open-source-apache-bench-tool/> � 8. Benchmarking Pulsar and Kafka - A More Accurate Perspective on � � �Pulsar�s Performance � � �<https://streamnative.io/blog/tech/2020-11-09-benchmark-pulsar-kafka-performance/> � 9. Performance-Analyse: Apache Cassandra 4.0.0 Release � � �<https://benchant.com/blog/cassandra-4-performance> 10. Log4J Performance - This page compares the performance of a number � � �of logging frameworks � � �<https://logging.apache.org/log4j/2.x/performance.html> 11. SystemML Performance Testing � � �<https://systemds.apache.org/docs/1.0.0/python-performance-test.html>",not-ak
63,"Performance Engineering Track at ApacheCon NA? Hi All The call for tracks for ApacheCon NA is open. There is a suggestion to try and run a Performance Engineering track at ApacheCon this year. At the end of the message I have included some details including a definition of what we mean by it and some reasoning about why it could be good to run. We have a list of projects that have something to do with performance engineering and if you take a look - you will see that this project is on the list! So what I need is a some feedback as to whether the community thinks that this could be an interesting track topic to run at ApacheCon..and more importantly would the community be willing to submit talks for it or attend ApacheCon to see it. Like I say - this is just an idea at this stage. If the Performance Engineering track does get approval to be included at ApacheCon - do we have any volunteers willing to help with managing and promoting the track on behalf of the project? Thanks Sharan ----------------------------- *Performance Engineering* is the science and practice of engineering software with the required performance and scalability characteristics. Many Apache projects focus on solving hard Big Data performance and scalability challenges, while others provide tools for performance engineering - but there are few projects that don�??t care about some aspect of software performance. This track will enable Apache projects members to share their experiences of performance engineering best practices, tools, techniques, and results, from their own communities, with the benefits of cross-fertilization between projects. Performance Engineering in the wider open source community is pervasive and includes methods and tools (including automation and agile approaches) for performance: architecting and design, benchmarking, monitoring, tracing, analysis, prediction, modeling and simulation, testing and reporting, regression testing, and source code analysis and instrumentation techniques. Performance Engineering also has wider applicability to DevOps, the operation of cloud platforms by managed service providers (hence some overlap with SRE - Site Reliability Engineering), and customer application performance and tuning. This track would therefore be applicable to the wider open source community. *SUPPORTING DETAILS* *Google Searches* Google �??Open source performance engineering�?? has 4,180,000,000 results Google �??site:apache.org performance�?? has 147,000 results *Apache Projects *which may have some interest in, or focus on, performance (just the top results): JMeter, Cassandra, Storm, Spark, Samza, Pulsar, Kafka, Log4J, SystemML, Drill, HTTP Server, Cayenne, ActiveMQ, Impala, Geode, Flink, Ignite, Impala, Lucene, TVM, Tika, YuniKorn, Solr, Iceberg, Dubbo, Hudi, Accumulo, Xerces, MXNet, Zookeeper *Incubator projects *which may have some interest in, or focus on, performance**(again just top results): Crail, Eagle, Nemo, Skywalking, MXnet, HAWQ, Mnemonic, CarbonData, Drill, ShenYu, Tephra, Sedona *References *(randomly selected to show the range of open-source performance engineering topics available, rather than the quality of articles): 1. Performance Engineering for Apache Spark and Databricks Runtime ETHZ, Big Data HS19 2. Real time insights into LinkedIn's performance using Apache Samza 3. A day in the life of an open source performance engineering team 4. Locating Performance Regression Root Causes in the Field Operations ofWeb-based Systems: An Experience Report Published in: IEEE Transactions on Software Engineering (Early Access) 5. How to Detect Performance Changes in Software History: Performance Analysis of Software System Versions 6. Performance-Regression Pitfalls Every Project Should Avoid 7. How to benchmark your websites with the open source Apache Bench tool 8. Benchmarking Pulsar and Kafka - A More Accurate Perspective on Pulsar�??s Performance 9. Performance-Analyse: Apache Cassandra 4.0.0 Release 10. Log4J Performance - This page compares the performance of a number of logging frameworks 11. SystemML Performance Testing",not-ak
570,"[RELEASE] Apache Cassandra 4.0-beta2 released The Cassandra team is pleased to announce the release of Apache Cassandra version 4.0-beta2. Apache Cassandra is a fully distributed database. It is the right choice when you need scalability and high availability without compromising performance. http://cassandra.apache.org/ Downloads of source and binary distributions are listed in our download section: http://cassandra.apache.org/download/ This version is a bug fix release[1] on the 4.0 series. As always, please pay attention to the release notes[2] and Let us know[3] if you were to encounter any problem. Enjoy! [1]: CHANGES.txt https://gitbox.apache.org/repos/asf?p=cassandra.git;a=blob_plain;f=CHANGES.txt;hb=refs/tags/cassandra-4.0-beta2 [2]: NEWS.txt https://gitbox.apache.org/repos/asf?p=cassandra.git;a=blob_plain;f=NEWS.txt;hb=refs/tags/cassandra-4.0-beta2 [3]: https://issues.apache.org/jira/browse/CASSANDRA",not-ak
1417,"RE: A top container module like hadoop-cloud for cloud integration modules Thanks Steve for the feedback and thoughts. Looks like people don't want to move around the related modules as it may not add much real value. It's fine. I may provide better thoughts later when learn the aspect deeper. Regards, Kai",not-ak
2217,"RE: RE: SEVERE Data Corruption Problems Here is my chronology: - I turned on my current cluster in early December, starting with about 0.7 RC2 or thereabouts. I ran into a number of problems but was able to get things more or less ironed out (upgrading to new versions pretty quickly). Once 0.7.0 was released, I had no problems for about 2 weeks. In that time (using 0.7.0), I ran frequent compactions but never a repair (not really needed with my workload: read repair works fine and I use expiring columns) - Sometime mid-January (~21) I hit my first instance of sstable corruption. I was able to fix things by deleting EVERYTHING related to the problematic CF on the problematic node (sstables, hints column family, saved caches, the works). I then ran a repair which failed (http://www.mail-archive.com/user@cassandra.apache.org/msg09154.html) possibly due to CASSANDRA-1992 or some such. I was able to delete sstables, run cleanup and compaction, truncate unimportant CFs and get my service operating again - A week or two ago I created a new CF which turned out to be the most problematic in terms of SSTable corruption. Since creating this CF via CLI (again, all nodes running 0.7.0), there have been no repairs run and no ring changes (moving, bootstrapping or decommissioning). Unless I misunderstand CASSANDRA-1992, I don't think it is related. I have been seeing steadily increasing rates of Cassandra exceptions on multiple CFs, reads failing, compaction failing, hinted handoff failing, inability to export sstables2json, etc. Now I cant even understand how any of the RC bugs I hit back in the day are still around given I was running 0.7.0 for weeks and ran multiple full compactions without issue. Regardless, they could not have affected then new CF. I have seen no improvement for the one node I put on the 0.7 branch (r 1069600). I am seeing the same behaviour for multiple failed compactions (as per the bug I filed: https://issues.apache.org/jira/browse/CASSANDRA-2084) and am still investigating the read exceptions. Jonathan suggested a completely clean 0.7.1 install which would be a lot of work given I would have to migrate data at an application level but I would be willing to do so if I had any confidence it would help. Here is an example of one SSTable on the node running 0.7. Notice that a bunch of seemingly fine sstables (no problems reading from it that I could determine but my tests were not rigorous and this happened overnight), which had to either be created or compacted at least once (given -f-) on 0.7 (with, for example, the CASSANDRA-1992 and CASSANDRA-1999 fixes) gets compacted to a new SSTable that is completely f'ed. INFO [CompactionExecutor:1] 2011-02-10 20:25:42,200 CompactionManager.java (line 373) Compacting [org.apache.cassandra.io.sstable.SSTableReader(path='/var/lib/cassandra/data /kikmetrics/ProcessingBuckets-f-4311-Data.db'),org.apache.cassandra.io.sstab le.SSTableReader(path='/var/lib/cassandra/data/kikmetrics/ProcessingBuckets- f-4312-Data.db'),org.apache.cassandra.io.sstable.SSTableReader(path='/var/li b/cassandra/data/kikmetrics/ProcessingBuckets-f-4313-Data.db'),org.apache.ca ssandra.io.sstable.SSTableReader(path='/var/lib/cassandra/data/kikmetrics/Pr ocessingBuckets-f-4314-Data.db')] ... INFO [CompactionExecutor:1] 2011-02-10 20:25:49,908 CompactionIterator.java (line 135) Compacting large row 555345525f4556454e547c5345434f4e445f3130 (393599737 bytes) incrementally ... INFO [CompactionExecutor:1] 2011-02-10 20:26:42,989 CompactionManager.java (line 458) Compacted to /var/lib/cassandra/data/kikmetrics/ProcessingBuckets-tmp-f-4315-Data.db. 487,085,029 to 477,567,892 (~98% of original) bytes for 12 keys. Time: 60,788ms. ... ... this sstable does not appear in the logs unitll: ... INFO [CompactionExecutor:1] 2011-02-10 22:51:30,613 CompactionManager.java (line 373) Compacting [org.apache.cassandra.io.sstable.SSTableReader(path='/var/lib/cassandra/data /kikmetrics/ProcessingBuckets-e-4295-Data.db'),org.apache.cassandra.io.sstab le.SSTableReader(path='/var/lib/cassandra/data/kikmetrics/ProcessingBuckets- f-4315-Data.db'),org.apache.cassandra.io.sstable.SSTableReader(path='/var/li b/cassandra/data/kikmetrics/ProcessingBuckets-f-4320-Data.db'),org.apache.ca ssandra.io.sstable.SSTableReader(path='/var/lib/cassandra/data/kikmetrics/Pr ocessingBuckets-f-4327-Data.db')] ... ... Note the 'File :' output is a minor change I made (obviously) ... ERROR [CompactionExecutor:1] 2011-02-10 22:51:49,029 AbstractCassandraDaemon.java (line 114) Fatal exception in thread Thread[CompactionExecutor:1,1,main] java.io.IOError: java.io.IOException: File :/var/lib/cassandra/data/kikmetrics/ProcessingBuckets-f-4315-Data.db at org.apache.cassandra.io.sstable.SSTableIdentityIterator.(SSTableIdenti tyIterator.java:85) at org.apache.cassandra.io.sstable.SSTableScanner$KeyScanningIterator.next(SSTa bleScanner.java:179) at org.apache.cassandra.io.sstable.SSTableScanner$KeyScanningIterator.next(SSTa bleScanner.java:144) at org.apache.cassandra.io.sstable.SSTableScanner.next(SSTableScanner.java:136) at org.apache.cassandra.io.sstable.SSTableScanner.next(SSTableScanner.java:39) at org.apache.commons.collections.iterators.CollatingIterator.set(CollatingIter ator.java:284) at org.apache.commons.collections.iterators.CollatingIterator.least(CollatingIt erator.java:326) at org.apache.commons.collections.iterators.CollatingIterator.next(CollatingIte rator.java:230) at org.apache.cassandra.utils.ReducingIterator.computeNext(ReducingIterator.jav a:68) at com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator .java:136) at com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:131 ) at org.apache.commons.collections.iterators.FilterIterator.setNextObject(Filter Iterator.java:183) at org.apache.commons.collections.iterators.FilterIterator.hasNext(FilterIterat or.java:94) at org.apache.cassandra.db.CompactionManager.doCompaction(CompactionManager.jav a:427) at org.apache.cassandra.db.CompactionManager$1.call(CompactionManager.java:123) at org.apache.cassandra.db.CompactionManager$1.call(CompactionManager.java:93) at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303) at java.util.concurrent.FutureTask.run(FutureTask.java:138) at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.ja va:886) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:9 08) at java.lang.Thread.run(Thread.java:662) Caused by: java.io.IOException: File :/var/lib/cassandra/data/kikmetrics/ProcessingBuckets-f-4315-Data.db ... 21 more Caused by: java.io.EOFException: attempted to skip 67113066 bytes but only skipped 27852647 at org.apache.cassandra.io.sstable.IndexHelper.skipBloomFilter(IndexHelper.java :51) at org.apache.cassandra.io.sstable.SSTableIdentityIterator.(SSTableIdenti tyIterator.java:69) ... 20 more INFO [CompactionExecutor:1] 2011-02-10 22:51:49,030 CompactionManager.java (line 373) Compacting [org.apache.cassandra.io.sstable.SSTableReader(path='/var/lib/cassandra/data /kikmetrics/ProcessingBuckets-e-4295-Data.db'),org.apache.cassandra.io.sstab le.SSTableReader(path='/var/lib/cassandra/data/kikmetrics/ProcessingBuckets- f-4315-Data.db'),org.apache.cassandra.io.sstable.SSTableReader(path='/var/li b/cassandra/data/kikmetrics/ProcessingBuckets-f-4320-Data.db'),org.apache.ca ssandra.io.sstable.SSTableReader(path='/var/lib/cassandra/data/kikmetrics/Pr ocessingBuckets-f-4327-Data.db')] ... etc ... Now when trying to export ProcessingBuckets-f-4315-Data.db using sstable2json, I get the following: Exception in thread ""main"" java.io.IOError: java.io.EOFException at org.apache.cassandra.io.util.ColumnIterator.deserializeNext(ColumnSortedMap. java:246) at org.apache.cassandra.io.util.ColumnIterator.next(ColumnSortedMap.java:262) at org.apache.cassandra.io.util.ColumnIterator.next(ColumnSortedMap.java:223) at java.util.concurrent.ConcurrentSkipListMap.buildFromSorted(ConcurrentSkipLis tMap.java:1493) at java.util.concurrent.ConcurrentSkipListMap.(ConcurrentSkipListMap.java :1443) at org.apache.cassandra.db.SuperColumnSerializer.deserialize(SuperColumn.java:3 66) at org.apache.cassandra.db.SuperColumnSerializer.deserialize(SuperColumn.java:3 14) at org.apache.cassandra.db.columniterator.IndexedSliceReader$IndexedBlockFetche r.getNextBlock(IndexedSliceReader.java:181) at org.apache.cassandra.db.columniterator.IndexedSliceReader.computeNext(Indexe dSliceReader.java:120) at org.apache.cassandra.db.columniterator.IndexedSliceReader.computeNext(Indexe dSliceReader.java:48) at com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator .java:136) at com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:131 ) at org.apache.cassandra.db.columniterator.SSTableSliceIterator.hasNext(SSTableS liceIterator.java:108) at org.apache.cassandra.tools.SSTableExport.serializeRow(SSTableExport.java:178 ) at org.apache.cassandra.tools.SSTableExport.export(SSTableExport.java:353) at org.apache.cassandra.tools.SSTableExport.export(SSTableExport.java:375) at org.apache.cassandra.tools.SSTableExport.export(SSTableExport.java:388) at org.apache.cassandra.tools.SSTableExport.main(SSTableExport.java:446) Caused by: java.io.EOFException at java.io.RandomAccessFile.readByte(RandomAccessFile.java:591) at org.apache.cassandra.utils.ByteBufferUtil.readShortLength(ByteBufferUtil.jav a:287) at org.apache.cassandra.utils.ByteBufferUtil.readWithShortLength(ByteBufferUtil .java:298) at org.apache.cassandra.db.ColumnSerializer.deserialize(ColumnSerializer.java:6 6) at org.apache.cassandra.io.util.ColumnIterator.deserializeNext(ColumnSortedMap. java:242) ... 17 more :( Dan From: Aaron Morton [mailto:aaron@thelastpickle.com] Sent: February-10-11 20:16 To: dev@cassandra.apache.org Subject: Re: RE: SEVERE Data Corruption Problems Looks like the bloom filter for the row is corrupted, does it happen for all reads or just for reads on one row ? After the upgrade to 0.7 (assuming an 0.7 nightly build) did you run anything like nodetool repair ? Have you tried asking on the #cassandra IRC room to see if their are any comitters around ? Aaron On 11 Feb, 2011,at 01:18 PM, Dan Hendry wrote: Upgraded one node to 0.7. Its logging exceptions like mad (thousands per minute). All like below (which is fairly new to me): ERROR [ReadStage:721] 2011-02-10 18:13:56,190 AbstractCassandraDaemon.java (line 114) Fatal exception in thread Threa d[ReadStage:721,5,main] java.io.IOError: java.io.EOFException at org.apache.cassandra.db.columniterator.SSTableNamesIterator.(SSTableNa mesIterator.java:75) at org.apache.cassandra.db.filter.NamesQueryFilter.getSSTableColumnIterator(Nam esQueryFilter.java:59) at org.apache.cassandra.db.filter.QueryFilter.getSSTableColumnIterator(QueryFil ter.java:80) at org.apache.cassandra.db.ColumnFamilyStore.getTopLevelColumns(ColumnFamilySto re.java:1275) at org.apache.cassandra.db.ColumnFamilyStore.getColumnFamily(ColumnFamilyStore. java:1167) at org.apache.cassandra.db.ColumnFamilyStore.getColumnFamily(ColumnFamilyStore. java:1095) at org.apache.cassandra.db.Table.getRow(Table.java:384) at org.apache.cassandra.db.SliceByNamesReadCommand.getRow(SliceByNamesReadComma nd.java:60) at org.apache.cassandra.service.StorageProxy$LocalReadRunnable.runMayThrow(Stor ageProxy.java:473) at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:30) at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.ja va:886) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:9 08) at java.lang.Thread.run(Thread.java:662) Caused by: java.io.EOFException at java.io.DataInputStream.readInt(DataInputStream.java:375) at org.apache.cassandra.utils.BloomFilterSerializer.deserialize(BloomFilterSeri alizer.java:48) at org.apache.cassandra.utils.BloomFilterSerializer.deserialize(BloomFilterSeri alizer.java:30) at org.apache.cassandra.io.sstable.IndexHelper.defreezeBloomFilter(IndexHelper. java:108) at org.apache.cassandra.db.columniterator.SSTableNamesIterator.read(SSTableName sIterator.java:106) at org.apache.cassandra.db.columniterator.SSTableNamesIterator.(SSTableNa mesIterator.java:71) ... 12 more Dan",not-ak
1253,"[RELEASE] Apache Cassandra 2.1.16 released The Cassandra team is pleased to announce the release of Apache Cassandra version 2.1.16. Apache Cassandra is a fully distributed database. It is the right choice when you need scalability and high availability without compromising performance. http://cassandra.apache.org/ Downloads of source and binary distributions are listed in our download section: http://cassandra.apache.org/download/ This version is a bug fix release[1] on the 2.1 series. As always, please pay attention to the release notes[2] and Let us know[3] if you were to encounter any problem. Enjoy! [1]: (CHANGES.txt) https://goo.gl/Unwb9s [2]: (NEWS.txt) https://goo.gl/LuZHa5 [3]: https://issues.apache.org/jira/browse/CASSANDRA",not-ak
1517,"Re: The Apache Software Foundation announces Apache(tm) Tajo(tm) v0.11.0 Great! Thanks Hyunsik and others for your effort. Best regards, Jihoon 2015? 10? 27? (?) ?? 8:41, Hyunsik Choi hyunsik@apache.org>?? ??:",not-ak
1268,"[RELEASE] Apache Cassandra 3.8 released The Cassandra team is pleased to announce the release of Apache Cassandra version 3.8. Apache Cassandra is a fully distributed database. It is the right choice when you need scalability and high availability without compromising performance. http://cassandra.apache.org/ Downloads of source and binary distributions are listed in our download section: http://cassandra.apache.org/download/ This version is a bug fix release[1] on the 3.8 series. As always, please pay attention to the release notes[2] and Let us know[3] if you were to encounter any problem. Enjoy! [1]: (CHANGES.txt) https://goo.gl/QYFPm1 [2]: (NEWS.txt) https://goo.gl/f9y9ZV [3]: https://issues.apache.org/jira/browse/CASSANDRA",not-ak
1239,Re: Review of Cassandra actions ,not-ak
1240,Re: Review of Cassandra actions ,not-ak
1241,"Re: Review of Cassandra actions Hi Mark, Thanks, that was a calm and diplomatic email. recognise where they might need to apologise I will start the ball rolling here, as I have not always been generous in my interpretations of others' actions, and have certainly contributed to escalation. But I wonder if you would also help get the ball rolling; your reasonable tone gives me hope that you can. The topic for me has been: can board members recognise publicly where they have misstepped. Doing so provides assurances to the whole ASF community that the board can be trusted. https://www.mail-archive.com/user@cassandra.apache.org/msg48692.html In this email chain not long ago, you attempted to apply a misreading of the ASF guidelines to non-ASF individuals. When I pointed this out, you went silent. In that chain, as now, I had a righteous indignation that no doubt inflamed the topic, and could have resolved the issue with more diplomacy. I'm also sure you had excellent intentions. Nevertheless, you did misstep as a board member by quite badly misapplying the guidelines. With no public recognition of this, I was left with an impression of unaccountability; I don't know how others responded. I think it would be fantastic if board members, as people in positions of authority, lead by example and began recognising where their public behaviour has missed the mark. Perhaps that would promote those in less lofty positions to begin doing the same, and greater trust all round. On 6 November 2016 at 21:42, Mark Thomas wrote:",not-ak
1242,Re: Review of Cassandra actions For the sake of clarity I am a member of the ASF board but I am not speaking on behalf of the board in this email. ,not-ak
1243,"Re: Review of Cassandra actions Benedict, you ride the 'bla said blub', b��h.. since at least 5 replies. Yes the discussion was heated on both sides. But Chris didn't say anything since many posts. And his reply was sharp but really not totally personal. Can we now come back to a more technical discussion again please? Some board members tried to explain what they think went wrong. (And 'they' is not a single person but a pretty big group of people). This got dealt with by the board and the Cassandra PMC since months (the first mails I can find are from February). Recently very positive work has been done by both DataStax (cleaner separation of Cassandra as community project and their company. Also _many_ trademark fixes have been applied) and the overall PMC (many new PMC members from other companies got voted in). But all that only after the nice words got followed by sanctions. To be honest I've not seen a project where people are around for 3 years, have over 500 good commits and STILL did not get invited to become a PMC member. That is usually a very alarming sign. And I've seen other PMCs acting as 'owner' of a project and 'defending' their influence in the past. But that is not what the ASF wants! We aim for real community projects and not benevolent dictatorship. PS, those other projecs got 'fixed' as well... LieGrue, strub On Sunday, 6 November 2016, 18:45, Benedict Elliott Smith wrote:",not-ak
1244,"Re: Review of Cassandra actions You've cherry picked, as usual. ""In what possible universe dropping that hammer threat from the �20% off� email thread, then following up with a Game of Thrones youtube clip is alright?"" ""In an ideal world, that power would entail corresponding duties: care and consideration in your actions at least."" ""That kind of behaviour is inappropriate for a board member... If you don�t see this, we do indeed have bigger problems."" You seem to suffer from double standards, in the wrong direction. Far more offensive language from a board member is completely justifiable by nothing by frustration . experience with far less incendiary language is completely inexcusable, and obviates the rest of a message. On 6 November 2016 at 17:33, Jim Jagielski wrote:",not-ak
1245,"Re: Review of Cassandra actions ""well written, cogent and on-topic"" ... ""reasoned rebuttal"" You keep on using those words. I don't think they mean what you think they do. Some data points: o "" A lot of extra power, like it or not (I have a feeling you quite like it, though)."" o ""you are being hotheaded, impulsive, antagonising, and immature."" o ""in what possible universe"" o ""Frankly, it wouldn�t be appropriate for a greeter at Walmart"" So if the above warrants what you consider well-written, cogent, on-topic and reasoned, then I fear that any further discussion is really worthless. o+o",not-ak
1246,"Re: Review of Cassandra actions Jim, I would love it if you could take the time to explain how arrived at a diagnosis of trolling. Aleksey made a well written, cogent and on-topic criticism of your ongoing behaviour, as well as a reasoned rebuttal of your absurd claim that your power is inherent to *you*, not your position (I don't think many people know who you are, only what you are). It was explicitly the topic of discussion, and there is mounting evidence of your misbehaviour. This is the very definition of discussion, not trolling. Much like your ""chess"" comment, this appears to be an attempt to shut down substantive discussion of your unsuitability for the role of board member. On 6 November 2016 at 13:01, Jim Jagielski wrote:",not-ak
1247,"Re: Review of Cassandra actions Sorry that people took the reply as pompous... You are certainly within your rights to take it anyway you want. It was not meant that way. In the same vein, I am within my rights to take responses in the way I want, which I took as simple trolling. And with trolls, as with thermonuclear war, the only ""winning"" move is not to play.",not-ak
1248,Re: Review of Cassandra actions Thanks Jeff for your thoughtful comments. +100 Sent from my iPhone,not-ak
1249,"Re: Review of Cassandra actions I hope the other 7 members of the board take note of this response, and other similar reactions on dev@ today. When Datastax violated trademark, they acknowledged it and worked to correct it. To their credit, they tried to do the right thing. When the PMC failed to enforce problems, we acknowledged it and worked to correct it. We aren't perfect, but we're trying. When a few members the board openly violate the code of conduct, being condescending and disrespectful under the auspices of ""enforcing the rules"" and ""protecting the community"", they're breaking the rules, damaging the community, and nobody seems willing to acknowledge it or work to correct it. It's not isolated, I'll link examples if it's useful. In a time when we're all trying to do the right thing to protect the project and the community, it's unfortunate that high ranking, long time members within the ASF actively work to undermine trust and community while flaunting the code of conduct, which requires friendliness, empathy, and professionalism, and the rest of the board is silent on the matter.",not-ak
1250,"Re: Review of Cassandra actions I take this response (a second time) as a pompous way to trivialize the responses of others as to the point of their points being meaningless to you. So either explain what this means, or accept the fact that you are as Chris is exactly what people are claiming you to be. Abnoxious bullies more interested in throwing your weight around and causing havoc, destroying a community, rather than actually being motivated by improving the ASF. On 11/05/2016 06:16 PM, Jim Jagielski wrote:",not-ak
1765,"Help needed: failed unit test based on miniMRCluster on Yarn with cdh 5.1.3 Hi, folks, I have encountered a strange error when I am trying to upgrade from cdh4 to cdh5.1.3. I have a unit test based on miniMRcluster and ClusterMapReduceTestCase. It runs successfully with cdh 4. After I have changed my maven setting to upgrade to cdh5. The running always failed. I have tried to isolate the problem. So I used the standard unit test (https://svn.apache.org/repos/asf/hadoop/common/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestMiniMRClientCluster.java) and compile it with my maven setting, then I reproduced the same error by only testing testRestart(). 22596 [main] INFO org.apache.hadoop.mapreduce.v2.hs.JobHistory - Stopping JobHistory 22596 [main] INFO org.apache.hadoop.mapreduce.v2.hs.JobHistory - Stopping History Cleaner/Move To Done 22597 [Thread[Thread-184,5,main]] ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted 22597 [main] INFO org.apache.hadoop.hdfs.MiniDFSCluster - Shutting down the Mini HDFS Cluster 22597 [main] INFO org.apache.hadoop.hdfs.MiniDFSCluster - Shutting down DataNode 1 22598 [main] WARN org.apache.hadoop.hdfs.server.datanode.DirectoryScanner - DirectoryScanner: shutdown has been called The test should be compatible for both MR1 and MR2. I also tried to overwrite some Yarn configuration, but it didn't help. I tried to google the related issue, but no luck for this particular issue.Any comments or Help are appreciated. Thanks so much! My mvn configuration part is as follows, 2.3.0-cdh5.1.3 2.3.0-cdh5.1.3 2.3.0-cdh5.1.3 org.apache.hadoop hadoop-client ${version.hadoop} org.apache.hadoop hadoop-minicluster ${version.hadoop.minicluster} org.slf4j slf4j-log4j12 ${project.groupId} common-hadoop ${project.version} Best regards, Lumin Zhang",not-ak
1058,"[VOTE] Merge HDFS-9806 to trunk Discussion thread: https://s.apache.org/kxT1 We're down to the last few issues and are preparing the branch to merge to trunk. We'll post merge patches to HDFS-9806 [1]. Minor, ""cleanup"" tasks (checkstyle, findbugs, naming, etc.) will be tracked in HDFS-12712 [2]. We've tried to ensure that when this feature is disabled, HDFS is unaffected. For those reviewing this, please look for places where this might add overheads and we'll address them before the merge. The site documentation [3] and design doc [4] should be up to date and sufficient to try this out. Again, please point out where it is unclear and we can address it. This has been a long effort and we're grateful for the support we've received from the community. In particular, thanks to ��igo Goiri, Andrew Wang, Anu Engineer, Steve Loughran, Sean Mackrory, Lukas Majercak, Uma Gunuganti, Kai Zheng, Rakesh Radhakrishnan, Sriram Rao, Lei Xu, Zhe Zhang, Jing Zhao, Bharat Viswanadham, ATM, Chris Nauroth, Sanjay Radia, Atul Sikaria, and Peng Li for all your input into the design, testing, and review of this feature. The vote will close no earlier than one week from today, 12/15. -C [1]: https://issues.apache.org/jira/browse/HDFS-9806 [2]: https://issues.apache.org/jira/browse/HDFS-12712 [3]: https://github.com/apache/hadoop/blob/HDFS-9806/hadoop-hdfs-project/hadoop-hdfs/src/site/markdown/HdfsProvidedStorage.md [4]: https://issues.apache.org/jira/secure/attachment/12875791/HDFS-9806-design.002.pdf --------------------------------------------------------------------- To unsubscribe, e-mail: hdfs-dev-unsubscribe@hadoop.apache.org For additional commands, e-mail: hdfs-dev-help@hadoop.apache.org",not-ak
71,"[RELEASE] Apache Cassandra 4.0.3 released The Cassandra team is pleased to announce the release of Apache Cassandra version 4.0.3.Apache Cassandra is a fully distributed database. It is the right choice when you need scalability and high availability without compromising performance.�http://cassandra.apache.org/Downloads of source and binary distributions are listed in our download section:�http://cassandra.apache.org/download/This version is a bug fix release[1] on the 4.0 series. As always, please pay attention to the release notes[2] and Let us know[3] if you were to encounter any problem.Enjoy![1]: CHANGES.txt https://gitbox.apache.org/repos/asf?p=cassandra.git;a=blob_plain;f=CHANGES.txt;hb=refs/tags/cassandra-4.0.3[2]: NEWS.txt https://gitbox.apache.org/repos/asf?p=cassandra.git;a=blob_plain;f=NEWS.txt;hb=refs/tags/cassandra-4.0.3[3]: https://issues.apache.org/jira/browse/CASSANDRA",not-ak
896,"triage of recent dtest failures Hi all, Now that the vote is on for the next releases, I've done an initial triage of the failed dtest runs from 2.2, 3.0, and 3.11 (based on my circleci runs). Below are the ten dtest failures I found most often (not exhaustive, but representative), and I opened up corresponding jiras for them. Let's see if we can get all the tickets assigned and analyzed. If in researching, a test is indescribably flakey, that is valuble knowledge as well. Being able to identify flakey tests and label them as such is step forward, lacking a full fix. With these tickets, it might be that the test needs to be corrected, and might not necessarily be a problem with database. In some cases, it will be a problem in casandra, so please keep that in mind. Remember, fixing these tests helps *all* of us get to more stable and reliable releases, and thus makes the database and project as a whole stronger. Also, feel free to reach out to me with questions on these. Thanks! -Jason * test_describecluster_more_information_three_datacenters - nodetool_test.TestNodetool - versions: 3.11, 3.0, 2.2 https://issues.apache.org/jira/browse/CASSANDRA-14484# * test_closing_connections - thrift_hsha_test.TestThriftHSHA - versions: 3.11, 3.0, 2.2 https://issues.apache.org/jira/browse/CASSANDRA-14595 * test_mutation_v5 - write_failures_test.TestWriteFailures - versions: 3.11 only https://issues.apache.org/jira/browse/CASSANDRA-14596 * snapshot_test.TestArchiveCommitlog.* - versions: apparently only 3.0 https://issues.apache.org/jira/browse/CASSANDRA-14597 * test_decommissioned_node_cant_rejoin - topology_test.TestTopology - versions: seen on 3.0, but may be more https://issues.apache.org/jira/browse/CASSANDRA-14598 * test_functional - global_row_key_cache_test.TestGlobalRowKeyCache - versions: apparently only 3.0 https://issues.apache.org/jira/browse/CASSANDRA-14599 * test_system_auth_ks_is_alterable - auth_test.TestAuth - versions: 3.0 / 3.11 https://issues.apache.org/jira/browse/CASSANDRA-14600 * test_failure_threshold_deletions - paging_test.TestPagingWithDeletions -versions 3.11 only https://issues.apache.org/jira/browse/CASSANDRA-14601 * test_sstableofflinerelevel - offline_tools_test.TestOfflineTools - versions 3.0 only https://issues.apache.org/jira/browse/CASSANDRA-14602 * test_alter_rf_and_run_read_repair & test_read_repair_chance - read_repair_test.TestReadRepair - versions 2.2, 3.0 https://issues.apache.org/jira/browse/CASSANDRA-14603",not-ak
495,"[RELEASE] Apache Cassandra 4.0-beta4 released The Cassandra team is pleased to announce the release of Apache Cassandra version 4.0-beta4. Apache Cassandra is a fully distributed database. It is the right choice when you need scalability and high availability without compromising performance. http://cassandra.apache.org/ Downloads of source and binary distributions are listed in our download section: http://cassandra.apache.org/download/ This version is a beta release[1] on the 4.0 series. As always, please pay attention to the release notes[2] and Let us know[3] if you were to encounter any problem. Enjoy! [1]: CHANGES.txt https://gitbox.apache.org/repos/asf?p=cassandra.git;a=blob_plain;f=CHANGES.txt;hb=refs/tags/cassandra-4.0-beta4 [2]: NEWS.txt https://gitbox.apache.org/repos/asf?p=cassandra.git;a=blob_plain;f=NEWS.txt;hb=refs/tags/cassandra-4.0-beta4 [3]: https://issues.apache.org/jira/browse/CASSANDRA",not-ak
1099,"[RELEASE] Apache Cassandra 3.11.1 released The Cassandra team is pleased to announce the release of Apache Cassandra version 3.11.1. Apache Cassandra is a fully distributed database. It is the right choice when you need scalability and high availability without compromising performance. http://cassandra.apache.org/ Downloads of source and binary distributions are listed in our download section: http://cassandra.apache.org/download/ This version is a bug fix release[1] on the 3.11 series. As always, please pay attention to the release notes[2] and Let us know[3] if you were to encounter any problem. Enjoy! [1]: (CHANGES.txt) https://goo.gl/QFBuPn [2]: (NEWS.txt) https://goo.gl/vHd41x [3]: https://issues.apache.org/jira/browse/CASSANDRA --------------------------------------------------------------------- To unsubscribe, e-mail: dev-unsubscribe@cassandra.apache.org For additional commands, e-mail: dev-help@cassandra.apache.org",not-ak
1647,"March 2015 QA retrospective Hi all, It�s time for the first retrospective. For those not familiar this is the part of the development process where we discuss what is and isn�t working when it comes to making reliable releases. We go over the things that worked, the things that didn�t work, and what changes we are going to make. This is not a forum for discussing individual bugs (or bugs fixed before release due to successful process) although you can cite one and we can discuss what we could have done differently to catch it. Even if a bug wasn�t released if it was caught the wrong way (blind luck) and you think our process wouldn�t have caught it you can bring that up as well. I don�t expect this retrospective to be the most productive because we already know we are far behind in several areas (passing utests, dtests, running utests and dtests for on each commit, running a larger black box system test) and many issues will circle back around to being addressed by one of those three. If your a developer you can review all things you have committed (or reviewed) in the past month and ask yourself if it met the criteria of done that we agreed on including adding tests for existing untested code (usually the thing missed). Better to do it now then after discovering your definition of done was flawed because it released a preventible bug. For this one retrospective you can reach back further to something already released that you feel passionate about, and if you can point to a utest or dtest that should have caught it that is still missing we can add that to the list of things to test. That would go under CASSANDRA-9012 (Triage missing test coverage) . There is a root JIRA for making trunk always releasable. A lot falls under CASSANDRA-9007 ( Run stress nightly against trunk in a way that validates ) which is the root for a new kitchen sink style test that validates the entire feature set together in a black box fashion. Philip Thompson has a basic job running so we are close to (or at) the tipping point where the doneness criteria for every ticket needs to include making sure this job covers the thing you added/changed. If you aren�t going to add the coverage you need to justify (to yourself and your reviewer) breaking it out into something separate and file a JIRA indicating the coverage was missing (if one doesn�t already exist). Make sure to link it to 9007 so we can see what has already been reported. The reason I say we might not be at the tipping point is that while we have the job we haven�t ironed out how stress (or something new) will act as a container for validating multiple features. Especially in an environment where things like cluster/node failures and topology changes occur. Retrospectives aren�t supposed to include the preceding paragraphs we should funnel discussion about them into a separate email thread. On to the retrospective. This is more for me to solicit from information from you then for me to push information to you. Went well Positive response to the definition of done Lot�s of manpower from QA and progress on test infrastructure Went poorly Some wanting to add validation to a kitchen sink style test, but not being able to yet Not having a way to know if we are effectively implementing the definition of done without waiting for bugs as feedback Changes Coordinate with Philip Thompson to see how we can get to having developers able to add validation to the kitchen sink style test Regards, Ariel",not-ak
1831,Re: very old dependencies I agree. We should still be diligent in keeping dependencies up-to-date as long as the changes are fairly non-destructive (I hear you about guava). That would be a pretty big service to not only users but also developers of libraries on hadoop. ,not-ak
1832,"Re: very old dependencies Yes, we've been recommending the use of the classloader option. I think it is a viable solution to the version clash problem. We're not very enthused about the classpath.first config because you could trade one set of problems for another. Judging from some issues still being discovered (MAPREDUCE-5751 and MAPREDUCE-5813 for example), however, I feel like the classloader option is not being used or tested widely... ",not-ak
1833,"Re: very old dependencies On 29 March 2014 02:41, Andrew Wang wrote: We're already supporting Java7 and openjdk7. OpenJDK doesn't seem any different in terms of reliability. One resource leak during stream closes (Y! patch in Hadoop 2.3+; already fixed in openjdk now). In exchange you get compressed pointers that work reliably, NUMA-aware heap allocation and GC (short-lived heap on local CPU, long-lived heap striped across sockets, GC threads work with their socket's RAM) 7u51 has broken a few things -not in Hadoop itself, but nearby: https://issues.apache.org/jira/browse/JCLOUDS-427 The fix for that went into Guava 16.x https://code.google.com/p/guava-libraries/issues/detail?id=1635 this shows a problem with Guava: fixes don't seem to get backported, updates drop old classes and methods. There's a risk that branch-2 will need to update Guava whether we want to or not -if some change in the OS or JVM forces it. +1 -1 We are already doing this for the non-traumatic artifacts (e.g SL4FJ), commons-io, commons-lang, commons-logging &c. Stuff with good backwards compatibility stories and no code changes. This lets YARN and client applications pick up more recent JARs (so helps their later dependencies work). Guice and Guava? Leave alone unless there's no choice. -1 Shading stops you seeing what's in the classpath, and stops ops teams doing audits & control of what artifacts are on their hosts. What if someone really did need to find what had jetty 6 on their servers. Currently: find & grep. With shading -not easy at all. What we can do is OSGi-enable the Hadoop core binaries: https://issues.apache.org/jira/browse/HADOOP-7977?jql=project%20%3D%20HADOOP%20AND%20text%20~%20osgi Then we could think about what it would take to deploy YARN apps in an OSGi container, so that the AM & other containers come up with the YARN classpath, but only have access to those bits of it hadoop exports (org.apache.hadoop,*, core & site XML), and everything else gets explicitly loaded. AMs would need to tell YARN that they were OSGi apps and then (somehow) they'd get launched in an OSGi container, picking up the local hadoop binaries, but having their own versions of everything. Someone needs to volunteer to do all of that, of course. Patching the Hadoop JARs to work in OSGi would be a first step, and could be done on branch-2 without breaking existing code. -Steve -- CONFIDENTIALITY NOTICE NOTICE: This message is intended for the use of the individual or entity to which it is addressed and may contain information that is confidential, privileged and exempt from disclosure under applicable law. If the reader of this message is not the intended recipient, you are hereby notified that any printing, copying, dissemination, distribution, disclosure or forwarding of this communication is strictly prohibited. If you have received this communication in error, please contact the sender immediately and delete it from your system. Thank You.",executive
1834,"Re: very old dependencies We've successfully supported CDH4.2+ on Java 7 as well as CDH5, so I think that code wise we're ready to move to 7. However, we can't start using Java 7-only features in the 2.x line for compatibility reasons. Also, even if the compatibility guidelines state that we can bump our dependencies whenever we want, practically speaking we can't in the 2.x line without breaking existing applications. I think the best we can do is fix this for 3.x by shading everything so we don't hit this issue again. Andrew ",executive
1835,"Re: very old dependencies I think we need some way of isolating YARN, MR, and HDFS clients from the Hadoop dependencies. Anything else just isn't sane... whatever we may say, there will always be clients that rely on the dependencies that we pull in, if we make those visible. I can't really blame clients for this. It's sort of unclear what happens when you pull in multiple versions of a dependency through Maven. The easiest way to solve this would be to use something like Maven-shade. best, Colin ",existence
1836,"Re: very old dependencies Regarding JDK7, we have at least one jira I'm aware of proposing several improvements that we can make in our code by using new JDK7 APIs. https://issues.apache.org/jira/browse/HADOOP-9590 If anyone wants to repurpose this as a master JDK7 enhancement jira and start cataloging additional improvement ideas for using JDK7 APIs, please feel free. The reluctance I've heard around JDK7 mostly relates to testing and compatibility across ecosystem components. If there are success stories around large-scale Hadoop system test suites executed with JDK7, then that could help build confidence. For compatibility, I think this effectively means that Hadoop, HDFS, YARN and MapReduce have to wait until after all downstream ecosystem projects finish their upgrades to JDK7. Chris Nauroth Hortonworks http://hortonworks.com/ ",executive
1837,"Re: very old dependencies On 28 March 2014 17:00, Sandy Ryza wrote: If you look at the compatibility statement of hadoop it makes clear there are no guarantees about dependencies and especially transitive ones. http://hadoop.apache.org/docs/r2.3.0/hadoop-project-dist/hadoop-common/Compatibility.html#Java_Classpath That is not an accident -any statement of stability would risk painting us into a corner and never able to update anything. It also allowed us to ship hadoop 2.2 without doing a rush update of every dependency -that would only have caused chaos and delays. Protubf -> 2.5 was enough -and that was done because it was even worse than guava in terms of compatibility policy. The issue goes beyond MR as YARN apps pick up the core binaries, so are constrained by what comes in hadoop/lib. hdfs/lib and yarn/lib. most of which is pretty dated. and if you have an app like hbase or accumulo, with more current dependencies, you have to play games excluding all of hadoop's dependencies. But even that doesn't help with Guava, because it is so aggressive about retiring classes and methods. for the sake of our own code and more modern apps, I'm in favour of gradually rolling out updates that don't break things, force a move to java7 or require changes to the source. -- CONFIDENTIALITY NOTICE NOTICE: This message is intended for the use of the individual or entity to which it is addressed and may contain information that is confidential, privileged and exempt from disclosure under applicable law. If the reader of this message is not the intended recipient, you are hereby notified that any printing, copying, dissemination, distribution, disclosure or forwarding of this communication is strictly prohibited. If you have received this communication in error, please contact the sender immediately and delete it from your system. Thank You.",executive
1838,"Re: very old dependencies Given the fact that Java 6 is EOL for a while, I wonder, when is a good time to drop the support of java 6 in trunk? New functionalities in JDK7 such as file system watcher can simplify the implementation of the name node and the data node in HDFS. ",executive
1839,"Re: very old dependencies I don't disagree about version age -I've just been downgrading a project to use some of the versions. The issue with YARN apps is that you get these on your classpath. 1. There's a JIRA: https://issues.apache.org/jira/browse/HADOOP-9991 2. Nobody is working full time on these, I sporadically apply the patches -I get to feel the pain downstream commons lang is at 2.6 now, which should keep you happy. jetty? Now that the shuffle is on netty we could think about this and jersey Guava is trouble. Leave it: new code doesn't work. Remove it and old code stops working. https://issues.apache.org/jira/browse/HADOOP-10101 I think for branch-3 we should go ahead an apply the patch. For branch 2, it's too destructuve. At some point we also have to commit being java7 + only -this would actually help us move up to some of the later dependencies. That's clearly not a branch-2 On 28 March 2014 14:59, Sangjin Lee wrote: -- CONFIDENTIALITY NOTICE NOTICE: This message is intended for the use of the individual or entity to which it is addressed and may contain information that is confidential, privileged and exempt from disclosure under applicable law. If the reader of this message is not the intended recipient, you are hereby notified that any printing, copying, dissemination, distribution, disclosure or forwarding of this communication is strictly prohibited. If you have received this communication in error, please contact the sender immediately and delete it from your system. Thank You.",executive
1840,"Re: very old dependencies My understanding is that unfortunately we're stuck with these for the rest of 2.x, because changing them could break jobs that rely on them. For jobs that want to use newer versions, the recommendation is to use mapreduce.user.classpath.first or turn on classpath isolation with mapreduce.job.classloader. -Sandy ",not-ak
1841,"very old dependencies Hi folks, Even as 2.3 was released, several dependencies of hadoop are quite dated. And more and more of them are causing friction for hadoop-related libraries and hadoop users in general, as these dependency versions are often incompatibly different than the versions most people use these days. So this is becoming a very real problem, if not one already. Some key ones include - guava: 11.0.2 (current 16.0.1) - jetty: 6.1.26 (current 9.1.3) - commons-lang: 2.6 (current 3.3.1) In particular, guava is already causing a lot of issues as many developers have moved onto a newer version and are using APIs that do not exist in 11.0.2, and get NoSuchMethodErrors and such. Also, for jetty, 6.1.26 has been EOFed for some time now. Do we have a plan to review some of these dependencies and upgrade them to reasonably up-to-date versions? I remember seeing some JIRAs on specific dependencies, but has a review been done to determine a good set of versions to upgrade to? It would be great if we could upgrade some of the more common ones at least to modern versions. Thanks, Sangjin",executive
1886,RE: [VOTE] Merge HDFS-2832 Heterogeneous Storage Phase 1 to trunk +1 My team has been developing and testing against the HDFS-2832 branch for the past month. It has proven to be quite stable. Eric,not-ak
851,"Re: SEDA, queues, and a second lower-priority queue set additionally, a certain number of the threads in each stage could be restricted from serving the low-priority queues at all, say 8/32 or 16/32 threads, to further ensure processing availability to the higher-priority tasks. ",not-ak
1802,"the issues when porting Cassandra to IBM power8 machine all: I am trying to port Cassandra to IBM's Power8 platform, which is little endian and Ubuntu14 installed. The follow tests failed with errors below: hcj@ubuntu-hcj:~$ ant test -Dtest.name=PreparedStatementsTest -v error log: [junit] ------------- ---------------- --------------- [junit] Testcase: testStatementRePreparationOnReconnect (org.apache.cassandra.cql3.PreparedStatementsTest): Caused an ERROR [junit] All host(s) tried for query failed (no host was tried) [junit] com.datastax.driver.core.exceptions.NoHostAvailableException: All host(s) tried for query failed (no host was tried) [junit] at com.datastax.driver.core.exceptions.NoHostAvailableException.copy (NoHostAvailableException.java:65) [junit] at com.datastax.driver.core.DefaultResultSetFuture.extractCauseFromExecutionException (DefaultResultSetFuture.java:259) [junit] at com.datastax.driver.core.DefaultResultSetFuture.getUninterruptibly (DefaultResultSetFuture.java:175) [junit] at com.datastax.driver.core.AbstractSession.execute (AbstractSession.java:52) [junit] at org.apache.cassandra.cql3.PreparedStatementsTest.testStatementRePreparationOnReconnect (PreparedStatementsTest.java:118) [junit] Caused by: com.datastax.driver.core.exceptions.NoHostAvailableException: All host(s) tried for query failed (no host was tried) [junit] at com.datastax.driver.core.RequestHandler.sendRequest (RequestHandler.java:102) [junit] at com.datastax.driver.core.SessionManager.execute (SessionManager.java:461) [junit] at com.datastax.driver.core.SessionManager.executeQuery (SessionManager.java:497) [junit] at com.datastax.driver.core.SessionManager.executeAsync (SessionManager.java:87) [junit] hcj@ubuntu-hcj:~/cassandra/cassandra-trunk$ ant test -Dtest.name=NativeCellTest -v error log: [junit] WARNING: multiple versions of ant detected in path for junit [junit] jar:file:/usr/share/ant/lib/ant.jar!/org/apache/tools/ant/Project.class [junit] and jar:file:/home/hcj/cassandra/cassandra-trunk/build/lib/jars/ant-1.6.5.jar!/org/apache/tools/ant/Project.class [junit] Testsuite: org.apache.cassandra.db.NativeCellTest [junit] Tests run: 2, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 0.932 sec [junit] [junit] ------------- Standard Output --------------- [junit] WARN 11:52:26 JNA link failure, one or more native method will be unavailable. [junit] WARN 11:52:26 JNA link failure, one or more native method will be unavailable. [junit] ------------- ---------------- --------------- [junit] Testcase: testCells(org.apache.cassandra.db.NativeCellTest): FAILED [junit] [junit] junit.framework.AssertionFailedError: [junit] at org.apache.cassandra.db.NativeCellTest.test (NativeCellTest.java:218) [junit] at org.apache.cassandra.db.NativeCellTest.testCells (NativeCellTest.java:122) [junit] hcj@ubuntu-hcj:~/cassandra/cassandra-trunk$ ant test -Dtest.name=SSTableMetadataTest -v error log: [junit] ------------- Standard Output --------------- [junit] WARN 11:54:28 JNA link failure, one or more native method will be unavailable. [junit] WARN 11:54:28 JNA link failure, one or more native method will be unavailable. [junit] ------------- ---------------- --------------- [junit] Testcase: testWithDeletes (org.apache.cassandra.io.sstable.SSTableMetadataTest): FAILED [junit] expected:<-1.71136172E8> but was:<1.420545269E9> [junit] junit.framework.AssertionFailedError: expected:<-1.71136172E8> but was:<1.420545269E9> [junit] at org.apache.cassandra.io.sstable.SSTableMetadataTest.testWithDeletes (SSTableMetadataTest.java:186) [junit] Could anyone give me any hint on how to hacking these three issues? If they are related to some native lib, which lib needs to be recompiled? Thanks, -jack",not-ak
1942,"Re: CQL vs Thrift +1. Thrift should be all about raw data cells. -Vivek ________________________________ From: Jonathan Ellis To: dev@cassandra.apache.org Sent: Thursday, July 18, 2013 2:48 AM Subject: Re: CQL vs Thrift ",not-ak
1943,"Re: CQL vs Thrift If you understand how cql collections are written you can decode them and work with them from thrift. It's quite a chore and i would not suggest trying yo do it however. (I suspect tyler tried it and jonathan broke his hand jk) There is a perl cassandra driver that did something like this. On Wednesday, July 17, 2013, Jonathan Ellis wrote:",not-ak
1944,Re: CQL vs Thrift ,not-ak
1945,Re: CQL vs Thrift ,not-ak
1946,"Re: CQL vs Thrift Hi, I'm the maintainer of pycassa and the DataStax python-driver. I just broke some fingers, so I will be brief. Regarding performance, the python driver is brand new and still has some issues to be worked out around performance (C extension, locking and signaling). How you use it has a big impact, though; see the benchmarks/ dir. Some are on par or better than pycassa for single-threaded rates with fewer connections. You can use all Thrift CFs through CQL3. Some cql3 support may be backported to pycassa to ease the transition, but I have done no work there so far. I'll leave it to somebody else to comment on adding collections, etc to Thrift. ",executive
1947,"CQL vs Thrift Hi all, This is may be is not the right place to ask, but I though developers can answer to my questions better than users. It looks clear that Cassandra dev team concentrates on CQL rather than Thrift interface. I'm considering using Cassandra as a storage for my current project which will replace MySQL. I still have problem choosing between Thrift (Pycassa) vs CQL (cqlengine, python-driver). Personally after using pycassa in test project I fall in love with it. I'd prefer to use pycassa rather than python-driver, cqlengine or write raw queries. 1) What's going on with Thrift interface and pycassa? I read somewhere that it will be for backward compatibility, but does it mean that new features will not be added to the Thrift interface hence will not be available with pycassa? For example collections http://www.datastax.com/dev/blog/cql3_collections. 2) Currently column families created using CQL is not visible through the Thrift interface and vice versa. If I start with pycassa and in future I decide to use CQL (due to lack of new features) will it be possible to use these CFs? Or convert them so they become visible and accessible using CQL? 3) Also I've done some basic tests (pycassa vs. cqlengine, no prepared statements) and seems like pycassa performs almost 2 times better which makes it more preferable. It was simple inserts of couple thousands rows. Do I have to put up with all this and start using CQL? Thanks, -- Vladimir Prudnikov",executive
266,"Re: [DISCUSS] CEP-7 Storage Attached Index Good new Mike that row based indexing will be available, this was a major lacking from SASI at that time ! Le jeu. 16 sept. 2021 � 15:38, Mike Adamson a �crit :",not-ak
267,"Re: [DISCUSS] CEP-7 Storage Attached Index Hi, Just to keep this thread up to date with development progress, we will be adding row-aware support to SAI in the next few weeks. This is currently going through the final stages of review and testing. This feature also adds on-disk versioning to SAI. This allows SAI to support multiple on-disk formats during upgrades. I am mentioning this now because the CEP mentions �Partition Based Iteration� as an initial feature. We will change that to �Row Based Iteration� when the feature is merged. MikeA",existence
268,"Re: [DISCUSS] CEP-7 Storage Attached Index Thanks Caleb. Those observations are valid factual statements, and it's good to be clear where limitations are. I'd like to add that the usefulness of fan-out/broadcast secondary index queries depends on cluster size. I have noticed that everything in Cassandra tends to be designed for extremely large scale, with hundred or more nodes in mind. In the case of SAI or other indexes it is however the case that they can be more useful in smaller clusters, where the read amplification from fan-out is moderate. Cassandra userbase is probably different, but my experience from the Mongodb world was that less than 10% of users even need to use sharding. Hence 90% of apps can get the full benefit of a good secondary index implementation, including using queries without partition key. Similarly, at the other end someone with a large cluster could benefit from the ability to execute some infrequent query that needs to be broadcast across the cluster, as long as this query is insignificant in the total workload of the cluster. (Like once per day or once per hour.) henrik ",not-ak
269,"Re: [DISCUSS] CEP-7 Storage Attached Index Hey there, In the spirit of trying to get as many possible objections to a successful vote out of the way, I've added a ""Challenges"" section to the CEP: https://cwiki.apache.org/confluence/display/CASSANDRA/CEP-7%3A+Storage+Attached+Index#CEP7:StorageAttachedIndex-Challenges Most of you will be familiar with these, but I think we need to be as open/candid as possible about the potential risk they pose to SAI's broader usability. I've described them from the point of view that they are not intractable, but if anyone thinks they are, let's hash that disagreement out. Thanks! ",not-ak
275,Re: [DISCUSS] CEP-7 Storage Attached Index +1 on introducing this in an incremental manner and after reading through CASSANDRA-16092 that seems like a perfect place to start. I see that work on that Jira has stopped until direction for CEP-7 has been voted in. I say start the vote and let's get this really valuable developer feature underway. Patrick ,not-ak
277,"Re: [DISCUSS] CEP-7 Storage Attached Index So this thread stalled almost a year ago. (Wow, time flies when you're trying to release 4.0.) My synthesis of the conversation to this point is that while there are some open questions about testing methodology/""definition of done"" and our choice of particular on-disk data structures, neither of these should be a serious obstacle to moving forward w/ a vote. Having said that, is there anything left around the CEP that we feel should prevent it from moving to a vote? In terms of how we would proceed from the point a vote passes, it seems like there have been enough concerns around the proposed/necessary breaking changes to the 2i API, that we will start development by introducing components as incrementally as possible into a long-running feature branch off trunk. (This work would likely start w/ *CASSANDRA-16092* , which we could resolve as a sub-task of the SAI epic without interfering with other trunk development likely destined for a 4.x minor, etc.) ",executive
532,"Re: [DISCUSS] CEP-7 Storage Attached Index The goal is to support row-level index when merging SAI, I will update the CEP about it. Can you share more details on the optimizations? ",not-ak
533,"Re: [DISCUSS] CEP-7 Storage Attached Index table read perf (because SAI/SASI executes LOTS of SinglePartitionReadCommand after searching on-disk index) is more effective than switching from Trie to Prefix BTree. I haven't suggested switching to Prefix B-Tree or any other structure, the question was about rationale and motivation of picking one over the other, which I am curious about for personal reasons/interests that lie outside of Cassandra. Having this listed in CEP could have been helpful for future guidance. It's ok if this question is outside of the CEP scope. I also agree that there are many areas that require improvement around the read/write path and 2i, many of which (even outside of base table format or read perf) can yield positive performance results. time is right. I am very excited for this contribution, too, and it looks like very solid work. I have one more question, about ""Upon resolving partition keys, rows are loaded using Cassandra�s internal partition read command across SSTables and are post filtered"". One of the criticisms of SASI and reasons for marking it as experimental was CASSANDRA-11990. I think switching to row offsets also has a huge impact on interaction with SPRC and has some potential for optimisations. Question is: is this planned as a next step? If yes, how are we going to mark SAI as experimental until it gets row offsets? Also, it is likely that index format is going to change when row offsets are added, so my concern is that we may have to support two versions of a format for a smooth migration. ",not-ak
534,"Re: [DISCUSS] CEP-7 Storage Attached Index using Will update the CEP to emphasize: SAI will replace other indexes. construction. As long as prefix BTree supports range/prefix aggregation (which is used to speed up range/prefix query when matching entire subtree), we can plug it in and compare. It won't affect the CEP design which focuses on sharing data across indexes and posting aggregation. But for improving overall index read performance, I think improving base table read perf (because SAI/SASI executes LOTS of SinglePartitionReadCommand after searching on-disk index) is more effective than switching from Trie to Prefix BTree. ",executive
535,"Re: [DISCUSS] CEP-7 Storage Attached Index FWIW, I personally look forward to receiving that contribution when the time is right. ?On 23/09/2020, 18:45, ""Josh McKenzie"" wrote: talking about that would involve some bits of information DataStax might not be ready to share? At the risk of derailing, I've been poking and prodding this week at we contributors at DS getting our act together w/a draft CEP for donating the trie-based indices to the ASF project. More to come; the intention is certainly to contribute that code. The lack of a destination to merge it into (i.e. no 5.0-dev branch) is removing significant urgency from the process as well (not to open a 3rd Pandora's box), but there's certainly an interrelatedness to the conversations going on. --- Josh McKenzie Sent via Superhuman ",not-ak
538,"Re: [DISCUSS] CEP-7 Storage Attached Index talking about that would involve some bits of information DataStax might not be ready to share? At the risk of derailing, I've been poking and prodding this week at we contributors at DS getting our act together w/a draft CEP for donating the trie-based indices to the ASF project. More to come; the intention is certainly to contribute that code. The lack of a destination to merge it into (i.e. no 5.0-dev branch) is removing significant urgency from the process as well (not to open a 3rd Pandora's box), but there's certainly an interrelatedness to the conversations going on. --- Josh McKenzie Sent via Superhuman ",not-ak
539,"Re: [DISCUSS] CEP-7 Storage Attached Index As long as we can construct the on-disk indexes efficiently/directly from a Memtable-attached index on flush, there's room to try other data structures. Most of the innovation in SAI is around the layout of postings (something we can expand on if people are interested) and having a natively row-oriented design that scales w/ multiple indexed columns on single SSTables. There are some broader implications of using the trie that reach outside SAI itself, but talking about that would involve some bits of information DataStax might not be ready to share? ",existence
540,"Re: [DISCUSS] CEP-7 Storage Attached Index I did see a bit about ""future parity and beyond"" which is more or less an obvious goal. I think CEP should be more upfront with ""eventually replace it"" bit, since it raises the question about what the people who are using other index implementations can expect. ",not-ak
544,"Re: [DISCUSS] CEP-7 Storage Attached Index I think one of the goals stated in the CEP is for SAI to have parity with 2i such that it could eventually replace it. --------------------------------------------------------------------- To unsubscribe, e-mail: dev-unsubscribe@cassandra.apache.org For additional commands, e-mail: dev-help@cassandra.apache.org",not-ak
545,"Re: [DISCUSS] CEP-7 Storage Attached Index Short question: looking forward, how are we going to maintain three 2i implementations: SASI, SAI, and 2i? Another thing I think this CEP is missing is rationale and motivation about why trie-based indexes were chosen over, say, B-Tree. We did have a short discussion about this on Slack, but both arguments that I've heard (space-saving and keeping a small subset of nodes in memory) work only for the most primitive implementation of a B-Tree. Fully-occupied prefix B-Tree can have similar properties. There's been a lot of research on B-Trees and optimisations in those. Unfortunately, I do not have an implementation sitting around for a direct comparison, but I can imagine situations when B-Trees may perform better because of simpler construction. Maybe we should even consider prototyping a prefix B-Tree to have a more fair comparison. Thank you, -- Alex ",executive
565,Re: [DISCUSS] CEP-7 Storage Attached Index Thank you Patrick for hosting Cassandra Contributor Meeting for CEP-7 SAI. The recorded video is available here: https://cwiki.apache.org/confluence/display/CASSANDRA/2020-09-01+Apache+Cassandra+Contributor+Meeting ,not-ak
567,"Re: [DISCUSS] CEP-7 Storage Attached Index Thank you, Charles and Patrick ",not-ak
568,"Re: [DISCUSS] CEP-7 Storage Attached Index Thank you, Patrick! ",not-ak
569,Re: [DISCUSS] CEP-7 Storage Attached Index I just moved it to 8AM for this meeting to better accommodate APAC. Please see the update here: https://cwiki.apache.org/confluence/display/CASSANDRA/2020-08-01+Apache+Cassandra+Contributor+Meeting Patrick ,not-ak
575,"Re: [DISCUSS] CEP-7 Storage Attached Index Patrick, 11AM PST is a bad time for the people in the APAC timezone. Can we move it to 7 or 8AM PST in the morning to accommodate their needs ? ~Charles ",not-ak
576,"Re: [DISCUSS] CEP-7 Storage Attached Index Meeting scheduled. https://cwiki.apache.org/confluence/display/CASSANDRA/2020-08-01+Apache+Cassandra+Contributor+Meeting Tuesday September 1st, 11AM PST. I added a basic bullet for the agenda but if there is more, edit away. Patrick ",not-ak
577,Re: [DISCUSS] CEP-7 Storage Attached Index +1 ,not-ak
578,Re: [DISCUSS] CEP-7 Storage Attached Index +1 ,not-ak
579,Re: [DISCUSS] CEP-7 Storage Attached Index +1 ,not-ak
580,"Re: [DISCUSS] CEP-7 Storage Attached Index +1 On Wed, Aug 26, 2020, 3:45 PM Patrick McFadin wrote:",not-ak
581,"Re: [DISCUSS] CEP-7 Storage Attached Index This is related to the discussion Jordan and I had about the contributor Zoom call. Instead of open mic for any issue, call it based on a discussion thread or threads for higher bandwidth discussion. I would be happy to schedule on for next week to specifically discuss CEP-7. I can attach the recorded call to the CEP after. +1 or -1? Patrick ",not-ak
582,"Re: [DISCUSS] CEP-7 Storage Attached Index We probably should have a discussion on the ML or monthly contrib call about it first to see how aligned the interested contributors are. Could do that through CEP as well but CEP's (at least thus far sans k8s operator) tend to start with a strong, deeply thought out point of view being expressed. ",not-ak
583,"Re: [DISCUSS] CEP-7 Storage Attached Index bound SAI also benefits from larger memory because SAI puts block info on heap for searching on-disk components and having cross-index files on page cache improves read performance of different indexes on the same table. in SAI won't crash the node during compaction and requires less CPU/IO. * SAI defines global memory limit for compaction instead of per-index memory limit used by SASI. For example, compactions are running on 10 tables and each has 10 indexes. SAI will cap the memory usage with global limit while SASI may use up to 100 * per-index limit. * After flushing in-memory segments to disk, SAI won't merge on-disk segments while SASI attempts to merge them at the end. There are pros and cons of not merging segments: ** Pros: compaction runs faster and requires fewer resources. ** Cons: small segments reduce compression ratio. * SAI on-disk format with row ids compresses better. deprecation doesn't, the Agreed that we should reduce maintenance area if possible, but only very limited code base (eg. RangeIterator, QueryPlan) can be shared. The rest of the code base is quite different because of on-disk format and cross-index files. The goal of this CEP is to get community buy-in on SAI's design. Tokenization, DelimiterAnalyzer should be straightforward to implement on top of SAI. Except for ""Like"", ""Tokenisation"", ""DelimiterAnalyzer"", the rest of SASI can be replaced by SAI. away""? I believe most of the known bugs in 2i/SASI either have been addressed in SAI or don't apply to SAI. loaded Agreed that modularization is the way to go and will speed up module development speed. Does community plan to open another discussion or CEP on modularization? ",executive
584,"Re: [DISCUSS] CEP-7 Storage Attached Index Adding to Duy's questions� * Hardware specs SASI's performance, specifically the search in the B+ tree component, depends a lot on the component file's header being available in the pagecache. SASI benefits from (needs) nodes with lots of RAM. Is SAI bound to this same or similar limitation? Flushing of SASI can be CPU+IO intensive, to the point of saturation, pauses, and crashes on the node. SSDs are a must, along with a bit of tuning, just to avoid bringing down your cluster. Beyond reducing space requirements, does SAI improve on these things? Like SASI how does SAI, in its own way, change/narrow the recommendations on node hardware specs? * Code Maintenance I understand the desire in keeping out of scope the longer term deprecation and migration plan, but� if SASI provides functionality that SAI doesn't, like tokenisation and DelimiterAnalyzer, yet introduces a body of code ~somewhat similar, shouldn't we be roughly sketching out how to reduce the maintenance surface area? Can we list what configurations of SASI will become deprecated once SAI becomes non-experimental? Given a few bugs are open against 2i and SASI, can we provide some overview, or rough indication, of how many of them we could ""triage away""? And, is it time for the project to start introducing new SPI implementations as separate sub-modules and jar files that are only loaded at runtime based on configuration settings? (sorry for the conflation on this one, but maybe it's the right time to raise it :shrug:) regards, Mick ",executive
585,"Re: [DISCUSS] CEP-7 Storage Attached Index started around the ""definition of done"" before determining what sufficient quality assurance looks like for this feature. Looking forward to the Test/QA guideline. Thanks for bringing this up. Added CEP-7 SAI cwiki: https://cwiki.apache.org/confluence/display/CASSANDRA/CEP-7%3A+Storage+Attached+Index ",not-ak
586,"Re: [DISCUSS] CEP-7 Storage Attached Index space required for index structure when using CONTAINS logic because of the decomposition of text columns into n-grams. Will SAI suffer from the same issue in future iterations ? SAI does not have specific ngram support atm, though that may be added with tokenizers. Ngrams do indeed grow the index, that's a user decision for faster queries or more disk space. ",executive
587,"Re: [DISCUSS] CEP-7 Storage Attached Index Hi Duy, great questions. that As of now, SAI indexes partition offset, same as SASI. But during design, we have taken row-level-index into consideration and row-awareness is being prototyped. For the record, partition-level indexing works nicely when most rows in the wide partition match indexed value. After switching to row-level-index, when matching most rows in wide partition, the index engine needs to fall back to partition-level index behavior (scanning entire partition + post-filter) instead of fetching single rows many times. huge the Tokenization wasn't part of the CEP scope. Off the top of my head, I think tokenization did require more space, as both SAI and SASI need to store matches for every decomposed value. But with frame-of-reference encoding on row ids, SAI should require less disk space than SASI. does Yes. * On coordinator, it will find replicas with PK. * On replica side: - it will skip to given PK token - there is some pruning based on min/max key of index segments. Collections, static columns, composite partition key are supported. I think ""UDT indexings (at any depth)"" can be added because there is no architectural limitation on SAI or SASI. I have invited you to slack #cassandra-sai, really appreciate your participation. ",executive
589,"Re: [DISCUSS] CEP-7 Storage Attached Index Last but not least 4) Are collections, static columns, composite partition key composent and UDT indexings (at any depth) on the roadmap of SAI ? I strongly believe that those features are the bare minimum to make SAI an interesting replacement for the native 2nd index as well as SASI. SASI limited support for those advanced data structures has hindered its wide adoption (among other issues and bugs) Regards Duy Hai DOAN Le mar. 18 ao�t 2020 � 13:02, Jasonstack Zhao Yang < jasonstack.zhao@gmail.com> a �crit :",executive
590,"Re: [DISCUSS] CEP-7 Storage Attached Index CASSANDRA-15536 might set some good examples for retrospectively shoring up our quality assurance, but offers no prescriptions for how we approach the testing of new work. I think the project needs to conclude the discussions that keep being started around the ""definition of done"" before determining what sufficient quality assurance looks like for this feature. I've briefly set out some of my views in an earlier email chain that was initiated by Josh, that unfortunately received no response. The project is generally very busy right now as we approach 4.0 release, which is partially I assume why there has been no movement. Assuming no further activity from others, as we get closer to 4.0 (and I have more time) I will try to produce a more formal proposal for quality assurance for the project, to be debated and agreed. ?On 18/08/2020, 12:02, ""Jasonstack Zhao Yang"" wrote: Mick thanks for your questions. defining more specific QA guidelines for 4.0-rc. This would be an important Agreed, I think CASSANDRA-15536 (4.0 Quality: Components and Test Plans) has set a good example of QA/Testing. defined? (per above) SAI will follow the same QA/Testing guideline as in CASSANDRA-15536. plan> for making those changes ensuring maintained QA, e.g. is there separate QA implementation? The plan is to have interface changes and their new implementations to be reviewed/tested/merged at once to reduce overhead. But if having interface changes reviewed/tested/merged separately helps quality, I don't think anyone will object. the> CEP author of when users might still choose afresh 2i or SASI over SAI I'd like SAI to be the only index for users, but this is a decision to be made by the community. Contributors that are still active on C* or related projects: Andres de la Pe�a Caleb Rackliffe Dan LaRocque Jason Rutherglen Mike Adamson Rocco Varela Zhao Yang I will shepherd. Anyone that is interested in C* index, feel free to join us at slack #cassandra-sai. why? (the CEP process suggest a wiki page, and feedback on why another Didn't notice wiki is required. Will port CEP to wiki. ",not-ak
591,"Re: [DISCUSS] CEP-7 Storage Attached Index Thank you Zhao Yang for starting this topic After reading the short design doc, I have a few questions 1) SASI was pretty inefficient indexing wide partitions because the index structure only retains the partition token, not the clustering colums. As per design doc SAI has row id mapping to partition offset, can we hope that indexing wide partition will be more efficient with SAI ? One detail that worries me is that in the beggining of the design doc, it is said that the matching rows are post filtered while scanning the partition. Can you confirm or infirm that SAI is efficient with wide partitions and provides the partition offsets to the matching rows ? 2) About space efficiency, one of the biggest drawback of SASI was the huge space required for index structure when using CONTAINS logic because of the decomposition of text columns into n-grams. Will SAI suffer from the same issue in future iterations ? I'm anticipating a bit 3) If I'm querying using SAI and providing complete partition key, will it be more efficient than querying without partition key. In other words, does SAI provide any optimisation when partition key is specified ? Regards Duy Hai DOAN Le mar. 18 ao�t 2020 � 11:39, Mick Semb Wever a �crit :",executive
592,"Re: [DISCUSS] CEP-7 Storage Attached Index Mick thanks for your questions. defining more specific QA guidelines for 4.0-rc. This would be an important Agreed, I think CASSANDRA-15536 (4.0 Quality: Components and Test Plans) has set a good example of QA/Testing. defined? (per above) SAI will follow the same QA/Testing guideline as in CASSANDRA-15536. plan> for making those changes ensuring maintained QA, e.g. is there separate QA implementation? The plan is to have interface changes and their new implementations to be reviewed/tested/merged at once to reduce overhead. But if having interface changes reviewed/tested/merged separately helps quality, I don't think anyone will object. the> CEP author of when users might still choose afresh 2i or SASI over SAI I'd like SAI to be the only index for users, but this is a decision to be made by the community. Contributors that are still active on C* or related projects: Andres de la Pe�a Caleb Rackliffe Dan LaRocque Jason Rutherglen Mike Adamson Rocco Varela Zhao Yang I will shepherd. Anyone that is interested in C* index, feel free to join us at slack #cassandra-sai. why? (the CEP process suggest a wiki page, and feedback on why another Didn't notice wiki is required. Will port CEP to wiki. ",executive
593,"Re: [DISCUSS] CEP-7 Storage Attached Index What comes immediately to mind is testing requirements. It has been mentioned already that the project's testability and QA guidelines are inadequate to successfully introduce new features and refactorings to the codebase. During the 4.0 beta phase this was intended to be addressed, i.e. defining more specific QA guidelines for 4.0-rc. This would be an important step towards QA guidelines for all changes and CEPs post-4.0. Questions from me - How will this be tested, how will its QA status and lifecycle be defined? (per above) - With existing C* code needing to be changed, what is the proposed plan for making those changes ensuring maintained QA, e.g. is there separate QA cycles planned for altering the SPI before adding a new SPI implementation? - Despite being out of scope, it would be nice to have some idea from the CEP author of when users might still choose afresh 2i or SASI over SAI, - Who fills the roles involved? Who are the contributors in this DataStax team? Who is the shepherd? Are there other stakeholders willing to be involved? - Is there a preference to use gdoc instead of the project's wiki, and why? (the CEP process suggest a wiki page, and feedback on why another approach is considered better helps evolve the CEP process itself) cheers, Mick",executive
594,"[DISCUSS] CEP-7 Storage Attached Index Hi, As per the CEP guideline, I am sending this email to start a discussion about Storage-Attached-Index[1][2] for Apache Cassandra. A team at DataStax has developed a new index implementation, called Storage Attached Index(SAI), based on the advancement made by SASI. SAI improves: * disk usage by sharing of common data between multiple column indexes on the same table and better compression of on-disk structures. * numeric range query performance with modified KDTree and collection type support. * compaction performance and stability for larger data set. There is a more detailed explanation about SAI design in the CEP document. To make the technical discussion simpler, we created a slack channel #cassandra-sai. We are looking forward to the community's feedback and suggestions. Regards, Zhao Yang [1] https://docs.google.com/document/d/1V830eAMmQAspjJdjviVZIaSolVGvZ1hVsqOLWyV0DS4/edit#heading=h.cgm22puztagk [2] https://issues.apache.org/jira/browse/CASSANDRA-16052",executive
392,"RE: Enable running Cassandra 3.11 on Java 11 Java 11 support in Cassandra 3.11 would be fantastic. Is this something the Cassandra project will follow-up or is this a dead-end in favor of Cassandra 4.0, although Java 11 is marked as ""experimental"" there. Not sure what this means for production usage. ? Thanks, Thomas",not-ak
329,"[RELEASE] Apache Cassandra 4.0.0 released The Cassandra team is pleased to announce the release of Apache Cassandra version 4.0.0. Apache Cassandra is a fully distributed database. It is the right choice when you need scalability and high availability without compromising performance. http://cassandra.apache.org/ Downloads of source and binary distributions are available in our download section: http://cassandra.apache.org/download/ This version is the initial release in the 4.0 series. As always, please pay attention to the release notes[2] and Let us know[3] if you were to encounter any problem. Enjoy! [1]: CHANGES.txt https://gitbox.apache.org/repos/asf?p=cassandra.git;a=blob_plain;f=CHANGES.txt;hb=refs/tags/cassandra-4.0.0 [2]: NEWS.txt https://gitbox.apache.org/repos/asf?p=cassandra.git;a=blob_plain;f=NEWS.txt;hb=refs/tags/cassandra-4.0.0 [3]: https://issues.apache.org/jira/browse/CASSANDRA --------------------------------------------------------------------- To unsubscribe, e-mail: dev-unsubscribe@cassandra.apache.org For additional commands, e-mail: dev-help@cassandra.apache.org",not-ak
657,"Re: List of serious issues fixed in 3.0.x Wanted to add some that I remembered: * https://issues.apache.org/jira/browse/CASSANDRA-12811 - data resurrection, but was marked as normal because was discovered with a test. Should've marked it as critical. * https://issues.apache.org/jira/browse/CASSANDRA-12956 - data loss (commit log isn't replayed on custom 2i exception) * https://issues.apache.org/jira/browse/CASSANDRA-12144 - undeletable/duplicate rows problem; can be considered data resurrection and/or sstable corruption. ",not-ak
676,"Re: List of serious issues fixed in 3.0.x ""ML is plaintext bro"" - thanks Mick.�?_?Since we're stuck in the late 90's, here's some links to a gsheet:Defects by month:�https://docs.google.com/spreadsheets/d/1Qt8lLIiqVvK7mlSML7zsmXdAc-LsvktFW5RXJDRtN8k/edit#gid=1584867240Defects by component:�https://docs.google.com/spreadsheets/d/1Qt8lLIiqVvK7mlSML7zsmXdAc-LsvktFW5RXJDRtN8k/edit#gid=1946109279Defects by type:�https://docs.google.com/spreadsheets/d/1Qt8lLIiqVvK7mlSML7zsmXdAc-LsvktFW5RXJDRtN8k/edit#gid=385136105",not-ak
677,"Re: List of serious issues fixed in 3.0.x Sankalp, thanks for sending the spreadsheet and Josh for preparing this analysis (pending image issues; look forward to reading)! I'd encourage everyone involved in the project to review the list of tickets captured here. These issues aren't theoretical and represent real scenarios that result in data loss, data corruption, incorrect responses to queries, and other violations of fundamental properties of the database. As a community, we've made great progress over the past two years. The focus on quality has dramatically improved the safety of Cassandra as a database -- especially in the most recent patchlevel releases of the 3.0.x and 3.11.x series. That said, we're also not out of the woods. The following three issues have been reported and confirmed genuine in the past week: � CASSANDRA-15789: Rows can get duplicated in mixed major-version clusters and after full upgrade � CASSANDRA-15778: CorruptSSTableException after a 2.1 SSTable is upgraded to 3.0, failing reads � CASSANDRA-15790: EmptyType doesn't override writeValue so could attempt to write bytes when expected not to Regarding Dinesh's point on regression tests, we're beginning to go even further. In response to the issues in this spreadsheet, we're evolving new approaches toward *active assertion* of data integrity. C-15789 adds read/repair/compaction-path detection of primary key duplication, a great way to audit and remediate instances of corruption detected in a cluster. Repaired data tracking introduced in C-14145 and improvements to Preview Repair are also great examples, enabling Cassandra to assert the consistency of repaired data (something we'd taken for granted). Active assertion of data integrity invariants in Cassandra is an important frontier -- and one we need to explore further. Previously-adopted methodologies like property-based testing, large-scale diff tests asserting identity of data between 2.1- and 3.0.x clusters post-upgrade via billions of randomized queries, fault injection, model-based tests, CI improvements, and flaky test reduction have helped us make huge progress toward quality and continue to pay dividends. I want to thank everyone for their work on safety and stability. It's clear we have more ahead, but it's critical to Apache Cassandra's future and toward shipping a 4.0 release that users can trust and adopt quickly. � Scott ________________________________________ From: Joshua McKenzie Sent: Thursday, May 7, 2020 9:31 AM Cc: dev@cassandra.apache.org Subject: Re: List of serious issues fixed in 3.0.x Hearing the images got killed by the web server. Trying from gmail (sorry for spam). Time to see if it's the apache smtp server or the list culling images: ------------------------------------------- I did a little analysis on this data (any defect marked with fixversion 4.0 that rose to the level of critical in terms of availability, correctness, or corruption/loss) and charted some things the rest of the project community might find interesting: 1: Critical (availability, correctness, corruption/loss) defects fixed per month since about 6 months before 3.11.0: [monthly.png] 2: Components in which critical defects arose (note: bright red bar == sum of 3 dark red): [Total Defects by Component.png] 3: Type of defect found and fixed (bright red: cluster down or permaloss, dark red: temp corrupt/loss, yellow: incorrect response): [Total Defects by Type.png] My personal takeaways from this: a ton of great defect fixing work has gone into 4.0. I'd love it if we had both code coverage analysis for testing on the codebase as well as data to surface where hotspots of defects are in the code that might need further testing (caveat: many have voiced their skepticism of the value of this type of data in the past in this project community, so that's probably another conversation to have on another thread) Hope someone else finds the above interesting if not useful. -- Joshua McKenzie ",not-ak
678,"Re: List of serious issues fixed in 3.0.x Hearing the images got killed by the web server. Trying from gmail (sorry for spam). Time to see if it's the apache smtp server or the list culling images:-------------------------------------------I did a little analysis on this data (any defect marked with fixversion 4.0 that rose to the level of critical in terms of availability, correctness, or corruption/loss) and charted some things the rest of the project community might find interesting:1: Critical (availability, correctness, corruption/loss) defects fixed per month since about 6 months before 3.11.0:2: Components in which critical defects arose (note: bright red bar == sum of 3 dark red):3: Type of defect found and fixed (bright red: cluster down or permaloss, dark red: temp corrupt/loss, yellow: incorrect response):My personal takeaways from this: a ton of great defect fixing work has gone into 4.0. I'd love it if we had both code coverage analysis for testing on the codebase as well as data to surface where hotspots of defects are in the code that might need further testing (caveat: many have voiced their skepticism of the value of this type of data in the past in this project community, so that's probably another conversation to have on another thread)Hope someone else finds the above interesting if not useful.--Joshua McKenzie",not-ak
679,"Re: List of serious issues fixed in 3.0.x I did a little analysis on this data (any defect marked with fixversion 4.0 that rose to the level of critical in terms of availability, correctness, or corruption/loss) and charted some things the rest of the project community might find interesting:1: Critical (availability, correctness, corruption/loss) defects fixed per month since about 6 months before 3.11.0:2: Components in which critical defects arose (note: bright red bar == sum of 3 dark red):3: Type of defect found and fixed (bright red: cluster down or permaloss, dark red: temp corrupt/loss, yellow: incorrect response):My personal takeaways from this: a ton of great defect fixing work has gone into 4.0. I'd love it if we had both code coverage analysis for testing on the codebase as well as data to surface where hotspots of defects are in the code that might need further testing (caveat: many have voiced their skepticism of the value of this type of data in the past in this project community, so that's probably another conversation to have on another thread)Hope someone else finds the above interesting if not useful.~Josh",not-ak
681,"Re: List of serious issues fixed in 3.0.x Hi Sankalp, Thanks for bringing this up. At the very minimum, I hope we have regression tests for the specific issues we have fixed. I personally think, the project should focus on building a comprehensive test suite. However, some of these issues can only be detected at scale. We need users to test* C* in their environment for their use-cases. Ideally these folks stand up large clusters and tee their traffic to the new cluster and report issues. If we had an automated test suite that everyone can run at a large scale that would be even better. Thanks, Dinesh * test != starting C* in a few nodes and looking at logs. --------------------------------------------------------------------- To unsubscribe, e-mail: dev-unsubscribe@cassandra.apache.org For additional commands, e-mail: dev-help@cassandra.apache.org",existence
682,"List of serious issues fixed in 3.0.x Hi, I want to share some of the serious issues that were found and fixed in 3.0.x. I have created this list from JIRA to help us identify areas for validating 4.0. This will also give an insight to the dev community. Let us know if anyone has suggestions on how to better use this data in validating 4.0. Also this list might be missing some issues identified early on in 3.0.x or some latest ones. Link: https://tinyurl.com/30seriousissues Thanks, Sankalp",not-ak
1421,"[RELEASE] Apache Cassandra 3.7 released The Cassandra team is pleased to announce the release of Apache Cassandra version 3.7. Apache Cassandra is a fully distributed database. It is the right choice when you need scalability and high availability without compromising performance. http://cassandra.apache.org/ Downloads of source and binary distributions are listed in our download section: http://cassandra.apache.org/download/ This version is a tick-tock bug fix release[1] on the 3.x series. As always, please pay attention to the release notes[2] and Let us know[3] if you were to encounter any problem. Enjoy! [1]: http://goo.gl/k1abJV (CHANGES.txt) [2]: http://goo.gl/3ENJIz (NEWS.txt) [3]: https://issues.apache.org/jira/browse/CASSANDRA",not-ak
2119,"RE: Hadoop Tools Layout (was Re: DistCpV2 in 0.23) If hadoop-tools will be built as part of hadoop-common, then none of these tools should be allowed to have a dependency on hdfs or mapreduce. Conversely is also true, when tools do have any such dependency, they cannot be bult as part of hadoop-common. We cannot have circular dependencies like that. That is probably obvious, but I'm just saying... Joep ________________________________________ From: Amareshwari Sri Ramadasu [amarsri@yahoo-inc.com] Sent: Wednesday, September 07, 2011 9:33 PM To: mapreduce-dev@hadoop.apache.org Cc: common-dev@hadoop.apache.org Subject: Re: Hadoop Tools Layout (was Re: DistCpV2 in 0.23) It is good to have hadoop-tools module separately. But as I asked before we need to answer some questions here. I'm trying to answer them myself. Comments are welcome. Here, I meant should Hadoop common mailing list be used Or should we have a separate mailing list for Tools? I agree with Vinod here, that we can tie it Hadoop-common jira/mailing lists. Jenkins nightly/patch builds for Hadoop tools can run as part of Hadoop common if use Hadoop common mailing list for this. Also, I propose every patch build of HDFS and MAPREDUCE should also run tools tests to make sure nothing is broken. That would ease the maintenance of hadoop-tools module. I presume tools test should not take much time (some thing like not more than 30 minutes). I'm not sure about this whether Mavenization can take care of it. Thanks Amareshwari On 9/8/11 9:13 AM, ""Rottinghuis, Joep"" wrote: Does a separate hadoop-tools module imply that there will be a separate Jenkins build as well? Thanks, Joep ________________________________________ From: Alejandro Abdelnur [tucu@cloudera.com] Sent: Wednesday, September 07, 2011 11:35 AM To: mapreduce-dev@hadoop.apache.org Subject: Re: Hadoop Tools Layout (was Re: DistCpV2 in 0.23) Makes sense On Wed, Sep 7, 2011 at 11:32 AM, wrote:",existence
2121,"RE: Hadoop Tools Layout (was Re: DistCpV2 in 0.23) Does a separate hadoop-tools module imply that there will be a separate Jenkins build as well? Thanks, Joep ________________________________________ From: Alejandro Abdelnur [tucu@cloudera.com] Sent: Wednesday, September 07, 2011 11:35 AM To: mapreduce-dev@hadoop.apache.org Subject: Re: Hadoop Tools Layout (was Re: DistCpV2 in 0.23) Makes sense On Wed, Sep 7, 2011 at 11:32 AM, wrote:",not-ak
1688,"RE: [DISCUSSION] Portable remote client APIs Yep! I just think both can support multiple language client. As you mentioned, it is not critical issues about performance in Thrift. Anyway, I think it's a good discussion about the remote interface on Tajo. :) Sincerely, Yousun Jeong",existence
1693,"RE: [DISCUSSION] Portable remote client APIs I give +1 to maintain both rest and thrift. Best regards, Seungun. ________________________________________ ?? ??: ??? ?? ??: 2015? 3? 13? ??? ?? 1:33 ?? ??: dev@tajo.apache.org ??: RE: [DISCUSSION] Portable remote client APIs I suggest another option. What do you think about two options for remote interface? Thrift is the faster and more lightweight than REST. Please refer this article. - http://blog.cloudera.com/blog/2013/03/how-to-use-the-apache-hbase-rest-interface-part-1/ It describes various ways to access and interact with HBase. Both of them, giving developers a wide choice of languages and programs to use. Best regards, Yousun Jeong.",not-ak
1694,"RE: [DISCUSSION] Portable remote client APIs Hey folks, Any one will be attending ApacheCon at Austin TX next month? Thanks, --� Ethan On March 12, 2015 at 11:34:16 PM, ??? (jerryjung@sk.com) wrote: I suggest another option. What do you think about two options for remote interface? Thrift is the faster and more lightweight than REST. Please refer this article. - http://blog.cloudera.com/blog/2013/03/how-to-use-the-apache-hbase-rest-interface-part-1/ It describes various ways to access and interact with HBase. Both of them, giving developers a wide choice of languages and programs to use. Best regards, Yousun Jeong.",not-ak
1695,"RE: [DISCUSSION] Portable remote client APIs I suggest another option. What do you think about two options for remote interface? Thrift is the faster and more lightweight than REST. Please refer this article. - http://blog.cloudera.com/blog/2013/03/how-to-use-the-apache-hbase-rest-interface-part-1/ It describes various ways to access and interact with HBase. Both of them, giving developers a wide choice of languages and programs to use. Best regards, Yousun Jeong.",existence
